<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<!--[if IE]><meta http-equiv="X-UA-Compatible" content="IE=edge"><![endif]-->
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 1.5.2">
<title>The GPars Guide</title>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400">
<style>
/* Asciidoctor default stylesheet | MIT License | http://asciidoctor.org */
/* Remove the comments around the @import statement below when using this as a custom stylesheet */
/*@import "https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400";*/
article,aside,details,figcaption,figure,footer,header,hgroup,main,nav,section,summary{display:block}
audio,canvas,video{display:inline-block}
audio:not([controls]){display:none;height:0}
[hidden],template{display:none}
script{display:none!important}
html{font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}
body{margin:0}
a{background:transparent}
a:focus{outline:thin dotted}
a:active,a:hover{outline:0}
h1{font-size:2em;margin:.67em 0}
abbr[title]{border-bottom:1px dotted}
b,strong{font-weight:bold}
dfn{font-style:italic}
hr{-moz-box-sizing:content-box;box-sizing:content-box;height:0}
mark{background:#ff0;color:#000}
code,kbd,pre,samp{font-family:monospace;font-size:1em}
pre{white-space:pre-wrap}
q{quotes:"\201C" "\201D" "\2018" "\2019"}
small{font-size:80%}
sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}
sup{top:-.5em}
sub{bottom:-.25em}
img{border:0}
svg:not(:root){overflow:hidden}
figure{margin:0}
fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}
legend{border:0;padding:0}
button,input,select,textarea{font-family:inherit;font-size:100%;margin:0}
button,input{line-height:normal}
button,select{text-transform:none}
button,html input[type="button"],input[type="reset"],input[type="submit"]{-webkit-appearance:button;cursor:pointer}
button[disabled],html input[disabled]{cursor:default}
input[type="checkbox"],input[type="radio"]{box-sizing:border-box;padding:0}
input[type="search"]{-webkit-appearance:textfield;-moz-box-sizing:content-box;-webkit-box-sizing:content-box;box-sizing:content-box}
input[type="search"]::-webkit-search-cancel-button,input[type="search"]::-webkit-search-decoration{-webkit-appearance:none}
button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}
textarea{overflow:auto;vertical-align:top}
table{border-collapse:collapse;border-spacing:0}
*,*:before,*:after{-moz-box-sizing:border-box;-webkit-box-sizing:border-box;box-sizing:border-box}
html,body{font-size:100%}
body{background:#fff;color:rgba(0,0,0,.8);padding:0;margin:0;font-family:"Noto Serif","DejaVu Serif",serif;font-weight:400;font-style:normal;line-height:1;position:relative;cursor:auto}
a:hover{cursor:pointer}
img,object,embed{max-width:100%;height:auto}
object,embed{height:100%}
img{-ms-interpolation-mode:bicubic}
#map_canvas img,#map_canvas embed,#map_canvas object,.map_canvas img,.map_canvas embed,.map_canvas object{max-width:none!important}
.left{float:left!important}
.right{float:right!important}
.text-left{text-align:left!important}
.text-right{text-align:right!important}
.text-center{text-align:center!important}
.text-justify{text-align:justify!important}
.hide{display:none}
.antialiased,body{-webkit-font-smoothing:antialiased}
img{display:inline-block;vertical-align:middle}
textarea{height:auto;min-height:50px}
select{width:100%}
p.lead,.paragraph.lead>p,#preamble>.sectionbody>.paragraph:first-of-type p{font-size:1.21875em;line-height:1.6}
.subheader,.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{line-height:1.45;color:#7a2518;font-weight:400;margin-top:0;margin-bottom:.25em}
div,dl,dt,dd,ul,ol,li,h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6,pre,form,p,blockquote,th,td{margin:0;padding:0;direction:ltr}
a{color:#2156a5;text-decoration:underline;line-height:inherit}
a:hover,a:focus{color:#1d4b8f}
a img{border:none}
p{font-family:inherit;font-weight:400;font-size:1em;line-height:1.6;margin-bottom:1.25em;text-rendering:optimizeLegibility}
p aside{font-size:.875em;line-height:1.35;font-style:italic}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{font-family:"Open Sans","DejaVu Sans",sans-serif;font-weight:300;font-style:normal;color:#ba3925;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;line-height:1.0125em}
h1 small,h2 small,h3 small,#toctitle small,.sidebarblock>.content>.title small,h4 small,h5 small,h6 small{font-size:60%;color:#e99b8f;line-height:0}
h1{font-size:2.125em}
h2{font-size:1.6875em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.375em}
h4,h5{font-size:1.125em}
h6{font-size:1em}
hr{border:solid #ddddd8;border-width:1px 0 0;clear:both;margin:1.25em 0 1.1875em;height:0}
em,i{font-style:italic;line-height:inherit}
strong,b{font-weight:bold;line-height:inherit}
small{font-size:60%;line-height:inherit}
code{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;color:rgba(0,0,0,.9)}
ul,ol,dl{font-size:1em;line-height:1.6;margin-bottom:1.25em;list-style-position:outside;font-family:inherit}
ul,ol,ul.no-bullet,ol.no-bullet{margin-left:1.5em}
ul li ul,ul li ol{margin-left:1.25em;margin-bottom:0;font-size:1em}
ul.square li ul,ul.circle li ul,ul.disc li ul{list-style:inherit}
ul.square{list-style-type:square}
ul.circle{list-style-type:circle}
ul.disc{list-style-type:disc}
ul.no-bullet{list-style:none}
ol li ul,ol li ol{margin-left:1.25em;margin-bottom:0}
dl dt{margin-bottom:.3125em;font-weight:bold}
dl dd{margin-bottom:1.25em}
abbr,acronym{text-transform:uppercase;font-size:90%;color:rgba(0,0,0,.8);border-bottom:1px dotted #ddd;cursor:help}
abbr{text-transform:none}
blockquote{margin:0 0 1.25em;padding:.5625em 1.25em 0 1.1875em;border-left:1px solid #ddd}
blockquote cite{display:block;font-size:.9375em;color:rgba(0,0,0,.6)}
blockquote cite:before{content:"\2014 \0020"}
blockquote cite a,blockquote cite a:visited{color:rgba(0,0,0,.6)}
blockquote,blockquote p{line-height:1.6;color:rgba(0,0,0,.85)}
@media only screen and (min-width:768px){h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2}
h1{font-size:2.75em}
h2{font-size:2.3125em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.6875em}
h4{font-size:1.4375em}}table{background:#fff;margin-bottom:1.25em;border:solid 1px #dedede}
table thead,table tfoot{background:#f7f8f7;font-weight:bold}
table thead tr th,table thead tr td,table tfoot tr th,table tfoot tr td{padding:.5em .625em .625em;font-size:inherit;color:rgba(0,0,0,.8);text-align:left}
table tr th,table tr td{padding:.5625em .625em;font-size:inherit;color:rgba(0,0,0,.8)}
table tr.even,table tr.alt,table tr:nth-of-type(even){background:#f8f8f7}
table thead tr th,table tfoot tr th,table tbody tr td,table tr td,table tfoot tr td{display:table-cell;line-height:1.6}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2;word-spacing:-.05em}
h1 strong,h2 strong,h3 strong,#toctitle strong,.sidebarblock>.content>.title strong,h4 strong,h5 strong,h6 strong{font-weight:400}
.clearfix:before,.clearfix:after,.float-group:before,.float-group:after{content:" ";display:table}
.clearfix:after,.float-group:after{clear:both}
*:not(pre)>code{font-size:.9375em;font-style:normal!important;letter-spacing:0;padding:.1em .5ex;word-spacing:-.15em;background-color:#f7f7f8;-webkit-border-radius:4px;border-radius:4px;line-height:1.45;text-rendering:optimizeSpeed}
pre,pre>code{line-height:1.45;color:rgba(0,0,0,.9);font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;text-rendering:optimizeSpeed}
.keyseq{color:rgba(51,51,51,.8)}
kbd{display:inline-block;color:rgba(0,0,0,.8);font-size:.75em;line-height:1.4;background-color:#f7f7f7;border:1px solid #ccc;-webkit-border-radius:3px;border-radius:3px;-webkit-box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em white inset;box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em #fff inset;margin:-.15em .15em 0 .15em;padding:.2em .6em .2em .5em;vertical-align:middle;white-space:nowrap}
.keyseq kbd:first-child{margin-left:0}
.keyseq kbd:last-child{margin-right:0}
.menuseq,.menu{color:rgba(0,0,0,.8)}
b.button:before,b.button:after{position:relative;top:-1px;font-weight:400}
b.button:before{content:"[";padding:0 3px 0 2px}
b.button:after{content:"]";padding:0 2px 0 3px}
p a>code:hover{color:rgba(0,0,0,.9)}
#header,#content,#footnotes,#footer{width:100%;margin-left:auto;margin-right:auto;margin-top:0;margin-bottom:0;max-width:62.5em;*zoom:1;position:relative;padding-left:.9375em;padding-right:.9375em}
#header:before,#header:after,#content:before,#content:after,#footnotes:before,#footnotes:after,#footer:before,#footer:after{content:" ";display:table}
#header:after,#content:after,#footnotes:after,#footer:after{clear:both}
#content{margin-top:1.25em}
#content:before{content:none}
#header>h1:first-child{color:rgba(0,0,0,.85);margin-top:2.25rem;margin-bottom:0}
#header>h1:first-child+#toc{margin-top:8px;border-top:1px solid #ddddd8}
#header>h1:only-child,body.toc2 #header>h1:nth-last-child(2){border-bottom:1px solid #ddddd8;padding-bottom:8px}
#header .details{border-bottom:1px solid #ddddd8;line-height:1.45;padding-top:.25em;padding-bottom:.25em;padding-left:.25em;color:rgba(0,0,0,.6);display:-ms-flexbox;display:-webkit-flex;display:flex;-ms-flex-flow:row wrap;-webkit-flex-flow:row wrap;flex-flow:row wrap}
#header .details span:first-child{margin-left:-.125em}
#header .details span.email a{color:rgba(0,0,0,.85)}
#header .details br{display:none}
#header .details br+span:before{content:"\00a0\2013\00a0"}
#header .details br+span.author:before{content:"\00a0\22c5\00a0";color:rgba(0,0,0,.85)}
#header .details br+span#revremark:before{content:"\00a0|\00a0"}
#header #revnumber{text-transform:capitalize}
#header #revnumber:after{content:"\00a0"}
#content>h1:first-child:not([class]){color:rgba(0,0,0,.85);border-bottom:1px solid #ddddd8;padding-bottom:8px;margin-top:0;padding-top:1rem;margin-bottom:1.25rem}
#toc{border-bottom:1px solid #efefed;padding-bottom:.5em}
#toc>ul{margin-left:.125em}
#toc ul.sectlevel0>li>a{font-style:italic}
#toc ul.sectlevel0 ul.sectlevel1{margin:.5em 0}
#toc ul{font-family:"Open Sans","DejaVu Sans",sans-serif;list-style-type:none}
#toc a{text-decoration:none}
#toc a:active{text-decoration:underline}
#toctitle{color:#7a2518;font-size:1.2em}
@media only screen and (min-width:768px){#toctitle{font-size:1.375em}
body.toc2{padding-left:15em;padding-right:0}
#toc.toc2{margin-top:0!important;background-color:#f8f8f7;position:fixed;width:15em;left:0;top:0;border-right:1px solid #efefed;border-top-width:0!important;border-bottom-width:0!important;z-index:1000;padding:1.25em 1em;height:100%;overflow:auto}
#toc.toc2 #toctitle{margin-top:0;font-size:1.2em}
#toc.toc2>ul{font-size:.9em;margin-bottom:0}
#toc.toc2 ul ul{margin-left:0;padding-left:1em}
#toc.toc2 ul.sectlevel0 ul.sectlevel1{padding-left:0;margin-top:.5em;margin-bottom:.5em}
body.toc2.toc-right{padding-left:0;padding-right:15em}
body.toc2.toc-right #toc.toc2{border-right-width:0;border-left:1px solid #efefed;left:auto;right:0}}@media only screen and (min-width:1280px){body.toc2{padding-left:20em;padding-right:0}
#toc.toc2{width:20em}
#toc.toc2 #toctitle{font-size:1.375em}
#toc.toc2>ul{font-size:.95em}
#toc.toc2 ul ul{padding-left:1.25em}
body.toc2.toc-right{padding-left:0;padding-right:20em}}#content #toc{border-style:solid;border-width:1px;border-color:#e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;-webkit-border-radius:4px;border-radius:4px}
#content #toc>:first-child{margin-top:0}
#content #toc>:last-child{margin-bottom:0}
#footer{max-width:100%;background-color:rgba(0,0,0,.8);padding:1.25em}
#footer-text{color:rgba(255,255,255,.8);line-height:1.44}
.sect1{padding-bottom:.625em}
@media only screen and (min-width:768px){.sect1{padding-bottom:1.25em}}.sect1+.sect1{border-top:1px solid #efefed}
#content h1>a.anchor,h2>a.anchor,h3>a.anchor,#toctitle>a.anchor,.sidebarblock>.content>.title>a.anchor,h4>a.anchor,h5>a.anchor,h6>a.anchor{position:absolute;z-index:1001;width:1.5ex;margin-left:-1.5ex;display:block;text-decoration:none!important;visibility:hidden;text-align:center;font-weight:400}
#content h1>a.anchor:before,h2>a.anchor:before,h3>a.anchor:before,#toctitle>a.anchor:before,.sidebarblock>.content>.title>a.anchor:before,h4>a.anchor:before,h5>a.anchor:before,h6>a.anchor:before{content:"\00A7";font-size:.85em;display:block;padding-top:.1em}
#content h1:hover>a.anchor,#content h1>a.anchor:hover,h2:hover>a.anchor,h2>a.anchor:hover,h3:hover>a.anchor,#toctitle:hover>a.anchor,.sidebarblock>.content>.title:hover>a.anchor,h3>a.anchor:hover,#toctitle>a.anchor:hover,.sidebarblock>.content>.title>a.anchor:hover,h4:hover>a.anchor,h4>a.anchor:hover,h5:hover>a.anchor,h5>a.anchor:hover,h6:hover>a.anchor,h6>a.anchor:hover{visibility:visible}
#content h1>a.link,h2>a.link,h3>a.link,#toctitle>a.link,.sidebarblock>.content>.title>a.link,h4>a.link,h5>a.link,h6>a.link{color:#ba3925;text-decoration:none}
#content h1>a.link:hover,h2>a.link:hover,h3>a.link:hover,#toctitle>a.link:hover,.sidebarblock>.content>.title>a.link:hover,h4>a.link:hover,h5>a.link:hover,h6>a.link:hover{color:#a53221}
.audioblock,.imageblock,.literalblock,.listingblock,.stemblock,.videoblock{margin-bottom:1.25em}
.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{text-rendering:optimizeLegibility;text-align:left;font-family:"Noto Serif","DejaVu Serif",serif;font-size:1rem;font-style:italic}
table.tableblock>caption.title{white-space:nowrap;overflow:visible;max-width:0}
.paragraph.lead>p,#preamble>.sectionbody>.paragraph:first-of-type p{color:rgba(0,0,0,.85)}
table.tableblock #preamble>.sectionbody>.paragraph:first-of-type p{font-size:inherit}
.admonitionblock>table{border-collapse:separate;border:0;background:none;width:100%}
.admonitionblock>table td.icon{text-align:center;width:80px}
.admonitionblock>table td.icon img{max-width:none}
.admonitionblock>table td.icon .title{font-weight:bold;font-family:"Open Sans","DejaVu Sans",sans-serif;text-transform:uppercase}
.admonitionblock>table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #ddddd8;color:rgba(0,0,0,.6)}
.admonitionblock>table td.content>:last-child>:last-child{margin-bottom:0}
.exampleblock>.content{border-style:solid;border-width:1px;border-color:#e6e6e6;margin-bottom:1.25em;padding:1.25em;background:#fff;-webkit-border-radius:4px;border-radius:4px}
.exampleblock>.content>:first-child{margin-top:0}
.exampleblock>.content>:last-child{margin-bottom:0}
.sidebarblock{border-style:solid;border-width:1px;border-color:#e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;-webkit-border-radius:4px;border-radius:4px}
.sidebarblock>:first-child{margin-top:0}
.sidebarblock>:last-child{margin-bottom:0}
.sidebarblock>.content>.title{color:#7a2518;margin-top:0;text-align:center}
.exampleblock>.content>:last-child>:last-child,.exampleblock>.content .olist>ol>li:last-child>:last-child,.exampleblock>.content .ulist>ul>li:last-child>:last-child,.exampleblock>.content .qlist>ol>li:last-child>:last-child,.sidebarblock>.content>:last-child>:last-child,.sidebarblock>.content .olist>ol>li:last-child>:last-child,.sidebarblock>.content .ulist>ul>li:last-child>:last-child,.sidebarblock>.content .qlist>ol>li:last-child>:last-child{margin-bottom:0}
.literalblock pre,.listingblock pre:not(.highlight),.listingblock pre[class="highlight"],.listingblock pre[class^="highlight "],.listingblock pre.CodeRay,.listingblock pre.prettyprint{background:#f7f7f8}
.sidebarblock .literalblock pre,.sidebarblock .listingblock pre:not(.highlight),.sidebarblock .listingblock pre[class="highlight"],.sidebarblock .listingblock pre[class^="highlight "],.sidebarblock .listingblock pre.CodeRay,.sidebarblock .listingblock pre.prettyprint{background:#f2f1f1}
.literalblock pre,.literalblock pre[class],.listingblock pre,.listingblock pre[class]{-webkit-border-radius:4px;border-radius:4px;word-wrap:break-word;padding:1em;font-size:.8125em}
.literalblock pre.nowrap,.literalblock pre[class].nowrap,.listingblock pre.nowrap,.listingblock pre[class].nowrap{overflow-x:auto;white-space:pre;word-wrap:normal}
@media only screen and (min-width:768px){.literalblock pre,.literalblock pre[class],.listingblock pre,.listingblock pre[class]{font-size:.90625em}}@media only screen and (min-width:1280px){.literalblock pre,.literalblock pre[class],.listingblock pre,.listingblock pre[class]{font-size:1em}}.literalblock.output pre{color:#f7f7f8;background-color:rgba(0,0,0,.9)}
.listingblock pre.highlightjs{padding:0}
.listingblock pre.highlightjs>code{padding:1em;-webkit-border-radius:4px;border-radius:4px}
.listingblock pre.prettyprint{border-width:0}
.listingblock>.content{position:relative}
.listingblock code[data-lang]:before{display:none;content:attr(data-lang);position:absolute;font-size:.75em;top:.425rem;right:.5rem;line-height:1;text-transform:uppercase;color:#999}
.listingblock:hover code[data-lang]:before{display:block}
.listingblock.terminal pre .command:before{content:attr(data-prompt);padding-right:.5em;color:#999}
.listingblock.terminal pre .command:not([data-prompt]):before{content:"$"}
table.pyhltable{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.pyhltable td{vertical-align:top;padding-top:0;padding-bottom:0}
table.pyhltable td.code{padding-left:.75em;padding-right:0}
pre.pygments .lineno,table.pyhltable td:not(.code){color:#999;padding-left:0;padding-right:.5em;border-right:1px solid #ddddd8}
pre.pygments .lineno{display:inline-block;margin-right:.25em}
table.pyhltable .linenodiv{background:none!important;padding-right:0!important}
.quoteblock{margin:0 1em 1.25em 1.5em;display:table}
.quoteblock>.title{margin-left:-1.5em;margin-bottom:.75em}
.quoteblock blockquote,.quoteblock blockquote p{color:rgba(0,0,0,.85);font-size:1.15rem;line-height:1.75;word-spacing:.1em;letter-spacing:0;font-style:italic;text-align:justify}
.quoteblock blockquote{margin:0;padding:0;border:0}
.quoteblock blockquote:before{content:"\201c";float:left;font-size:2.75em;font-weight:bold;line-height:.6em;margin-left:-.6em;color:#7a2518;text-shadow:0 1px 2px rgba(0,0,0,.1)}
.quoteblock blockquote>.paragraph:last-child p{margin-bottom:0}
.quoteblock .attribution{margin-top:.5em;margin-right:.5ex;text-align:right}
.quoteblock .quoteblock{margin-left:0;margin-right:0;padding:.5em 0;border-left:3px solid rgba(0,0,0,.6)}
.quoteblock .quoteblock blockquote{padding:0 0 0 .75em}
.quoteblock .quoteblock blockquote:before{display:none}
.verseblock{margin:0 1em 1.25em 1em}
.verseblock pre{font-family:"Open Sans","DejaVu Sans",sans;font-size:1.15rem;color:rgba(0,0,0,.85);font-weight:300;text-rendering:optimizeLegibility}
.verseblock pre strong{font-weight:400}
.verseblock .attribution{margin-top:1.25rem;margin-left:.5ex}
.quoteblock .attribution,.verseblock .attribution{font-size:.9375em;line-height:1.45;font-style:italic}
.quoteblock .attribution br,.verseblock .attribution br{display:none}
.quoteblock .attribution cite,.verseblock .attribution cite{display:block;letter-spacing:-.05em;color:rgba(0,0,0,.6)}
.quoteblock.abstract{margin:0 0 1.25em 0;display:block}
.quoteblock.abstract blockquote,.quoteblock.abstract blockquote p{text-align:left;word-spacing:0}
.quoteblock.abstract blockquote:before,.quoteblock.abstract blockquote p:first-of-type:before{display:none}
table.tableblock{max-width:100%;border-collapse:separate}
table.tableblock td>.paragraph:last-child p>p:last-child,table.tableblock th>p:last-child,table.tableblock td>p:last-child{margin-bottom:0}
table.spread{width:100%}
table.tableblock,th.tableblock,td.tableblock{border:0 solid #dedede}
table.grid-all th.tableblock,table.grid-all td.tableblock{border-width:0 1px 1px 0}
table.grid-all tfoot>tr>th.tableblock,table.grid-all tfoot>tr>td.tableblock{border-width:1px 1px 0 0}
table.grid-cols th.tableblock,table.grid-cols td.tableblock{border-width:0 1px 0 0}
table.grid-all *>tr>.tableblock:last-child,table.grid-cols *>tr>.tableblock:last-child{border-right-width:0}
table.grid-rows th.tableblock,table.grid-rows td.tableblock{border-width:0 0 1px 0}
table.grid-all tbody>tr:last-child>th.tableblock,table.grid-all tbody>tr:last-child>td.tableblock,table.grid-all thead:last-child>tr>th.tableblock,table.grid-rows tbody>tr:last-child>th.tableblock,table.grid-rows tbody>tr:last-child>td.tableblock,table.grid-rows thead:last-child>tr>th.tableblock{border-bottom-width:0}
table.grid-rows tfoot>tr>th.tableblock,table.grid-rows tfoot>tr>td.tableblock{border-width:1px 0 0 0}
table.frame-all{border-width:1px}
table.frame-sides{border-width:0 1px}
table.frame-topbot{border-width:1px 0}
th.halign-left,td.halign-left{text-align:left}
th.halign-right,td.halign-right{text-align:right}
th.halign-center,td.halign-center{text-align:center}
th.valign-top,td.valign-top{vertical-align:top}
th.valign-bottom,td.valign-bottom{vertical-align:bottom}
th.valign-middle,td.valign-middle{vertical-align:middle}
table thead th,table tfoot th{font-weight:bold}
tbody tr th{display:table-cell;line-height:1.6;background:#f7f8f7}
tbody tr th,tbody tr th p,tfoot tr th,tfoot tr th p{color:rgba(0,0,0,.8);font-weight:bold}
p.tableblock>code:only-child{background:none;padding:0}
p.tableblock{font-size:1em}
td>div.verse{white-space:pre}
ol{margin-left:1.75em}
ul li ol{margin-left:1.5em}
dl dd{margin-left:1.125em}
dl dd:last-child,dl dd:last-child>:last-child{margin-bottom:0}
ol>li p,ul>li p,ul dd,ol dd,.olist .olist,.ulist .ulist,.ulist .olist,.olist .ulist{margin-bottom:.625em}
ul.unstyled,ol.unnumbered,ul.checklist,ul.none{list-style-type:none}
ul.unstyled,ol.unnumbered,ul.checklist{margin-left:.625em}
ul.checklist li>p:first-child>.fa-square-o:first-child,ul.checklist li>p:first-child>.fa-check-square-o:first-child{width:1em;font-size:.85em}
ul.checklist li>p:first-child>input[type="checkbox"]:first-child{width:1em;position:relative;top:1px}
ul.inline{margin:0 auto .625em auto;margin-left:-1.375em;margin-right:0;padding:0;list-style:none;overflow:hidden}
ul.inline>li{list-style:none;float:left;margin-left:1.375em;display:block}
ul.inline>li>*{display:block}
.unstyled dl dt{font-weight:400;font-style:normal}
ol.arabic{list-style-type:decimal}
ol.decimal{list-style-type:decimal-leading-zero}
ol.loweralpha{list-style-type:lower-alpha}
ol.upperalpha{list-style-type:upper-alpha}
ol.lowerroman{list-style-type:lower-roman}
ol.upperroman{list-style-type:upper-roman}
ol.lowergreek{list-style-type:lower-greek}
.hdlist>table,.colist>table{border:0;background:none}
.hdlist>table>tbody>tr,.colist>table>tbody>tr{background:none}
td.hdlist1{padding-right:.75em;font-weight:bold}
td.hdlist1,td.hdlist2{vertical-align:top}
.literalblock+.colist,.listingblock+.colist{margin-top:-.5em}
.colist>table tr>td:first-of-type{padding:0 .75em;line-height:1}
.colist>table tr>td:last-of-type{padding:.25em 0}
.thumb,.th{line-height:0;display:inline-block;border:solid 4px #fff;-webkit-box-shadow:0 0 0 1px #ddd;box-shadow:0 0 0 1px #ddd}
.imageblock.left,.imageblock[style*="float: left"]{margin:.25em .625em 1.25em 0}
.imageblock.right,.imageblock[style*="float: right"]{margin:.25em 0 1.25em .625em}
.imageblock>.title{margin-bottom:0}
.imageblock.thumb,.imageblock.th{border-width:6px}
.imageblock.thumb>.title,.imageblock.th>.title{padding:0 .125em}
.image.left,.image.right{margin-top:.25em;margin-bottom:.25em;display:inline-block;line-height:0}
.image.left{margin-right:.625em}
.image.right{margin-left:.625em}
a.image{text-decoration:none}
span.footnote,span.footnoteref{vertical-align:super;font-size:.875em}
span.footnote a,span.footnoteref a{text-decoration:none}
span.footnote a:active,span.footnoteref a:active{text-decoration:underline}
#footnotes{padding-top:.75em;padding-bottom:.75em;margin-bottom:.625em}
#footnotes hr{width:20%;min-width:6.25em;margin:-.25em 0 .75em 0;border-width:1px 0 0 0}
#footnotes .footnote{padding:0 .375em;line-height:1.3;font-size:.875em;margin-left:1.2em;text-indent:-1.2em;margin-bottom:.2em}
#footnotes .footnote a:first-of-type{font-weight:bold;text-decoration:none}
#footnotes .footnote:last-of-type{margin-bottom:0}
#content #footnotes{margin-top:-.625em;margin-bottom:0;padding:.75em 0}
.gist .file-data>table{border:0;background:#fff;width:100%;margin-bottom:0}
.gist .file-data>table td.line-data{width:99%}
div.unbreakable{page-break-inside:avoid}
.big{font-size:larger}
.small{font-size:smaller}
.underline{text-decoration:underline}
.overline{text-decoration:overline}
.line-through{text-decoration:line-through}
.aqua{color:#00bfbf}
.aqua-background{background-color:#00fafa}
.black{color:#000}
.black-background{background-color:#000}
.blue{color:#0000bf}
.blue-background{background-color:#0000fa}
.fuchsia{color:#bf00bf}
.fuchsia-background{background-color:#fa00fa}
.gray{color:#606060}
.gray-background{background-color:#7d7d7d}
.green{color:#006000}
.green-background{background-color:#007d00}
.lime{color:#00bf00}
.lime-background{background-color:#00fa00}
.maroon{color:#600000}
.maroon-background{background-color:#7d0000}
.navy{color:#000060}
.navy-background{background-color:#00007d}
.olive{color:#606000}
.olive-background{background-color:#7d7d00}
.purple{color:#600060}
.purple-background{background-color:#7d007d}
.red{color:#bf0000}
.red-background{background-color:#fa0000}
.silver{color:#909090}
.silver-background{background-color:#bcbcbc}
.teal{color:#006060}
.teal-background{background-color:#007d7d}
.white{color:#bfbfbf}
.white-background{background-color:#fafafa}
.yellow{color:#bfbf00}
.yellow-background{background-color:#fafa00}
span.icon>.fa{cursor:default}
.admonitionblock td.icon [class^="fa icon-"]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default}
.admonitionblock td.icon .icon-note:before{content:"\f05a";color:#19407c}
.admonitionblock td.icon .icon-tip:before{content:"\f0eb";text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111}
.admonitionblock td.icon .icon-warning:before{content:"\f071";color:#bf6900}
.admonitionblock td.icon .icon-caution:before{content:"\f06d";color:#bf3400}
.admonitionblock td.icon .icon-important:before{content:"\f06a";color:#bf0000}
.conum[data-value]{display:inline-block;color:#fff!important;background-color:rgba(0,0,0,.8);-webkit-border-radius:100px;border-radius:100px;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:"Open Sans","DejaVu Sans",sans-serif;font-style:normal;font-weight:bold}
.conum[data-value] *{color:#fff!important}
.conum[data-value]+b{display:none}
.conum[data-value]:after{content:attr(data-value)}
pre .conum[data-value]{position:relative;top:-.125em}
b.conum *{color:inherit!important}
.conum:not([data-value]):empty{display:none}
h1,h2{letter-spacing:-.01em}
dt,th.tableblock,td.content{text-rendering:optimizeLegibility}
p,td.content{letter-spacing:-.01em}
p strong,td.content strong{letter-spacing:-.005em}
p,blockquote,dt,td.content{font-size:1.0625rem}
p{margin-bottom:1.25rem}
.sidebarblock p,.sidebarblock dt,.sidebarblock td.content,p.tableblock{font-size:1em}
.exampleblock>.content{background-color:#fffef7;border-color:#e0e0dc;-webkit-box-shadow:0 1px 4px #e0e0dc;box-shadow:0 1px 4px #e0e0dc}
.print-only{display:none!important}
@media print{@page{margin:1.25cm .75cm}
*{-webkit-box-shadow:none!important;box-shadow:none!important;text-shadow:none!important}
a{color:inherit!important;text-decoration:underline!important}
a.bare,a[href^="#"],a[href^="mailto:"]{text-decoration:none!important}
a[href^="http:"]:not(.bare):after,a[href^="https:"]:not(.bare):after{content:"(" attr(href) ")";display:inline-block;font-size:.875em;padding-left:.25em}
abbr[title]:after{content:" (" attr(title) ")"}
pre,blockquote,tr,img{page-break-inside:avoid}
thead{display:table-header-group}
img{max-width:100%!important}
p,blockquote,dt,td.content{font-size:1em;orphans:3;widows:3}
h2,h3,#toctitle,.sidebarblock>.content>.title{page-break-after:avoid}
#toc,.sidebarblock,.exampleblock>.content{background:none!important}
#toc{border-bottom:1px solid #ddddd8!important;padding-bottom:0!important}
.sect1{padding-bottom:0!important}
.sect1+.sect1{border:0!important}
#header>h1:first-child{margin-top:1.25rem}
body.book #header{text-align:center}
body.book #header>h1:first-child{border:0!important;margin:2.5em 0 1em 0}
body.book #header .details{border:0!important;display:block;padding:0!important}
body.book #header .details span:first-child{margin-left:0!important}
body.book #header .details br{display:block}
body.book #header .details br+span:before{content:none!important}
body.book #toc{border:0!important;text-align:left!important;padding:0!important;margin:0!important}
body.book #toc,body.book #preamble,body.book h1.sect0,body.book .sect1>h2{page-break-before:always}
.listingblock code[data-lang]:before{display:block}
#footer{background:none!important;padding:0 .9375em}
#footer-text{color:rgba(0,0,0,.6)!important;font-size:.9em}
.hide-on-print{display:none!important}
.print-only{display:block!important}
.hide-for-print{display:none!important}
.show-for-print{display:inherit!important}}
</style>
</head>
<body class="article">
<div id="header">
<h1>The GPars Guide <span class="image" style="float: right"><img src="gpars-rgb.svg" alt="Logo" width="200"></span></h1>
</div>
<div id="content">
<div class="sect1">
<h2 id="_introduction">Introduction</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The world of mainstream computing is changing rapidly these days. If you open the hood and look under the
covers of your computer, you&#8217;ll most likely see a dual-core processor there. Or a quad-core one, if you have
a high-end computer.  We all now run our software on multi-processor systems. The code we write today and
tomorrow will probably never run on a single processor system: parallel hardware has become standard.  Not
so with the software though, at least not yet. People still create single-threaded code, even though it will
not be able to leverage the full power of current and future hardware.  Some developers experiment with
low-level concurrency primitives, like threads, and locks or synchronized blocks.  However, it has become
obvious that the shared-memory multi-threading approach used at the application level causes more trouble
than it solves. Low-level concurrency handling is usually hard to get right, and it&#8217;s not much fun either.
With such a radical change in hardware, software inevitably has to change dramatically too. Higher-level
concurrency and parallelism concepts like map/reduce, fork/join, actors and dataflow provide natural
abstractions for different types of problem domains while leveraging the multi-core hardware.</p>
</div>
<div class="sect2">
<h3 id="_enter_gpars">Enter GPars</h3>
<div class="paragraph">
<p>Meet <a href="http://gpars.codehaus.org">GPars</a>, an open-source concurrency and parallelism library for Java and
Groovy that gives you a number of high-level abstractions for writing concurrent and parallel code in Groovy
(map/reduce, fork/join, asynchronous closures, actors, agents, dataflow concurrency and other concepts),
which can make your Java and Groovy code concurrent and/or parallel with little effort.  With GPars your
Java and/or Groovy code can easily utilize all the available processors on the target system. You can run
multiple calculations at the same time, request network resources in parallel, safely solve hierarchical
divide-and-conquer problems, perform functional style map/reduce or data parallel collection processing or
build your applications around the actor or dataflow model.</p>
</div>
<div class="paragraph">
<p>The project is open sourced under the <a href="http://gpars.codehaus.org/License">Apache 2 License</a>. If you&#8217;re working
on a commercial, open-source, educational or any other type of software project in Groovy, download the
binaries or integrate them from the Maven repository and get going. The way to writing highly concurrent
and/or parallel Java and Groovy code is wide open. Enjoy!</p>
</div>
</div>
<div class="sect2">
<h3 id="_credits">Credits</h3>
<div class="paragraph">
<p>This project could not have reached the point where it stands currently without all the great help and
contribution of many individuals, who have devoted their time, energy and expertise to make GPars a solid
product. First, it is the people in the core team who should be mentioned:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Václav Pech</p>
</li>
<li>
<p>Dierk Koenig</p>
</li>
<li>
<p>Alex Tkachman</p>
</li>
<li>
<p>Russel Winder</p>
</li>
<li>
<p>Paul King</p>
</li>
<li>
<p>Jon Kerridge</p>
</li>
<li>
<p>Rafał Sławik</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Over time, many people have contributed their ideas, provided useful feedback or helped GPars in one way or
another.  There are many people in this group, too many to name them all, but let&#8217;s list at least the most
active:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Hamlet d&#8217;Arcy</p>
</li>
<li>
<p>Hans Dockter</p>
</li>
<li>
<p>Guillaume Laforge</p>
</li>
<li>
<p>Robert Fischer</p>
</li>
<li>
<p>Johannes Link</p>
</li>
<li>
<p>Graeme Rocher</p>
</li>
<li>
<p>Alex Miller</p>
</li>
<li>
<p>Jeff Gortatowsky</p>
</li>
<li>
<p>Jiří Kropáček</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Many thanks to everyone!</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_getting_started">Getting Started</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Let&#8217;s set out a few assumptions before we get started:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>You know and use Groovy and Java: otherwise you&#8217;d not be investing your valuable time studying a
concurrency and parallelism library for Groovy and Java.</p>
</li>
<li>
<p>You definitely want to write your codes employing concurrency and parallelism using Groovy and Java.</p>
</li>
<li>
<p>If you are not using Groovy for your code, you are prepared to pay the inevitable verbosity tax of using
Java.</p>
</li>
<li>
<p>You target multi-core hardware with your code.</p>
</li>
<li>
<p>You appreciate that in concurrent and parallel code things can happen at any time, in any order, and more
likely with than one thing happening at once.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>With those assumptions in place, we get started.</p>
</div>
<div class="paragraph">
<p>It&#8217;s becoming more and more obvious that dealing with concurrency and parallelism at the
thread/synchronized/lock level, as provided by the JVM, is far too low a level to be safe and comfortable.
Many high-level concepts, such as actors and dataflow have been around for quite some time: parallel
computers have been in use, at least in data centres if not on the desktop, long before multi-core chips hit
the hardware mainstream. Now then is the time to adopt these higher-level abstractions in the mainstream
software industry.  This is what <strong>GPars</strong> enables for the Groovy and Java languages, allowing Groovy and Java
programmers to use higher-level abstractions and therefore make developing concurrent and parallel software
easier and less error prone.</p>
</div>
<div class="paragraph">
<p>The concepts available in <strong>GPars</strong> can be categorized into three groups:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>Code-level helpers</em> Constructs that can be applied to small parts of the code-base such as individual
algorithms or data structures without any major changes in the overall project architecture</p>
<div class="ulist">
<ul>
<li>
<p>Parallel Collections</p>
</li>
<li>
<p>Asynchronous Processing</p>
</li>
<li>
<p>Fork/Join (Divide/Conquer)</p>
</li>
</ul>
</div>
</li>
<li>
<p><em>Architecture-level concepts</em> Constructs that need to be taken into account when designing the project
structure</p>
<div class="ulist">
<ul>
<li>
<p>Actors</p>
</li>
<li>
<p>Communicating Sequential Processes (CSP)</p>
</li>
<li>
<p>Dataflow</p>
</li>
<li>
<p>Data Parallelism</p>
</li>
</ul>
</div>
</li>
<li>
<p><em>Shared Mutable State Protection</em> Although about 95% of current use of shared mutable state can be avoided
using proper abstractions, good abstractions are still necessary for the remaining 5% use cases, when
shared mutable state cannot be avoided</p>
<div class="ulist">
<ul>
<li>
<p>Agents</p>
</li>
<li>
<p>Software Transactional Memory (not fully implemented in GPars as yet)</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="sect2">
<h3 id="_downloading_and_installing">Downloading and Installing</h3>
<div class="paragraph">
<p>GPars is now distributed as standard with Groovy.  So if you have a Groovy installation, you should have
GPars already.  The exact version of GPars you have will, of course, depend of which version of Groovy.  If
you don&#8217;t already have GPars, and you do have Groovy, then perhaps you should upgrade your Groovy!</p>
</div>
<div class="paragraph">
<p>If you do not have a Groovy installation, but get Groovy by using dependencies or just having the groovy-all
artifact, then you will need to get GPars.  Also if you want to use a version of GPars different from the
one with Groovy, or have an old GPars-less Groovy you cannot upgrade, you will need to get GPars.  The ways
of getting GPars are:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Download the artifact from a repository and add it and all the transitive dependencies manually.</p>
</li>
<li>
<p>Specify a dependency in Gradle, Maven, or Ivy (or Gant, or Ant) build files.</p>
</li>
<li>
<p>Use Grapes (especially useful for Groovy scripts).</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>If you&#8217;re building a Grails or a Griffon application, you can use the appropriate plugins to fetch the jar
files for you.</p>
</div>
<div class="sect3">
<h4 id="_the_gpars_artifact">The GPars Artifact</h4>
<div class="paragraph">
<p>As noted above GPars is now distributed as standard with Groovy.  If however, you have to manage this
dependency manually, the GPars artifact is in the main Maven repository and in the Codehaus main and
snapshots repositories.  The released versions are in the Maven and Codehaus main repositories,
the current development version (SNAPSHOT) is in the Codehaus snapshots repository.  To use from Gradle
or Grapes use the specification:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>"org.codehaus.gpars:gpars:1.3.0"</pre>
</div>
</div>
<div class="paragraph">
<p>for the release version, and:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>"org.codehaus.gpars:gpars:1.4-SNAPSHOT"</pre>
</div>
</div>
<div class="paragraph">
<p>for the development version.  You will likely need to add the Codehaus snapshots repository manually to the
search list in this latter case.  Using Maven the dependency is:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>&lt;dependency&gt;
    &lt;groupId&gt;org.codehaus.gpars&lt;/groupId&gt;
    &lt;artifactId&gt;gpars&lt;/artifactId&gt;
    &lt;version&gt;1.3.0&lt;/version&gt;
&lt;/dependency&gt;</pre>
</div>
</div>
<div class="paragraph">
<p>or version 1.4-SNAPSHOT if using the latest snapshot.</p>
</div>
</div>
<div class="sect3">
<h4 id="_transitive_dependencies">Transitive Dependencies</h4>
<div class="paragraph">
<p>GPars as a library depends on Groovy version equal to or greater than 2.3. Also, the Fork/Join concurrency
library must be available. This comes as standard with Java 7.</p>
</div>
<div class="paragraph">
<p>GPars 2.x will depend on Java 8 and will only be usable with Groovy 3.0 and later.</p>
</div>
<div class="paragraph">
<p>Please visit the page <a href="http://gpars.codehaus.org/Integration">Integration</a> on the GPars website for more
details.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_a_hello_world_example">A Hello World Example</h3>
<div class="paragraph">
<p>Once you are setup, try the following Groovy script to test that your setup is functioning as it should.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import static groovyx.gpars.actor.Actors.actor

/**
 * A demo showing two cooperating actors. The decryptor decrypts received messages
 * and replies them back.  The console actor sends a message to decrypt, prints out
 * the reply and terminates both actors.  The main thread waits on both actors to
 * finish using the join() method to prevent premature exit, since both actors use
 * the default actor group, which uses a daemon thread pool.
 * @author Dierk Koenig, Vaclav Pech
 */

def decryptor = actor {
    loop {
        react { message -&gt;
            if (message instanceof String) reply message.reverse()
            else stop()
        }
    }
}

def console = actor {
    decryptor.send 'lellarap si yvoorG'
    react {
        println 'Decrypted message: ' + it
        decryptor.send false
    }
}

[decryptor, console]*.join()</pre>
</div>
</div>
<div class="paragraph">
<p>You should get a message "Decrypted message: Groovy is parallel" printed out on the console when you run the code.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">Java API</div>
<div class="paragraph">
<p>GPars has been designed primarily for use with the Groovy programming language.  Of course all Java and
Groovy programs are just bytecodes running on the JVM, so GPars can be used with Java source.  Despite being
aimed at Groovy code use, the solid technical foundation, plus the good performance characteristics, of
GPars make it an excellent library for Java programs. In fact most of GPars is written in Java, so there is
no performance penalty for Java applications using GPars.</p>
</div>
<div class="paragraph">
<p>For details please refer to the Java API section.</p>
</div>
</div>
</div>
<div class="paragraph">
<p>To quick-test using GPars via the Java API, you can compile and run the following Java code:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.MessagingRunnable;
import groovyx.gpars.actor.DynamicDispatchActor;

public class StatelessActorDemo {
    public static void main(String[] args) throws InterruptedException {
        final MyStatelessActor actor = new MyStatelessActor();
        actor.start();
        actor.send("Hello");
        actor.sendAndWait(10);
        actor.sendAndContinue(10.0, new MessagingRunnable&lt;String&gt;() {
            @Override protected void doRun(final String s) {
                System.out.println("Received a reply " + s);
            }
        });
    }
}

class MyStatelessActor extends DynamicDispatchActor {
    public void onMessage(final String msg) {
        System.out.println("Received " + msg);
        replyIfExists("Thank you");
    }

    public void onMessage(final Integer msg) {
        System.out.println("Received a number " + msg);
        replyIfExists("Thank you");
    }

    public void onMessage(final Object msg) {
        System.out.println("Received an object " + msg);
        replyIfExists("Thank you");
    }
}</pre>
</div>
</div>
<div class="paragraph">
<p>Remember though that you will almost certainly have to add the Groovy artifact to the build as well as the
GPars artifact.  GPars may well work at Java speeds with Java applications, but it still has some
compilation dependencies on Groovy.</p>
</div>
</div>
<div class="sect2">
<h3 id="_code_conventions">Code Conventions</h3>
<div class="paragraph">
<p>We follow certain conventions in the code samples. Understanding these may help you read and comprehend
GPars code samples better.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The <em>leftShift</em> operator <em>&lt;&lt;</em> has been overloaded on actors, agents and dataflow expressions (both
variables and streams) to mean <em>send</em> a message or <em>assign</em> a value.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre>myActor &lt;&lt; 'message'

myAgent &lt;&lt; {account -&gt; account.add('5 USD')}

myDataflowVariable &lt;&lt; 120332</pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>On actors and agents the default <em>call()</em> method has been also overloaded to mean <em>send</em> . So sending a
message to an actor or agent may look like a regular method call.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre>myActor "message"

myAgent {house -&gt; house.repair()}</pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>The <em>rightShift</em> operator <em>&gt;&gt;</em> in GPars has the <em>when bound</em> meaning. So</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre> myDataflowVariable &gt;&gt; {value -&gt; doSomethingWith(value)}</pre>
</div>
</div>
<div class="paragraph">
<p>will schedule the closure to run only after <em>myDataflowVariable</em> is bound to a value, with the value as a parameter.</p>
</div>
<div class="paragraph">
<p>In samples we tend to statically import frequently used factory methods:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>GParsPool.withPool()</p>
</li>
<li>
<p>GParsPool.withExistingPool()</p>
</li>
<li>
<p>GParsExecutorsPool.withPool()</p>
</li>
<li>
<p>GParsExecutorsPool.withExistingPool()</p>
</li>
<li>
<p>Actors.actor()</p>
</li>
<li>
<p>Actors.reactor()</p>
</li>
<li>
<p>Actors.fairReactor()</p>
</li>
<li>
<p>Actors.messageHandler()</p>
</li>
<li>
<p>Actors.fairMessageHandler()</p>
</li>
<li>
<p>Agent.agent()</p>
</li>
<li>
<p>Agent.fairAgent()</p>
</li>
<li>
<p>Dataflow.task()</p>
</li>
<li>
<p>Dataflow.operator()</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>It is more a matter of style preferences and personal taste, but we think static imports make the code more compact and readable.</p>
</div>
</div>
<div class="sect2">
<h3 id="_getting_set_up_in_an_ide">Getting Set Up In An IDE</h3>
<div class="paragraph">
<p>Adding the GPars jar files to your project or defining the appropriate dependencies in pom.xml should be
enough to get you started with GPars in your IDE.</p>
</div>
<div class="sect3">
<h4 id="_gpars_dsl_recognition">GPars DSL recognition</h4>
<div class="paragraph">
<p><strong>IntelliJ IDEA</strong> in both the free <em>Community Edition</em> and the commercial <em>Ultimate Edition</em> will recognize
the GPars domain specific languages, complete methods like <em>eachParallel()</em> , <em>reduce()</em> or <em>callAsync()</em>
and validate them. GPars uses the
<a href="http://www.jetbrains.net/confluence/display/GRVY/Scripting+IDE+for+DSL+awareness">Groovy DSL</a> mechanism,
which teaches IntelliJ IDEA the DSLs as soon as the GPars jar file is added to the project.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_applicability_of_concepts">Applicability of Concepts</h3>
<div class="paragraph">
<p>GPars provides a lot of concepts to pick from. We&#8217;re continuously building and updating a page that tries to
help user choose the right abstraction for their tasks at hands.  Please, refer to the
<a href="http://gpars.codehaus.org/Concepts+compared">Concepts Compared</a> page for details.</p>
</div>
<div class="paragraph">
<p>To briefly summarize the suggestions, below you can find the basic guide-lines:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>You&#8217;re looking at a collection, which needs to be <strong>iterated</strong> or processed using one of the many beautiful
Groovy collections method, like <em>each()</em> , <em>collect()</em> , <em>find()</em> and such. Proposing that processing each
element of the collection is independent of the other items, using GPars <strong>parallel collections</strong> can be
recommended.</p>
</li>
<li>
<p>If you have a <strong>long-lasting calculation</strong> , which may safely run in the background, use the <strong>asynchronous
invocation support</strong> in GPars. Since the GPars asynchronous functions can be composed, you can quickly
parallelize complex functional calculations without having to mark independent calculations explicitly.</p>
</li>
<li>
<p>You need to <strong>parallelize</strong> an algorithm at hand. You can identify a set of <strong>tasks</strong> with their mutual
dependencies. The tasks typically do not need to share data, but instead some tasks may need to wait for
other tasks to finish before starting. You&#8217;re ready to express these dependencies explicitly in code. With
GPars <strong>dataflow tasks</strong> you create internally sequential tasks, each of which can run concurrently with the
others. Dataflow variables and channels provide the tasks with the capability to express their
dependencies and to exchange data safely.</p>
</li>
<li>
<p>You can&#8217;t avoid using <strong>shared mutable state</strong> in your algorithm. Multiple threads will be accessing shared
data and (some of them) modifying it. Traditional locking and synchronized approach feels too risky or
unfamiliar. Go for <strong>agents</strong>, which will wrap your data and serialize all access to it.</p>
</li>
<li>
<p>You&#8217;re building a system with high concurrency demands. Tweaking a data structure here or task there won&#8217;t
cut it. You need to build the architecture from the ground up with concurrency in mind. <strong>Message-passing</strong>
might be the way to go.</p>
<div class="ulist">
<ul>
<li>
<p><strong>Groovy CSP</strong> will give you highly deterministic and composable model for concurrent processes. The model
is organized around the concept of <strong>calculations</strong> or <strong>processes</strong>, which run concurrently and communicate
through synchronous channels.</p>
</li>
<li>
<p>If you&#8217;re trying to solve a complex data-processing problem, consider GPars <strong>dataflow operators</strong> to build
a data flow network. The concept is organized around event-driven transformations wired into pipelines
using asynchronous channels.</p>
</li>
<li>
<p><strong>Actors</strong> and <strong>Active Objects</strong> will shine if you need to build a general-purpose, highly concurrent and
scalable architecture following the object-oriented paradigm.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p>Now you may have a better idea of what concepts to use on your current project. Go and check out more
details on them in the User Guide.</p>
</div>
</div>
<div class="sect2">
<h3 id="_what_s_new">What&#8217;s New</h3>
<div class="paragraph">
<p>The new GPars 1.3.0 release introduces several enhancements and improvements on top of the previous release,
mainly in the dataflow area.</p>
</div>
<div class="paragraph">
<p>Check out the <a href="http://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=12030&amp;version=20355">JIRA release notes</a></p>
</div>
<div class="sect3">
<h4 id="_project_changes">Project changes</h4>
<div class="sidebarblock">
<div class="content">
<div class="title">Breaking Changes</div>
<div class="paragraph">
<p>See "the Breaking Changes listing":http://gpars.codehaus.org/Breaking+Changes for the list of breaking changes.</p>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_asynchronous_functions">Asynchronous functions</h4>

</div>
<div class="sect3">
<h4 id="_parallel_collections">Parallel collections</h4>

</div>
<div class="sect3">
<h4 id="_fork_join">Fork / Join</h4>

</div>
<div class="sect3">
<h4 id="_actors">Actors</h4>
<div class="ulist">
<ul>
<li>
<p>Remote actors</p>
</li>
<li>
<p>Exception propagation from active objects</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_dataflow">Dataflow</h4>
<div class="ulist">
<ul>
<li>
<p>Remote dataflow variables and channels</p>
</li>
<li>
<p>Dataflow operators accepting variable number arguments</p>
</li>
<li>
<p>Select made @CompileStatic compatible</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_agent">Agent</h4>
<div class="ulist">
<ul>
<li>
<p>Remote agents</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_stm">Stm</h4>

</div>
<div class="sect3">
<h4 id="_other">Other</h4>
<div class="ulist">
<ul>
<li>
<p>Raised the JDK dependency to version 1.7</p>
</li>
<li>
<p>Raised the Groovy dependency to version 2.2</p>
</li>
<li>
<p>Replaced the jsr-177y fork-join pool implementation with the one from JDK 1.7</p>
</li>
<li>
<p>Removed the dependency on jsr-166y</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_renaming_hints">Renaming hints</h4>

</div>
</div>
<div class="sect2">
<h3 id="_java_api_using_gpars_from_java">Java API – Using GPars from Java</h3>
<div class="paragraph">
<p>Using GPars is very addictive, I guarantee. Once you get hooked you won&#8217;t be able to code without it.  May
the world force you to write code in Java, you will still be able to benefit from most of GPars features.</p>
</div>
<div class="sect3">
<h4 id="_java_api_specifics">Java API specifics</h4>
<div class="paragraph">
<p>Some parts of GPars are irrelevant in Java and it is better to use the underlying Java libraries directly:
* Parallel Collection – use jsr-166y library&#8217;s Parallel Array directly
* Fork/Join – use jsr-166y library&#8217;s Fork/Join support directly
* Asynchronous functions – use Java executor services directly</p>
</div>
<div class="paragraph">
<p>The other parts of GPars can be used from Java just like from Groovy, although most will miss the Groovy DSL capabilities.</p>
</div>
</div>
<div class="sect3">
<h4 id="_gpars_closures_in_java_api">GPars Closures in Java API</h4>
<div class="paragraph">
<p>To overcome the lack of closures as a language element in Java and to avoid forcing users to use Groovy closures directly
through the Java API, a few handy wrapper classes have been provided to help you define callbacks, actor body or dataflow tasks.
* groovyx.gpars.MessagingRunnable - used for single-argument callbacks or actor body
* groovyx.gpars.ReactorMessagingRunnable - used for ReactiveActor body
* groovyx.gpars.DataflowMessagingRunnable - used for dataflow operators' body</p>
</div>
<div class="paragraph">
<p>These classes can be used in all places GPars API expects a Groovy closure.</p>
</div>
</div>
<div class="sect3">
<h4 id="_actors_2">Actors</h4>
<div class="paragraph">
<p>The <em>DynamicDispatchActor</em> as well as the <em>ReactiveActor</em> classes can be used just like in Groovy:</p>
</div>
<div class="listingblock">
<div class="content">
<pre> import groovyx.gpars.MessagingRunnable;
 import groovyx.gpars.actor.DynamicDispatchActor;

 public class StatelessActorDemo {
     public static void main(String[] args) throws InterruptedException {
         final MyStatelessActor actor = new MyStatelessActor();
         actor.start();
         actor.send("Hello");
         actor.sendAndWait(10);
         actor.sendAndContinue(10.0, new MessagingRunnable&lt;String&gt;() {
             @Override protected void doRun(final String s) {
                 System.out.println("Received a reply " + s);
             }
         });
     }
 }

 class MyStatelessActor extends DynamicDispatchActor {
     public void onMessage(final String msg) {
         System.out.println("Received " + msg);
         replyIfExists("Thank you");
     }

     public void onMessage(final Integer msg) {
         System.out.println("Received a number " + msg);
         replyIfExists("Thank you");
     }

     public void onMessage(final Object msg) {
         System.out.println("Received an object " + msg);
         replyIfExists("Thank you");
     }
 }</pre>
</div>
</div>
<div class="paragraph">
<p>Although there are not many differences between Groovy and Java GPars use, notice, the callbacks
instantiating the MessagingRunnable class in place for a groovy closure.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovy.lang.Closure;
import groovyx.gpars.ReactorMessagingRunnable;
import groovyx.gpars.actor.Actor;
import groovyx.gpars.actor.ReactiveActor;

public class ReactorDemo {
    public static void main(final String[] args) throws InterruptedException {
        final Closure handler = new ReactorMessagingRunnable&lt;Integer, Integer&gt;() {
            @Override protected Integer doRun(final Integer integer) {
                return integer * 2;
            }
        };
        final Actor actor = new ReactiveActor(handler);
        actor.start();

        System.out.println("Result: " +  actor.sendAndWait(1));
        System.out.println("Result: " +  actor.sendAndWait(2));
        System.out.println("Result: " +  actor.sendAndWait(3));
    }
}</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_convenience_factory_methods">Convenience factory methods</h4>
<div class="paragraph">
<p>Obviously, all the essential factory methods to build actors quickly are available where you&#8217;d expect them.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovy.lang.Closure;
import groovyx.gpars.ReactorMessagingRunnable;
import groovyx.gpars.actor.Actor;
import groovyx.gpars.actor.Actors;

public class ReactorDemo {
    public static void main(final String[] args) throws InterruptedException {
        final Closure handler = new ReactorMessagingRunnable&lt;Integer, Integer&gt;() {
            @Override protected Integer doRun(final Integer integer) {
                return integer * 2;
            }
        };
        final Actor actor = Actors.reactor(handler);

        System.out.println("Result: " +  actor.sendAndWait(1));
        System.out.println("Result: " +  actor.sendAndWait(2));
        System.out.println("Result: " +  actor.sendAndWait(3));
    }
}</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_agents">Agents</h4>
<div class="listingblock">
<div class="content">
<pre> import groovyx.gpars.MessagingRunnable;
 import groovyx.gpars.agent.Agent;

 public class AgentDemo {
     public static void main(final String[] args) throws InterruptedException {
         final Agent counter = new Agent&lt;Integer&gt;(0);
         counter.send(10);
         System.out.println("Current value: " + counter.getVal());
         counter.send(new MessagingRunnable&lt;Integer&gt;() {
             @Override protected void doRun(final Integer integer) {
                 counter.updateValue(integer + 1);
             }
         });
         System.out.println("Current value: " + counter.getVal());
     }
 }</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_dataflow_concurrency">Dataflow Concurrency</h4>
<div class="paragraph">
<p>Both <em>DataflowVariables</em> and <em>DataflowQueues</em> can be used from Java without any hiccups. Just avoid the
handy overloaded operators and go straight to the methods, like <em>bind</em> , <em>whenBound</em>, <em>getVal</em> and other.
You may also continue using dataflow <em>tasks</em> passing to them instances of <em>Runnable</em> or <em>Callable</em> just like
groovy <em>Closure</em> .</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.MessagingRunnable;
import groovyx.gpars.dataflow.DataflowVariable;
import groovyx.gpars.group.DefaultPGroup;

import java.util.concurrent.Callable;

public class DataflowTaskDemo {
    public static void main(final String[] args) throws InterruptedException {
        final DefaultPGroup group = new DefaultPGroup(10);

        final DataflowVariable a = new DataflowVariable();

        group.task(new Runnable() {
            public void run() {
                a.bind(10);
            }
        });

        final Promise result = group.task(new Callable() {
            public Object call() throws Exception {
                return (Integer)a.getVal() + 10;
            }
        });

        result.whenBound(new MessagingRunnable&lt;Integer&gt;() {
            @Override protected void doRun(final Integer integer) {
                System.out.println("arguments = " + integer);
            }
        });

        System.out.println("result = " + result.getVal());
    }
}</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_dataflow_operators">Dataflow operators</h4>
<div class="paragraph">
<p>The sample below should illustrate the main differences between Groovy and Java API for dataflow operators.
* Use the convenience factory methods accepting list of channels to create operators or selectors
* Use <em>DataflowMessagingRunnable</em> to specify the operator body
* Call <em>getOwningProcessor()</em> to get hold of the operator from within the body in order to e.g. bind output values</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.DataflowMessagingRunnable;
import groovyx.gpars.dataflow.Dataflow;
import groovyx.gpars.dataflow.DataflowQueue;
import groovyx.gpars.dataflow.operator.DataflowProcessor;

import java.util.Arrays;
import java.util.List;

public class DataflowOperatorDemo {
    public static void main(final String[] args) throws InterruptedException {
        final DataflowQueue stream1 = new DataflowQueue();
        final DataflowQueue stream2 = new DataflowQueue();
        final DataflowQueue stream3 = new DataflowQueue();
        final DataflowQueue stream4 = new DataflowQueue();

        final DataflowProcessor op1 = Dataflow.selector(Arrays.asList(stream1), Arrays.asList(stream2), new DataflowMessagingRunnable(1) {
            @Override protected void doRun(final Object... objects) {
                getOwningProcessor().bindOutput(2*(Integer)objects[0]);
            }
        });

        final List secondOperatorInput = Arrays.asList(stream2, stream3);

        final DataflowProcessor op2 = Dataflow.operator(secondOperatorInput, Arrays.asList(stream4), new DataflowMessagingRunnable(2) {
            @Override protected void doRun(final Object... objects) {
                getOwningProcessor().bindOutput((Integer) objects[0] + (Integer) objects[1]);
            }
        });

        stream1.bind(1);
        stream1.bind(2);
        stream1.bind(3);
        stream3.bind(100);
        stream3.bind(100);
        stream3.bind(100);
        System.out.println("Result: " + stream4.getVal());
        System.out.println("Result: " + stream4.getVal());
        System.out.println("Result: " + stream4.getVal());
        op1.stop();
        op2.stop();
    }
}</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_performance">Performance</h4>
<div class="paragraph">
<p>In general, GPars overhead is identical irrespective of whether you use it from Groovy or Java and tends to
be very low.  GPars actors, for example, can compete head-to-head with other JVM actor options, like Scala
actors.</p>
</div>
<div class="paragraph">
<p>Since Groovy code in general runs slower than Java code, mainly due to dynamic method invocation, you might
consider writing your code in Java to improve performance. Typically numeric operations or frequent
fine-grained method calls within a task or actor body may benefit from a rewrite into Java.</p>
</div>
</div>
<div class="sect3">
<h4 id="_prerequisites">Prerequisites</h4>
<div class="paragraph">
<p>All the GPars integration rules apply to Java projects just like they do to Groovy projects. You only need
to include the groovy distribution jar file in your project and all is clear to march ahead.  You may also
want to check out the sample Java Maven project to get tips on how to integrate GPars into a maven-based
pure Java application – <a href="http://gpars.codehaus.org/Demos">Sample Java Maven Project</a></p>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_data_parallelism">Data Parallelism</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Focusing on data instead of processes helps create robust concurrent programs. You as a programmer define
your data together with functions that should be applied to it and then let the underlying machinery process
the data.  Typically a set of concurrent tasks will be created and submitted to a thread pool for
processing.</p>
</div>
<div class="paragraph">
<p>In GPars the <strong>GParsPool</strong> and <strong>GParsExecutorsPool</strong> classes give you access to low-level data parallelism
techniques.  The <strong>GParsPool</strong> class relies on the Fork/Join implementation introduced in JDK 7 and offers
excellent functionality and performance. The <strong>GParsExecutorsPool</strong> is provided for those who still need to
use the older Java executors.</p>
</div>
<div class="paragraph">
<p>There are three fundamental domains covered by the GPars low-level data parallelism:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Processing collections concurrently.</p>
</li>
<li>
<p>Running functions (closures) asynchronously.</p>
</li>
<li>
<p>Performing Fork/Join (Divide/Conquer) algorithms.</p>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
The API described here is based on using GPars with JDK7. It can be used with later JDKs, but JDK8
introduced the Streams framework which can be used directly from Groovy and in essence replaces the GPars
features covered here. There is work underway to provide the API described here based on the JDK8 Streams
framework for use with JDK8 and later to provide a simple upgrade path.
</td>
</tr>
</table>
</div>
<div class="sect2">
<h3 id="_parallel_collections_2">Parallel Collections</h3>
<div class="paragraph">
<p>Dealing with data frequently involves manipulating collections. Lists, arrays, sets, maps, iterators,
strings and lot of other data types can be viewed as collections of items.  The common pattern to process
such collections is to take elements sequentially, one-by-one, and make an action for each of the items
in row.</p>
</div>
<div class="paragraph">
<p>Take, for example, the <em>min</em> function, which is supposed to return the smallest element of a
collection. When you call the <em>min</em> method on a collection of numbers, a variable (<em>minVal</em> say) is create
to store the smallest value seen so far, initialized to some reasonable value of the given type, for example
for integers and floating point this may well be zero. The elements of the collection are then iterated
through with each being compared to the stored value. Should a value be less than the one currently held in
<em>minVal</em> then <em>minVal</em> is changed to store the newly seen smaller value. Once all elements have been
processed, the minimum value in the collection is stored in the <em>minVal</em> .</p>
</div>
<div class="paragraph">
<p>This algorithm, however simple, is <strong>totally wrong</strong> on multi-core and multi-processor hardware. Running the
<em>min</em> function on a dual-core chip can leverage <strong>at most 50%</strong> of the computing power of the chip.  On a
quad-core it would be only 25%. In this latter case, this algorithm effectively wastes 75% of the computing
power of the chip.</p>
</div>
<div class="paragraph">
<p>Tree-like structures proved to be more appropriate for parallel processing. The <em>min</em> function in our
example doesn&#8217;t need to iterate through all the elements in row and compare their values with the
<em>minVal</em> variable.  What it can do instead is relying on the multi-core/multi-processor nature of your
hardware. A <em>parallel_min</em> function can, for example, compare pairs (or tuples of certain size) of
neighboring values in the collection and promote the smallest value from the tuple into a next round of
comparison. Searching for minimum in different tuples can safely happen in parallel and so tuples in the
same round can be processed by different cores at the same time without races or contention among threads.</p>
</div>
<div class="sect3">
<h4 id="_meet_parallel_arrays">Meet Parallel Arrays</h4>
<div class="paragraph">
<p>Although not part of JDK7, the extra166y library brings a very convenient abstraction called
 <a href="http://groovy.dzone.com/articles/parallelize-your-arrays-with-j">Parallel Arrays</a>, and GPars has harnessed
 this to provide a very Groovy API.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
extra166y was never made part of the JDK&#8201;&#8212;&#8201;unlike the jsr166y library. In fact extra166y has been
made redundant from JDK8 onwards by the Streams framework.  So as to continue to support JDK7, GPars has a
copy of extra166y in it so there is no external dependency. As noted earlier, there is work underway to rewrite the
GPars API in terms of Streams for users of JDK8 onwards. Of course people using JDK8 onwards can simply use
Streams directly from Groovy.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>GPars leverages the
Parallel Arrays implementation in several ways. The <strong>GParsPool</strong> and <strong>GParsExecutorsPool</strong> classes provide
parallel variants of the common Groovy iteration methods like <em>each</em> , <em>collect</em> , <em>findAll</em> and
such.</p>
</div>
<div class="listingblock">
<div class="content">
<pre> def selfPortraits = images.findAllParallel{it.contains me}.collectParallel{it.resize()}</pre>
</div>
</div>
<div class="paragraph">
<p>It also allows for a more functional style map/reduce collection processing.</p>
</div>
<div class="listingblock">
<div class="content">
<pre> def smallestSelfPortrait = images.parallel.filter{it.contains me}.map{it.resize()}.min{it.sizeInMB}</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_gparspool">GParsPool</h4>
<div class="paragraph">
<p>Use of <strong>GParsPool</strong>&#8201;&#8212;&#8201;the JSR-166y based concurrent collection processor</p>
</div>
<div class="sect4">
<h5 id="_usage_of_gparspool">Usage of GParsPool</h5>
<div class="paragraph">
<p>The <strong>GParsPool</strong> class enables a <strong>ParallelArray</strong>-based (from JSR-166y) concurrency DSL for collections and
objects.</p>
</div>
<div class="paragraph">
<p>Examples of use:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>// Summarize numbers concurrently.
GParsPool.withPool {
    final AtomicInteger result = new AtomicInteger(0)
    [1, 2, 3, 4, 5].eachParallel{result.addAndGet(it)}
    assert 15 == result
}

// Multiply numbers asynchronously.
GParsPool.withPool {
    final List result = [1, 2, 3, 4, 5].collectParallel{it * 2}
    assert ([2, 4, 6, 8, 10].equals(result))
}</pre>
</div>
</div>
<div class="paragraph">
<p>The passed-in closure takes an instance of a ForkJoinPool as a parameter, which can be then used freely inside the closure.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>// Check whether all elements within a collection meet certain criteria.
GParsPool.withPool(5){ForkJoinPool pool -&gt;
    assert [1, 2, 3, 4, 5].everyParallel{it &gt; 0}
    assert ![1, 2, 3, 4, 5].everyParallel{it &gt; 1}
}</pre>
</div>
</div>
<div class="paragraph">
<p>The <em>GParsPool.withPool</em> method takes optional parameters for number of threads in the created pool and an
unhandled exception handler.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>withPool(10){...}
withPool(20, exceptionHandler){...}</pre>
</div>
</div>
<div class="paragraph">
<p>The <em>GParsPool.withExistingPool</em> takes an already existing ForkJoinPool instance to reuse.  The DSL is valid
only within the associated block of code and only for the thread that has called the <em>withPool</em> or
<em>withExistingPool</em> methods. The <em>withPool</em> method returns only after all the worker threads have finished
their tasks and the pool has been destroyed, returning back the return value of the associated block of
code. The <em>withExistingPool</em> method doesn&#8217;t wait for the pool threads to finish.</p>
</div>
<div class="paragraph">
<p>Alternatively, the <strong>GParsPool</strong> class can be statically imported <em>import static groovyx.gpars.GParsPool</em>,
which will allow omitting the <strong>GParsPool</strong> class name.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>withPool {
    assert [1, 2, 3, 4, 5].everyParallel{it &gt; 0}
    assert ![1, 2, 3, 4, 5].everyParallel{it &gt; 1}
}</pre>
</div>
</div>
<div class="paragraph">
<p>The following methods are currently supported on all objects in Groovy:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>eachParallel</em></p>
</li>
<li>
<p><em>eachWithIndexParallel</em></p>
</li>
<li>
<p><em>collectParallel</em></p>
</li>
<li>
<p><em>collectManyParallel</em></p>
</li>
<li>
<p><em>findAllParallel</em></p>
</li>
<li>
<p><em>findAnyParallel</em></p>
</li>
<li>
<p><em>findParallel</em></p>
</li>
<li>
<p><em>everyParallel</em></p>
</li>
<li>
<p><em>anyParallel</em></p>
</li>
<li>
<p><em>grepParallel</em></p>
</li>
<li>
<p><em>groupByParallel</em></p>
</li>
<li>
<p><em>foldParallel</em></p>
</li>
<li>
<p><em>minParallel</em></p>
</li>
<li>
<p><em>maxParallel</em></p>
</li>
<li>
<p><em>sumParallel</em></p>
</li>
<li>
<p><em>splitParallel</em></p>
</li>
<li>
<p><em>countParallel</em></p>
</li>
<li>
<p><em>foldParallel</em></p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="_meta_class_enhancer">Meta-class enhancer</h5>
<div class="paragraph">
<p>As an alternative you can use the <strong>ParallelEnhancer</strong> class to enhance meta-classes of any classes or
individual instances with the parallel methods.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.ParallelEnhancer

def list = [1, 2, 3, 4, 5, 6, 7, 8, 9]
ParallelEnhancer.enhanceInstance(list)
println list.collectParallel {it * 2 }

def animals = ['dog', 'ant', 'cat', 'whale']
ParallelEnhancer.enhanceInstance animals
println (animals.anyParallel {it ==~ /ant/} ? 'Found an ant' : 'No ants found')
println (animals.everyParallel {it.contains('a')} ? 'All animals contain a' : 'Some animals can live without an a')</pre>
</div>
</div>
<div class="paragraph">
<p>When using the <strong>ParallelEnhancer</strong> class, you&#8217;re not restricted to a <em>withPool</em> block with the use of the
GParsPool DSLs. The enhanced classed or instances remain enhanced till they get garbage collected.</p>
</div>
</div>
<div class="sect4">
<h5 id="_exception_handling">Exception handling</h5>
<div class="paragraph">
<p>If an exception is thrown while processing any of the passed-in closures, the first exception gets re-thrown
from the xxxParallel methods and the algorithm stops as soon as possible.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>The exception handling mechanism of GParsPool builds on the one built into the Fork/Join framework. Since
Fork/Join algorithms are by nature hierarchical, once any part of the algorithm fails, there&#8217;s usually
little benefit from continuing the computation, since some branches of the algorithm will never return a
result.</p>
</div>
<div class="paragraph">
<p>Bear in mind that the GParsPool implementation doesn&#8217;t give any guarantees about its behavior after a first
unhandled exception occurs, beyond stopping the algorithm and re-throwing the first detected exception to
the caller.  This behavior, after all, is consistent with what the traditional sequential iteration
methods do.</p>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_transparently_parallel_collections">Transparently parallel collections</h5>
<div class="paragraph">
<p>On top of adding new <em>xxxParallel</em> methods, GPars can also let you change the semantics of the original
iteration methods. For example, you may be passing a collection into a library method, which will process
your collection in a sequential way, let say using the <em>collect</em> method. By changing the semantics of the
<em>collect</em> method on your collection you can effectively parallelize the library sequential code.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>GParsPool.withPool {

    //The selectImportantNames() will process the name collections concurrently
    assert ['ALICE', 'JASON'] == selectImportantNames(['Joe', 'Alice', 'Dave', 'Jason'].makeConcurrent())
}

/**
 * A function implemented using standard sequential collect() and findAll() methods.
 */
def selectImportantNames(names) {
    names.collect {it.toUpperCase()}.findAll{it.size() &gt; 4}
}</pre>
</div>
</div>
<div class="paragraph">
<p>The <em>makeSequential</em> method will reset the collection back to the original sequential semantics.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import static groovyx.gpars.GParsPool.withPool

def list = [1, 2, 3, 4, 5, 6, 7, 8, 9]

println 'Sequential: ' list.each { print it + ',' } println()

withPool {

    println 'Sequential: '
    list.each { print it + ',' }
    println()

    list.makeConcurrent()

    println 'Concurrent: '
    list.each { print it + ',' }
    println()

    list.makeSequential()

    println 'Sequential: '
    list.each { print it + ',' }
    println()
}

println 'Sequential: '
list.each { print it + ',' }
println()</pre>
</div>
</div>
<div class="paragraph">
<p>The <em>asConcurrent()</em> convenience method will allow you to specify code blocks, in which the collection
maintains concurrent semantics.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import static groovyx.gpars.GParsPool.withPool

def list = [1, 2, 3, 4, 5, 6, 7, 8, 9]

println 'Sequential: '
list.each { print it + ',' }
println()

withPool {

    println 'Sequential: '
    list.each { print it + ',' }
    println()

    list.asConcurrent {
        println 'Concurrent: '
        list.each { print it + ',' }
        println()
    }

    println 'Sequential: '
    list.each { print it + ',' }
    println()
}

println 'Sequential: '
list.each { print it + ',' }
println()</pre>
</div>
</div>
<div class="paragraph">
<p>Transparent parallelizm, including the <em>makeConcurrent()</em> , <em>makeSequential()</em> and <em>asConcurrent()</em> methods,
is also available in combination with <em>ParallelEnhancer</em> .</p>
</div>
<div class="listingblock">
<div class="content">
<pre>/**
 * A function implemented using standard sequential collect() and findAll() methods.
 */
def selectImportantNames(names) {
    names.collect {it.toUpperCase()}.findAll{it.size() &gt; 4}
}

def names = ['Joe', 'Alice', 'Dave', 'Jason']
ParallelEnhancer.enhanceInstance(names)
//The selectImportantNames() will process the name collections concurrently
assert ['ALICE', 'JASON'] == selectImportantNames(names.makeConcurrent())</pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.ParallelEnhancer

def list = [1, 2, 3, 4, 5, 6, 7, 8, 9]

println 'Sequential: '
list.each { print it + ',' }
println()

ParallelEnhancer.enhanceInstance(list)

println 'Sequential: '
list.each { print it + ',' }
println()

list.asConcurrent {
    println 'Concurrent: '
    list.each { print it + ',' }
    println()

}
list.makeSequential()

println 'Sequential: '
list.each { print it + ',' }
println()</pre>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_avoid_side_effects_in_functions">Avoid side-effects in functions</h4>
<div class="paragraph">
<p>We have to warn you. Since the closures that are provided to the parallel methods like <em>eachParallel</em> or
<em>collectParallel()</em> may be run in parallel, you have to make sure that each of the closures is written in a
thread-safe manner. The closures must hold no internal state, share data nor have side-effects beyond the
boundaries the single element that they&#8217;ve been invoked on.  Violations of these rules will open the door
for race conditions and deadlocks, the most severe enemies of a modern multi-core programmer.</p>
</div>
<div class="paragraph">
<p><strong>Don&#8217;t do this:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre>def thumbnails = []
images.eachParallel {thumbnails &lt;&lt; it.thumbnail}  //Concurrently accessing a not-thread-safe collection of thumbnails, don't do this!</pre>
</div>
</div>
<div class="paragraph">
<p>At least, you&#8217;ve been warned.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>Because <strong>GParsPool</strong> uses a <strong>Fork/Join</strong> pool (with work stealing), threads may
not be applied to a waiting processing task even though they may appear
idle. With a work-stealing algorithm, worker threads that run out of things
to do can steal tasks from other threads that are still busy.</p>
</div>
<div class="paragraph">
<p>if you use <strong>GParsExecutorsPool</strong> , which doesn&#8217;t use <strong>Fork/Join</strong>, you get the
thread allocation behavior that you would naively expect.</p>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_gparsexecutorspool">GParsExecutorsPool</h4>
<div class="paragraph">
<p>Use of GParsExecutorsPool - the Java Executors' based concurrent collection processor</p>
</div>
</div>
<div class="sect3">
<h4 id="_usage_of_gparsexecutorspool">Usage of GParsExecutorsPool</h4>
<div class="paragraph">
<p>The <strong>GParsPool</strong> class enables a Java Executors-based concurrency DSL for collections and objects.</p>
</div>
<div class="paragraph">
<p>The <strong>GParsExecutorsPool</strong> class can be used as a pure-JDK-based collection parallel processor. Unlike the
<strong>GParsPool</strong> class, <strong>GParsExecutorsPool</strong> doesn&#8217;t require fork/join thread pools, but leverages the standard
JDK executor services to parallelize closures processing a collections or an object iteratively.  It needs
to be states, however, that <strong>GParsPool</strong> performs typically much better than <strong>GParsExecutorsPool</strong> does.</p>
</div>
<div class="paragraph">
<p>Examples of use:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>//multiply numbers asynchronously
 GParsExecutorsPool.withPool {
     Collection&lt;Future&gt; result = [1, 2, 3, 4, 5].collectParallel{it * 10}
     assert new HashSet([10, 20, 30, 40, 50]) == new HashSet((Collection)result*.get())
 }

 //multiply numbers asynchronously using an asynchronous closure
 GParsExecutorsPool.withPool {
     def closure={it * 10}
     def asyncClosure=closure.async()
     Collection&lt;Future&gt; result = [1, 2, 3, 4, 5].collect(asyncClosure)
     assert new HashSet([10, 20, 30, 40, 50]) == new HashSet((Collection)result*.get())
 }</pre>
</div>
</div>
<div class="paragraph">
<p>The passed-in closure takes an instance of a ExecutorService as a parameter, which can be then used freely
inside the closure.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>//find an element meeting specified criteria
 GParsExecutorsPool.withPool(5) {ExecutorService service -&gt;
     service.submit({performLongCalculation()} as Runnable)
 }</pre>
</div>
</div>
<div class="paragraph">
<p>The <em>GParsExecutorsPool.withPool()</em> method takes optional parameters for number of threads in the created pool and a thread factory.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>withPool(10) {...}
withPool(20, threadFactory) {...}</pre>
</div>
</div>
<div class="paragraph">
<p>The <em>GParsExecutorsPool.withExistingPool()</em> takes an already existing executor service instance to
reuse. The DSL is valid only within the associated block of code and only for the thread that has called the
<em>withPool()</em> or <em>withExistingPool()</em> method. The <em>withPool()</em> method returns only after all the worker
threads have finished their tasks and the executor service has been destroyed, returning back the return
value of the associated block of code. The <em>withExistingPool()</em> method doesn&#8217;t wait for the executor service
threads to finish.</p>
</div>
<div class="paragraph">
<p>Alternatively, the <strong>GParsExecutorsPool</strong> class can be statically imported <em>import static groovyx.gpars.GParsExecutorsPool.`<strong>`</em>, which will allow omitting the *GParsExecutorsPool</strong> class name.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>withPool {
     def result = [1, 2, 3, 4, 5].findParallel{Number number -&gt; number &gt; 2}
     assert result in [3, 4, 5]
 }</pre>
</div>
</div>
<div class="paragraph">
<p>The following methods on all objects, which support iterations in Groovy, are currently supported:
* eachParallel()
* eachWithIndexParallel()
* collectParallel()
* findAllParallel()
* findParallel()
* allParallel()
* anyParallel()
* grepParallel()
* groupByParallel()</p>
</div>
<div class="sect4">
<h5 id="_meta_class_enhancer_2">Meta-class enhancer</h5>
<div class="paragraph">
<p>As an alternative you can use the <em>GParsExecutorsPoolEnhancer</em> class to enhance meta-classes for any classes
or individual instances with asynchronous methods.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.GParsExecutorsPoolEnhancer

def list = [1, 2, 3, 4, 5, 6, 7, 8, 9]
GParsExecutorsPoolEnhancer.enhanceInstance(list)
println list.collectParallel {it * 2 }

def animals = ['dog', 'ant', 'cat', 'whale']
GParsExecutorsPoolEnhancer.enhanceInstance animals
println (animals.anyParallel {it ==~ /ant/} ? 'Found an ant' : 'No ants found')
println (animals.allParallel {it.contains('a')} ? 'All animals contain a' : 'Some animals can live without an a')</pre>
</div>
</div>
<div class="paragraph">
<p>When using the <em>GParsExecutorsPoolEnhancer</em> class, you&#8217;re not restricted to a <em>withPool()</em> block with the
use of the GParsExecutorsPool DSLs. The enhanced classed or instances remain enhanced till they get garbage
collected.</p>
</div>
</div>
<div class="sect4">
<h5 id="_exception_handling_2">Exception handling</h5>
<div class="paragraph">
<p>If exceptions are thrown while processing any of the passed-in closures, an instance of <em>AsyncException</em>
wrapping all the original exceptions gets re-thrown from the xxxParallel methods.</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_avoid_side_effects_in_functions_2">Avoid side-effects in functions</h4>
<div class="paragraph">
<p>Once again we need to warn you about using closures with side-effects effecting objects beyond the scope of
the single currently processed element or closures which keep state. Don&#8217;t do that! It is dangerous to pass
them to any of the <em>xxxParallel()</em> methods.</p>
</div>
</div>
<div class="sect3">
<h4 id="_memoize">Memoize</h4>
<div class="paragraph">
<p>The <em>memoize</em> function enables caching of function&#8217;s return values. Repeated calls to the memoized function
with the same argument values will, instead of invoking the calculation encoded in the original function,
retrieve the result value from an internal transparent cache.  Provided the calculation is considerably
slower than retrieving a cached value from the cache, this allows users to trade-off memory for performance.
Checkout out the example, where we attempt to scan multiple websites for particular content:</p>
</div>
<div class="paragraph">
<p>The memoize functionality of GPars has been contributed to Groovy in version 1.8 and if you run on Groovy
1.8 or later, it is recommended to use the Groovy functionality.  Memoize in GPars is almost identical,
except that it searches the memoize caches concurrently using the surrounding thread pool and so may give
performance benefits in some scenarios.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>The GPars memoize functionality has been renamed to avoid future conflicts with the memoize functionality in Groovy.
GPars now calls the methods with a preceding letter <em>g</em> , such as gmemoize().</p>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_examples_of_use">Examples of use</h4>
<div class="listingblock">
<div class="content">
<pre>GParsPool.withPool {
    def urls = ['http://www.dzone.com', 'http://www.theserverside.com', 'http://www.infoq.com']
    Closure download = {url -&gt;
        println "Downloading $url"
        url.toURL().text.toUpperCase()
    }
    Closure cachingDownload = download.gmemoize()

    println 'Groovy sites today: ' + urls.findAllParallel {url -&gt; cachingDownload(url).contains('GROOVY')}
    println 'Grails sites today: ' + urls.findAllParallel {url -&gt; cachingDownload(url).contains('GRAILS')}
    println 'Griffon sites today: ' + urls.findAllParallel {url -&gt; cachingDownload(url).contains('GRIFFON')}
    println 'Gradle sites today: ' + urls.findAllParallel {url -&gt; cachingDownload(url).contains('GRADLE')}
    println 'Concurrency sites today: ' + urls.findAllParallel {url -&gt; cachingDownload(url).contains('CONCURRENCY')}
    println 'GPars sites today: ' + urls.findAllParallel {url -&gt; cachingDownload(url).contains('GPARS')}
}</pre>
</div>
</div>
<div class="paragraph">
<p>Notice closures are enhanced inside the <em>GParsPool.withPool()</em> blocks with a <em>memoize()</em> function, which
returns a new closure wrapping the original closure with a cache.  In the example we&#8217;re calling the
<em>cachingDownload</em> function in several places in the code, however, each unique url gets downloaded only
once - the first time it is needed. The values are then cached and available for subsequent calls. And also
to all threads, no matter which thread originally came first with a download request for the particular url
and had to handle the actual calculation/download.</p>
</div>
<div class="paragraph">
<p>So, to wrap up, memoize shields a function by a cache of past return values. However, <em>memoize</em> can do even
more. In some algorithms adding a little memory may have dramatic impact on the computational complexity of
the calculation. Let&#8217;s look at a classical example of Fibonacci numbers.</p>
</div>
</div>
<div class="sect3">
<h4 id="_fibonacci_example">Fibonacci example</h4>
<div class="paragraph">
<p>A purely functional, recursive implementation, following closely the definition of Fibonacci numbers is
exponentially complex:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>Closure fib = {n -&gt; n &gt; 1 ? call(n - 1) + call(n - 2) : n}</pre>
</div>
</div>
<div class="paragraph">
<p>Try calling the <em>fib</em> function with numbers around 30 and you&#8217;ll see how slow it is.</p>
</div>
<div class="paragraph">
<p>Now with a little twist and added memoize cache the algorithm magically turns into a linearly complex one:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>Closure fib
fib = {n -&gt; n &gt; 1 ? fib(n - 1) + fib(n - 2) : n}.gmemoize()</pre>
</div>
</div>
<div class="paragraph">
<p>The extra memory we added cut off all but one recursive branches of the calculation. And all subsequent
calls to the same <em>fib</em> function will also benefit from the cached values.</p>
</div>
<div class="paragraph">
<p>Also, see below, how the <em>memoizeAtMost</em> variant can reduce memory consumption in our example, yet preserve
the linear complexity of the algorithm.</p>
</div>
</div>
<div class="sect3">
<h4 id="_available_variants">Available variants</h4>
<div class="sect4">
<h5 id="_memoize_2">memoize</h5>
<div class="paragraph">
<p>The basic variant, which keeps values in the internal cache for the whole lifetime of the memoized
function. Provides the best performance characteristics of all the variants.</p>
</div>
</div>
<div class="sect4">
<h5 id="_memoizeatmost">memoizeAtMost</h5>
<div class="paragraph">
<p>Allows the user to set a hard limit on number of items cached. Once the limit has been reached, all
subsequently added values will eliminate the oldest value from the cache using the LRU (Last Recently Used)
strategy.</p>
</div>
<div class="paragraph">
<p>So for our Fibonacci number example, we could safely reduce the cache size to two items:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>Closure fib
fib = {n -&gt; n &gt; 1 ? fib(n - 1) + fib(n - 2) : n}.memoizeAtMost(2)</pre>
</div>
</div>
<div class="paragraph">
<p>Setting an upper limit on the cache size may have two purposes:
* Keep the memory footprint of the cache within defined boundaries
* Preserve desired performance characteristics of the function. Too large caches may take longer to retrieve
  the cached value than it would have taken to calculate the result directly.</p>
</div>
</div>
<div class="sect4">
<h5 id="_memoizeatleast">memoizeAtLeast</h5>
<div class="paragraph">
<p>Allows unlimited growth of the internal cache until the JVM&#8217;s garbage collector decides to step in and evict
SoftReferences, used by our implementation, from the memory. The single parameter value to the
<em>memoizeAtLeast()</em> method specifies the minimum number of cached items that should be protected from gc
eviction. The cache will never shrink below the specified number of entries.  The cache ensures it only
protects the most recently used items from eviction using the LRU (Last Recently Used) strategy.</p>
</div>
</div>
<div class="sect4">
<h5 id="_memoizebetween">memoizeBetween</h5>
<div class="paragraph">
<p>Combines memoizeAtLeast and memoizeAtMost and so allowing the cache to grow and shrink in the range between
the two parameter values depending on available memory and the gc activity, yet the cache size will never
exceed the upper size limit to preserve desired performance characteristics of the cache.</p>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_map_reduce">Map-Reduce</h3>
<div class="paragraph">
<p>The Parallel Collection Map/Reduce DSL gives GPars a more functional flavor. In general, the Map/Reduce DSL
may be used for the same purpose as the <em>xxxParallel()</em> family methods and has very similar semantics.  On
the other hand, Map/Reduce can perform considerably faster, if you need to chain multiple methods to process
a single collection in multiple steps:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>    println 'Number of occurrences of the word GROOVY today: ' + urls.parallel
            .map {it.toURL().text.toUpperCase()}
            .filter {it.contains('GROOVY')}
            .map{it.split()}
            .map{it.findAll{word -&gt; word.contains 'GROOVY'}.size()}
            .sum()</pre>
</div>
</div>
<div class="paragraph">
<p>The <em>xxxParallel()</em> methods have to follow the contract of their non-parallel peers. So a
<em>collectParallel()</em> method must return a legal collection of items, which you can again treat as a Groovy
collection.  Internally the parallel collect method builds an efficient parallel structure, called parallel
array, performs the required operation concurrently and before returning destroys the Parallel Array
building the collection of results to return to you.  A potential call to let say <em>findAllParallel()</em> on the
resulting collection would repeat the whole process of construction and destruction of a Parallel Array
instance under the covers.</p>
</div>
<div class="paragraph">
<p>With Map/Reduce you turn your collection into a Parallel Array and back only once. The Map/Reduce family of
methods do not return Groovy collections, but are free to pass along the internal Parallel Arrays directly.
Invoking the <em>parallel</em> property on a collection will build a Parallel Array for the collection and return a
thin wrapper around the Parallel Array instance.  Then you can chain all required methods like:
* map()
* reduce()
* filter()
* size()
* sum()
* min()
* max()
* sort()
* groupBy()
* combine()</p>
</div>
<div class="paragraph">
<p>Returning back to a plain Groovy collection instance is always just a matter of retrieving the <em>collection</em>
property.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def myNumbers = (1..1000).parallel.filter{it % 2 == 0}.map{Math.sqrt it}.collection</pre>
</div>
</div>
<div class="sect3">
<h4 id="_avoid_side_effects_in_functions_3">Avoid side-effects in functions</h4>
<div class="paragraph">
<p>Once again we need to warn you. To avoid nasty surprises, please, keep your closures, which you pass to the
Map/Reduce functions, stateless and clean from side-effects.</p>
</div>
<div class="sect4">
<h5 id="_availability">Availability</h5>
<div class="paragraph">
<p>This feature is only available when using in the Fork/Join-based <strong>GParsPool</strong> , not in <strong>GParsExecutorsPool</strong> .</p>
</div>
</div>
<div class="sect4">
<h5 id="_classical_example">Classical Example</h5>
<div class="paragraph">
<p>A classical example, inspired by <a href="http://github.com/thevery" class="bare">http://github.com/thevery</a>, counting occurrences of words in a string:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import static groovyx.gpars.GParsPool.withPool

def words = "This is just a plain text to count words in"
print count(words)

def count(arg) {
  withPool {
    return arg.parallel
      .map{[it, 1]}
      .groupBy{it[0]}.getParallel()
      .map {it.value=it.value.size();it}
      .sort{-it.value}.collection
  }
}</pre>
</div>
</div>
<div class="paragraph">
<p>The same example, now implemented the more general <em>combine</em> operation:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def words = "This is just a plain text to count words in"
print count(words)

def count(arg) {
  withPool {
    return arg.parallel
      .map{[it, 1]}
      .combine(0) {sum, value -&gt; sum + value}.getParallel()
      .sort{-it.value}.collection
  }
}</pre>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_combine">Combine</h4>
<div class="paragraph">
<p>The <em>combine</em> operation expects on its input a list of tuples (two-element lists) considered to be key-value
pairs (such as [ [key1, value1], [key2, value2], [key1, value3], [key3, value4] &#8230;&#8203; ] ) with potentially
repeating keys. When invoked, <em>combine</em> merges the values for identical keys using the provided accumulator
function and produces a map mapping the original (unique) keys to their accumulated values.  E.g. [[a, b],
[c, d], [a, e], [c, f]] will be combined into [a : b+e, c : d+f], while the '+' operation on the values
needs to be provided by the user as the accumulation closure.</p>
</div>
<div class="paragraph">
<p>The <em>accumulation function</em> argument needs to specify a function to use for combining (accumulating) the
values belonging to the same key.  An <em>initial accumulator value</em> needs to be provided as well. Since the
<em>combine</em> method processes items in parallel, the <em>initial accumulator value</em> will be reused multiple times.
Thus the provided value must allow for reuse. It should be either a <strong>cloneable</strong> or <strong>immutable</strong> value or a
<strong>closure</strong> returning a fresh initial accumulator each time requested.  Good combinations of accumulator
functions and reusable initial values include:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>accumulator = {List acc, value -&gt; acc &lt;&lt; value} initialValue = []
accumulator = {List acc, value -&gt; acc &lt;&lt; value} initialValue = {-&gt; []}
accumulator = {int sum, int value -&gt; acc + value} initialValue = 0
accumulator = {int sum, int value -&gt; sum + value} initialValue = {-&gt; 0}
accumulator = {ShoppingCart cart, Item value -&gt; cart.addItem(value)} initialValue = {-&gt; new ShoppingCart()}</pre>
</div>
</div>
<div class="paragraph">
<p>The return type is a map.
E.g. [['he', 1], ['she', 2], ['he', 2], ['me', 1], ['she', 5], ['he', 1]] with the initial value provided a 0
will be combined into ['he' : 4, 'she' : 7, 'me' : 1]</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>The keys will be mutually compared using their equals and hashCode methods. Consider using <em>\@Canonical</em> or <em>\@EqualsAndHashCode</em>
to annotate classes that you use as keys. Just like with all hash maps in Groovy, be sure you&#8217;re using a String not a GString as a key!</p>
</div>
</div>
</div>
<div class="paragraph">
<p>For more involved scenarios when you <em>combine()</em> complex objects, a good strategy here is to have a class
that can be used as a key for the common use cases and apply different keys for uncommon cases.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovy.transform.ToString
import groovy.transform.TupleConstructor

import static groovyx.gpars.GParsPool.withPool

@TupleConstructor @ToString
class PricedCar implements Cloneable {
    String model
    String color
    Double price

    boolean equals(final o) {
        if (this.is(o)) return true
        if (getClass() != o.class) return false

        final PricedCar pricedCar = (PricedCar) o

        if (color != pricedCar.color) return false
        if (model != pricedCar.model) return false

        return true
    }

    int hashCode() {
        int result
        result = (model != null ? model.hashCode() : 0)
        result = 31 * result + (color != null ? color.hashCode() : 0)
        return result
    }

    @Override
    protected Object clone() {
        return super.clone()
    }
}

def cars = [new PricedCar('F550', 'blue', 2342.223),
        new PricedCar('F550', 'red', 234.234),
        new PricedCar('Da', 'white', 2222.2),
        new PricedCar('Da', 'white', 1111.1)]

withPool {
    //Combine by model
    def result =
        cars.parallel.map {
            [it.model, it]
        }.combine(new PricedCar('', 'N/A', 0.0)) {sum, value -&gt;
            sum.model = value.model
            sum.price += value.price
            sum
        }.values()

    println result


    //Combine by model and color (the PricedCar's equals and hashCode))
    result =
        cars.parallel.map {
            [it, it]
        }.combine(new PricedCar('', 'N/A', 0.0)) {sum, value -&gt;
            sum.model = value.model
            sum.color = value.color
            sum.price += value.price
            sum
        }.values()

    println result
}</pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_parallel_arrays">Parallel Arrays</h3>
<div class="paragraph">
<p>As an alternative, the efficient tree-based data structures defines in JSR-166y can be used directly. The
<em>parallelArray</em> property on any collection or object will return a <em>ParallelArray</em> instance holding the
elements of the original collection, which then can be manipulated through the jsr166y API. Please refer to
the jsr166y documentation for the API details.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.extra166y.Ops

groovyx.gpars.GParsPool.withPool {
    assert 15 == [1, 2, 3, 4, 5].parallelArray.reduce({a, b -&gt; a + b} as Ops.Reducer, 0)                                        //summarize
    assert 55 == [1, 2, 3, 4, 5].parallelArray.withMapping({it ** 2} as Ops.Op).reduce({a, b -&gt; a + b} as Ops.Reducer, 0)       //summarize squares
    assert 20 == [1, 2, 3, 4, 5].parallelArray.withFilter({it % 2 == 0} as Ops.Predicate)                                       //summarize squares of even numbers
            .withMapping({it ** 2} as Ops.Op)
            .reduce({a, b -&gt; a + b} as Ops.Reducer, 0)

    assert 'aa:bb:cc:dd:ee' == 'abcde'.parallelArray                                                                            //concatenate duplicated characters with separator
            .withMapping({it * 2} as Ops.Op)
            .reduce({a, b -&gt; "$a:$b"} as Ops.Reducer, "")</pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_asynchronous_invocation">Asynchronous Invocation</h3>
<div class="paragraph">
<p>Running long-lasting tasks in the background belongs to the activities, the need for which arises quite
frequently. Your main thread of execution wants to initialize a few calculations, downloads, searches or
such, however, the results may not be needed immediately. GPars gives the developers the tools to schedule
the asynchronous activities for processing in the background and collect the results once they&#8217;re needed.</p>
</div>
<div class="sect3">
<h4 id="_usage_of_gparspool_and_gparsexecutorspool_asynchronous_processing_facilities">Usage of GParsPool and GParsExecutorsPool asynchronous processing facilities</h4>
<div class="paragraph">
<p>Both <strong>GParsPool</strong> and <strong>GParsExecutorsPool</strong> provide almost identical services in this domain, although they
leverage different underlying machinery, based on which of the two classes the user chooses.</p>
</div>
<div class="sect4">
<h5 id="_closures_enhancements">Closures enhancements</h5>
<div class="paragraph">
<p>The following methods are added to closures inside the <em>GPars(Executors)Pool.withPool()</em> blocks:
* async() - Creates an asynchronous variant of the supplied closure, which when invoked returns a future for
  the potential return value
* callAsync() - Calls a closure in a separate thread supplying the given arguments, returning a future for
  the potential return value,</p>
</div>
<div class="paragraph">
<p>Examples:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>GParsPool.withPool() {
    Closure longLastingCalculation = {calculate()}
    Closure fastCalculation = longLastingCalculation.async()  //create a new closure, which starts the original closure on a thread pool
    Future result=fastCalculation()                           //returns almost immediately
    //do stuff while calculation performs ...
    println result.get()
}</pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre>GParsPool.withPool() {
    /**
     * The callAsync() method is an asynchronous variant of the default call() method to invoke a closure.
     * It will return a Future for the result value.
     */
    assert 6 == {it * 2}.call(3)
    assert 6 == {it * 2}.callAsync(3).get()
}</pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_timeouts">Timeouts</h5>
<div class="paragraph">
<p>The <em>callTimeoutAsync()</em> methods, taking either a long value or a Duration instance, allow the user to have
the calculation cancelled after a given time interval.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>{-&gt;
    while(true) {
        Thread.sleep 1000  //Simulate a bit of interesting calculation
        if (Thread.currentThread().isInterrupted()) break;  //We've been cancelled
    }
}.callTimeoutAsync(2000)</pre>
</div>
</div>
<div class="paragraph">
<p>In order to allow cancellation, the asynchronously running code must keep checking the <em>interrupted</em> flag of
its own thread and cease the calculation once the flag is set to true.</p>
</div>
</div>
<div class="sect4">
<h5 id="_executor_service_enhancements">Executor Service enhancements</h5>
<div class="paragraph">
<p>The ExecutorService and ForkJoinPool class is enhanced with the &lt;&lt; (leftShift) operator to submit tasks to
the pool and return a <em>Future</em> for the result.</p>
</div>
<div class="paragraph">
<p>Example:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>GParsExecutorsPool.withPool {ExecutorService executorService -&gt;
    executorService &lt;&lt; {println 'Inside parallel task'}
}</pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_running_functions_closures_in_parallel">Running functions (closures) in parallel</h5>
<div class="paragraph">
<p>The <strong>GParsPool</strong> and <strong>GParsExecutorsPool</strong> classes also provide handy methods <em>executeAsync()</em> and
<em>executeAsyncAndWait()</em> to easily run multiple closures asynchronously.</p>
</div>
<div class="paragraph">
<p>Example:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>GParsPool.withPool {
    assert [10, 20] == GParsPool.executeAsyncAndWait({calculateA()}, {calculateB()}         //waits for results
    assert [10, 20] == GParsPool.executeAsync({calculateA()}, {calculateB()})*.get()  //returns Futures instead and doesn't wait for results to be calculated
}</pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_composable_asynchronous_functions">Composable Asynchronous Functions</h3>
<div class="paragraph">
<p>Functions are to be composed. In fact, composing side-effect-free functions is very easy. Much easier and
reliable than composing objects, for example.  Given the same input, functions always return the same
result, they never change their behavior unexpectedly nor they break when multiple threads call them at the
same time.  h3. Functions in Groovy We can treat Groovy closures as functions. They take arguments, do their
calculation and return a value. Provided you don&#8217;t let your closures touch anything outside their scope,
your closures are well-behaved pure functions. Functions that you can combine for a better good.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def sum = (0..100000).inject(0, {a, b -&gt; a + b})</pre>
</div>
</div>
<div class="paragraph">
<p>For example, by combining a function adding two numbers with the <em>inject</em> function, which iterates through
the whole collection, you can quickly summarize all items. Then, replacing the <em>adding</em> function with a
<em>comparison</em> function will immediately give you a combined function calculating maximum.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def max = myNumbers.inject(0, {a, b -&gt; a&gt;b?a:b})</pre>
</div>
</div>
<div class="paragraph">
<p>You see, functional programming is popular for a reason.</p>
</div>
<div class="sect3">
<h4 id="_are_we_concurrent_yet">Are we concurrent yet?</h4>
<div class="paragraph">
<p>This all works just fine until you realize you&#8217;re not utilizing the full power of your expensive
hardware. The functions are plain sequential.  No parallelism in here. All but one processor core do
nothing, they&#8217;re idle, totally wasted.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>Those paying attention would suggest to use the <em>Parallel Collection</em> techniques described earlier and they
would certainly be correct.  For our scenario described here, where we process a collection, using those
<em>parallel</em> methods would be the best choice.  However, we&#8217;re now looking for a <strong>generic way to create and
combine asynchronous functions</strong> , which would help us not only for collection processing but mostly in other
more generic cases, like the one right below.</p>
</div>
</div>
</div>
<div class="paragraph">
<p>To make things more obvious, here&#8217;s an example of combining four functions, which are supposed to check
whether a particular web page matches the contents of a local file.  We need to download the page, load the
file, calculate hashes of both and finally compare the resulting numbers.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>Closure download = {String url -&gt;
    url.toURL().text
}

Closure loadFile = {String fileName -&gt;
    ...  //load the file here
}

Closure hash = {s -&gt; s.hashCode()}

Closure compare = {int first, int second -&gt;
    first == second
}

def result = compare(hash(download('http://www.gpars.org')), hash(loadFile('/coolStuff/gpars/website/index.html')))
println "The result of comparison: " + result</pre>
</div>
</div>
<div class="paragraph">
<p>We need to download the page, load up the file, calculate hashes of both and finally compare the resulting
numbers.  Each of the functions is responsible for one particular job. One downloads the content, second
loads the file, third calculates the hashes and finally the fourth one will do the comparison. Combining the
functions is as simple as nesting their calls.</p>
</div>
<div class="sect4">
<h5 id="_making_it_all_asynchronous">Making it all asynchronous</h5>
<div class="paragraph">
<p>The downside of our code is that we don&#8217;t leverage the independence of the <em>download()</em> and the <em>loadFile()</em>
functions.  Neither we allow the two hashes to be run concurrently. They could well run in parallel, but our
way to combine functions restricts any parallelism.</p>
</div>
<div class="paragraph">
<p>Obviously not all of the functions can run concurrently. Some functions depend on results of others. They
cannot start before the other function finishes.  We need to block them till their parameters are
available. The <em>hash()</em> functions needs a string to work on. The <em>compare()</em> function needs two numbers to
compare.</p>
</div>
<div class="paragraph">
<p>So we can only parallelize some functions, while blocking parallelism of others. Seems like a challenging
task.</p>
</div>
</div>
<div class="sect4">
<h5 id="_things_are_bright_in_the_functional_world">Things are bright in the functional world</h5>
<div class="paragraph">
<p>Luckily, the dependencies between functions are already expressed implicitly in the code. There&#8217;s no need
for us to duplicate the dependency information.  If one functions takes parameters and the parameters need
first to be calculated by another function, we implicitly have a dependency here. The <em>hash()</em> function
depends on the <em>loadFile()</em> as well as on the <em>download()</em> functions in our example.  The <em>inject</em> function
in our earlier example depends on the results of the <em>addition</em> functions invoked gradually on all the
elements of the collection.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>However difficult it may seem at first, our task is in fact very simple. We only need to teach our functions
to return <em>promises</em> of their future results. And we need to teach the other functions to accept those
<em>promises</em> as parameters so that they wait for the real values before they start their work.  And if we
convince the functions to release the threads they hold while waiting for the values, we get directly to
where the magic can happen.</p>
</div>
</div>
</div>
<div class="paragraph">
<p>In the good tradition of <em>GPars</em> we&#8217;ve made it very straightforward for you to convince any function to
believe in other functions' promises. Call the <em>asyncFun()</em> function on a closure and you&#8217;re asynchronous.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>withPool {
    def maxPromise = numbers.inject(0, {a, b -&gt; a&gt;b?a:b}.asyncFun())
    println "Look Ma, I can talk to the user while the math is being done for me!"
    println maxPromise.get()
}</pre>
</div>
</div>
<div class="paragraph">
<p>The <em>inject</em> function doesn&#8217;t really care what objects are being returned from the <em>addition</em> function,
maybe it is just a little surprised that each call to the <em>addition</em> function returns so fast, but doesn&#8217;t
moan much, keeps iterating and finally returns the overall result to you.</p>
</div>
<div class="paragraph">
<p>Now, this is the time you should stand behind what you say and do what you want others to do. Don&#8217;t frown at
the result and just accepts that you got back just a promise.  A <strong>promise</strong> to get the result delivered as
soon as the calculation is done. The extra heat coming out of your laptop is an indication the calculation
exploits natural parallelism in your functions and makes its best effort to deliver the result to you
quickly.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>The <em>promise</em> is a good old <em>DataflowVariable</em> , so you may query its status, register notification hooks or
make it an input to a Dataflow algorithm.</p>
</div>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre>withPool {
    def sumPromise = (0..100000).inject(0, {a, b -&gt; a + b}.asyncFun())
    println "Are we done yet? " + sumPromise.bound
    sumPromise.whenBound {sum -&gt; println sum}
}</pre>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>The <em>get()</em> method has also a variant with a timeout parameter, if you want to avoid the risk of waiting
indefinitely.</p>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_can_things_go_wrong">Can things go wrong?</h5>
<div class="paragraph">
<p>Sure. But you&#8217;ll get an exception thrown from the result promise <em>get()</em> method.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>try {
    sumPromise.get()
} catch (MyCalculationException e) {
    println "Guess, things are not ideal today."
}</pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_this_is_all_fine_but_what_functions_can_be_really_combined">This is all fine, but what functions can be really combined?</h5>
<div class="paragraph">
<p>There are no limits. Take any sequential functions you need to combine and you should be able to combine
their asynchronous variants as well.</p>
</div>
<div class="paragraph">
<p>Back to our initial example comparing content of a file with a web page, we simply make all the functions
asynchronous by calling the <em>asyncFun()</em> method on them and we are ready to set off.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>    Closure download = {String url -&gt;
        url.toURL().text
    }.asyncFun()

    Closure loadFile = {String fileName -&gt;
        ...  //load the file here
    }.asyncFun()

    Closure hash = {s -&gt; s.hashCode()}.asyncFun()

    Closure compare = {int first, int second -&gt;
        first == second
    }.asyncFun()

    def result = compare(hash(download('http://www.gpars.org')), hash(loadFile('/coolStuff/gpars/website/index.html')))
    println 'Allowed to do something else now'
    println "The result of comparison: " + result.get()</pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_calling_asynchronous_functions_from_within_asynchronous_functions">Calling asynchronous functions from within asynchronous functions</h5>
<div class="paragraph">
<p>Another very valuable characteristics of asynchronous functions is that their result promises can also be
composed.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import static groovyx.gpars.GParsPool.withPool

  withPool {
      Closure plus = {Integer a, Integer b -&gt;
          sleep 3000
          println 'Adding numbers'
          a + b
      }.asyncFun()

      Closure multiply = {Integer a, Integer b -&gt;
          sleep 2000
          a * b
      }.asyncFun()

      Closure measureTime = {-&gt;
          sleep 3000
          4
      }.asyncFun()

      Closure distance = {Integer initialDistance, Integer velocity, Integer time -&gt;
          plus(initialDistance, multiply(velocity, time))
      }.asyncFun()

      Closure chattyDistance = {Integer initialDistance, Integer velocity, Integer time -&gt;
          println 'All parameters are now ready - starting'
          println 'About to call another asynchronous function'
          def innerResultPromise = plus(initialDistance, multiply(velocity, time))
          println 'Returning the promise for the inner calculation as my own result'
          return innerResultPromise
      }.asyncFun()

      println "Distance = " + distance(100, 20, measureTime()).get() + ' m'
      println "ChattyDistance = " + chattyDistance(100, 20, measureTime()).get() + ' m'
  }</pre>
</div>
</div>
<div class="paragraph">
<p>If an asynchronous function (e.f. the <em>distance</em> function in the example) in its body calls another
asynchronous function (e.g. <em>plus</em> ) and returns the the promise of the invoked function, the inner
function&#8217;s ( <em>plus</em> ) result promise will compose with the outer function&#8217;s ( <em>distance</em> ) result
promise. The inner function ( <em>plus</em> ) will now bind its result to the outer function&#8217;s ( <em>distance</em> )
promise, once the inner function (plus) finishes its calculation.  This ability of promises to compose
allows functions to cease their calculation without blocking a thread not only when waiting for parameters,
but also whenever they call another asynchronous function anywhere in their body.</p>
</div>
</div>
<div class="sect4">
<h5 id="_methods_as_asynchronous_functions">Methods as asynchronous functions</h5>
<div class="paragraph">
<p>Methods can be referred to as closures using the <em>.&amp;</em> operator. These closures can then be transformed using
<em>asyncFun</em> into composable asynchronous functions just like ordinary closures.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>class DownloadHelper {
    String download(String url) {
        url.toURL().text
    }

    int scanFor(String word, String text) {
        text.findAll(word).size()
    }

    String lower(s) {
        s.toLowerCase()
    }
}
//now we'll make the methods asynchronous
withPool {
    final DownloadHelper d = new DownloadHelper()
    Closure download = d.&amp;download.asyncFun()
    Closure scanFor = d.&amp;scanFor.asyncFun()
    Closure lower = d.&amp;lower.asyncFun()

    //asynchronous processing
    def result = scanFor('groovy', lower(download('http://www.infoq.com')))
    println 'Allowed to do something else now'
    println result.get()
}</pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_using_annotation_to_create_asynchronous_functions">Using annotation to create asynchronous functions</h5>
<div class="paragraph">
<p>Instead of calling the <em>asyncFun()</em> function, the <em>@AsyncFun</em> annotation can be used to annotate
Closure-typed fields.  The fields have to be initialized in-place and the containing class needs to be
instantiated withing a <em>withPool</em> block.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import static groovyx.gpars.GParsPool.withPool
import groovyx.gpars.AsyncFun

class DownloadingSearch {
    @AsyncFun Closure download = {String url -&gt;
        url.toURL().text
    }

    @AsyncFun Closure scanFor = {String word, String text -&gt;
        text.findAll(word).size()
    }

    @AsyncFun Closure lower = {s -&gt; s.toLowerCase()}

    void scan() {
        def result = scanFor('groovy', lower(download('http://www.infoq.com')))  //synchronous processing
        println 'Allowed to do something else now'
        println result.get()
    }
}

withPool {
    new DownloadingSearch().scan()
}</pre>
</div>
</div>
<div class="sect5">
<h6 id="_alternative_pools">Alternative pools</h6>
<div class="paragraph">
<p>The <em>AsyncFun</em> annotation by default uses an instance of <strong>GParsPool</strong> from the wrapping withPool block. You
may, however, specify the type of pool explicitly:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>@AsyncFun(GParsExecutorsPoolUtil) def sum6 = {a, b -&gt; a + b }</pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="_blocking_functions_through_annotations">Blocking functions through annotations</h6>
<div class="paragraph">
<p>The <em>AsyncFun</em> also allows the user to specify, whether the resulting function should have blocking (true)
or non-blocking (false - default) semantics.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>@AsyncFun(blocking = true)
def sum = {a, b -&gt; a + b }</pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="_explicit_and_delayed_pool_assignment">Explicit and delayed pool assignment</h6>
<div class="paragraph">
<p>When using the <em>GPars(Executors)PoolUtil.asyncFun()</em> function directly to create an asynchronous function
you have two additional options to assign a thread pool to the function.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The thread pool to use by the function can be specified explicitly as an additional argument at creation time</p>
</li>
<li>
<p>The implicit thread pool can be obtained from the surrounding scope at invocation rather at creation time</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>When specifying the thread pool explicitly, the call doesn&#8217;t need to be wrapped in an <em>withPool()</em> block:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>Closure sPlus = {Integer a, Integer b -&gt;
    a + b
}

Closure sMultiply = {Integer a, Integer b -&gt;
    sleep 2000
    a * b
}

println "Synchronous result: " + sMultiply(sPlus(10, 30), 100)

final pool = new FJPool()

Closure aPlus = GParsPoolUtil.asyncFun(sPlus, pool)
Closure aMultiply = GParsPoolUtil.asyncFun(sMultiply, pool)

def result = aMultiply(aPlus(10, 30), 100)

println "Time to do something else while the calculation is running"
println "Asynchronous result: " + result.get()</pre>
</div>
</div>
<div class="paragraph">
<p>With delayed pool assignment only the function invocation must be surrounded with a <em>withPool()</em> block:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>Closure aPlus = GParsPoolUtil.asyncFun(sPlus)
Closure aMultiply = GParsPoolUtil.asyncFun(sMultiply)

withPool {
    def result = aMultiply(aPlus(10, 30), 100)

    println "Time to do something else while the calculation is running"
    println "Asynchronous result: " + result.get()
}</pre>
</div>
</div>
<div class="paragraph">
<p>On our side this is a very interesting domain to explore, so any comments, questions or suggestions on
combining asynchronous functions or hints about its limits are welcome.</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_fork_join_2">Fork-Join</h3>
<div class="paragraph">
<p>Fork/Join or Divide and Conquer is a very powerful abstraction to solve hierarchical problems.</p>
</div>
<div class="sect3">
<h4 id="_the_abstraction">The abstraction</h4>
<div class="paragraph">
<p>When talking about hierarchical problems, think about quick sort, merge sort, file system or general tree
navigation and such.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Fork / Join algorithms essentially split a problem at hands into several smaller sub-problems and
recursively apply the same algorithm to each of the sub-problems.</p>
</li>
<li>
<p>Once the sub-problem is small enough, it is solved directly.</p>
</li>
<li>
<p>The solutions of all sub-problems are combined to solve their parent problem, which in turn helps solve
its own parent problem.</p>
</li>
</ul>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>Check out the fancy <a href="http://blog.krecan.net/2011/03/27/visualizing-forkjoin/">interactive Fork/Join
visualization demo</a>, which will show you how threads cooperate to solve a common divide-and-conquer
algorithm.</p>
</div>
</div>
</div>
<div class="paragraph">
<p>The mighty <strong>JSR-166y</strong> library solves Fork / Join orchestration pretty nicely for us, but leaves a couple of
rough edges, which can hurt you, if you don&#8217;t pay attention enough. You still deal with threads, pools or
synchronization barriers.</p>
</div>
<div class="sect4">
<h5 id="_the_gpars_abstraction_convenience_layer">The GPars abstraction convenience layer</h5>
<div class="paragraph">
<p>GPars can hide the complexities of dealing with threads, pools and recursive tasks from you, yet let you
leverage the powerful Fork/Join implementation in jsr166y.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import static groovyx.gpars.GParsPool.runForkJoin
import static groovyx.gpars.GParsPool.withPool

withPool() {
    println """Number of files: ${
        runForkJoin(new File("./src")) {file -&gt;
            long count = 0
            file.eachFile {
                if (it.isDirectory()) {
                    println "Forking a child task for $it"
                    forkOffChild(it)           //fork a child task
                } else {
                    count++
                }
            }
            return count + (childrenResults.sum(0))
            //use results of children tasks to calculate and store own result
        }
    }"""
}</pre>
</div>
</div>
<div class="paragraph">
<p>The <em>runForkJoin()</em> factory method will use the supplied recursive code together with the provided values
and build a hierarchical Fork/Join calculation. The number of values passed to the <em>runForkJoin()</em> method
must match the number of expected parameters of the closure as well as the number of arguments passed into
the <em>forkOffChild()</em> or <em>runChildDirectly()</em> methods.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def quicksort(numbers) {
    withPool {
        runForkJoin(0, numbers) {index, list -&gt;
            def groups = list.groupBy {it &lt;=&gt; list[list.size().intdiv(2)]}
            if ((list.size() &lt; 2) || (groups.size() == 1)) {
                return [index: index, list: list.clone()]
            }
            (-1..1).each {forkOffChild(it, groups[it] ?: [])}
            return [index: index, list: childrenResults.sort {it.index}.sum {it.list}]
        }.list
    }
}</pre>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>The important piece of the puzzle that needs to be mentioned here is that <em>forkOffChild()</em> doesn&#8217;t
wait for the child to run.  It merely schedules it for execution some time in the future. If a child fails
by throwing an exception, you should not expect the exception to be fired from the forkOffChild() method
itself. The exception ise likely to happen long after the parent has returned from the call to the
<em>forkOffChild()</em> method.</p>
</div>
<div class="paragraph">
<p>It is the <em>getChildrenResults()</em> method that will re-throw exceptions that happened in the child sub-tasks
back to the parent task.</p>
</div>
</div>
</div>
<div class="sect5">
<h6 id="_alternative_approach">Alternative approach</h6>
<div class="paragraph">
<p>Alternatively, the underlying mechanism of nested Fork/Join worker tasks can be used
directly. Custom-tailored workers can eliminate the performance overhead associated with parameter spreading
imposed when using the generic workers. Also, custom workers can be implemented in Java and so further
increase the performance of the algorithm.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>public final class FileCounter extends AbstractForkJoinWorker&lt;Long&gt; {
    private final File file;

    def FileCounter(final File file) {
        this.file = file
    }

    @Override
    protected Long computeTask() {
        long count = 0;
        file.eachFile {
            if (it.isDirectory()) {
                println "Forking a thread for $it"
                forkOffChild(new FileCounter(it))           //fork a child task
            } else {
                count++
            }
        }
        return count + ((childrenResults)?.sum() ?: 0)  //use results of children tasks to calculate and store own result
    }
}

withPool(1) {pool -&gt;  //feel free to experiment with the number of fork/join threads in the pool
    println "Number of files: ${runForkJoin(new FileCounter(new File("..")))}"
}</pre>
</div>
</div>
<div class="paragraph">
<p>The AbstractForkJoinWorker subclasses may be written both in Java or Groovy, giving you the option to easily
optimize for execution speed, if row performance of the worker becomes a bottleneck.</p>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_fork_join_saves_your_resources">Fork / Join saves your resources</h5>
<div class="paragraph">
<p>Fork/Join operations can be safely run with small number of threads thanks to internally using the
TaskBarrier class to synchronize the threads. While a thread is blocked inside an algorithm waiting for its
sub-problems to be calculated, the thread is silently returned to the pool to take on any of the available
sub-problems from the task queue and process them.  Although the algorithm creates as many tasks as there
are sub-directories and tasks wait for the sub-directory tasks to complete, as few as one thread is enough
to keep the computation going and eventually calculate a valid result.</p>
</div>
</div>
<div class="sect4">
<h5 id="_mergesort_example">Mergesort example</h5>
<div class="listingblock">
<div class="content">
<pre>import static groovyx.gpars.GParsPool.runForkJoin
import static groovyx.gpars.GParsPool.withPool

/**
 * Splits a list of numbers in half
 */
def split(List&lt;Integer&gt; list) {
    int listSize = list.size()
    int middleIndex = listSize / 2
    def list1 = list[0..&lt;middleIndex]
    def list2 = list[middleIndex..listSize - 1]
    return [list1, list2]
}

/**
 * Merges two sorted lists into one
 */
List&lt;Integer&gt; merge(List&lt;Integer&gt; a, List&lt;Integer&gt; b) {
    int i = 0, j = 0
    final int newSize = a.size() + b.size()
    List&lt;Integer&gt; result = new ArrayList&lt;Integer&gt;(newSize)

    while ((i &lt; a.size()) &amp;&amp; (j &lt; b.size())) {
        if (a[i] &lt;= b[j]) result &lt;&lt; a[i++]
        else result &lt;&lt; b[j++]
    }

    if (i &lt; a.size()) result.addAll(a[i..-1])
    else result.addAll(b[j..-1])
    return result
}

final def numbers = [1, 5, 2, 4, 3, 8, 6, 7, 3, 4, 5, 2, 2, 9, 8, 7, 6, 7, 8, 1, 4, 1, 7, 5, 8, 2, 3, 9, 5, 7, 4, 3]

withPool(3) {  //feel free to experiment with the number of fork/join threads in the pool
    println """Sorted numbers: ${
        runForkJoin(numbers) {nums -&gt;
            println "Thread ${Thread.currentThread().name[-1]}: Sorting $nums"
            switch (nums.size()) {
                case 0..1:
                    return nums                                   //store own result
                case 2:
                    if (nums[0] &lt;= nums[1]) return nums     //store own result
                    else return nums[-1..0]                       //store own result
                default:
                    def splitList = split(nums)
                    [splitList[0], splitList[1]].each {forkOffChild it}  //fork a child task
                    return merge(* childrenResults)      //use results of children tasks to calculate and store own result
            }
        }
    }"""
}</pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_mergesort_example_using_a_custom_tailored_worker_class">Mergesort example using a custom-tailored worker class</h5>
<div class="listingblock">
<div class="content">
<pre>public final class SortWorker extends AbstractForkJoinWorker&lt;List&lt;Integer&gt;&gt; {
    private final List numbers

    def SortWorker(final List&lt;Integer&gt; numbers) {
        this.numbers = numbers.asImmutable()
    }

    /**
     * Splits a list of numbers in half
     */
    def split(List&lt;Integer&gt; list) {
        int listSize = list.size()
        int middleIndex = listSize / 2
        def list1 = list[0..&lt;middleIndex]
        def list2 = list[middleIndex..listSize - 1]
        return [list1, list2]
    }

    /**
     * Merges two sorted lists into one
     */
    List&lt;Integer&gt; merge(List&lt;Integer&gt; a, List&lt;Integer&gt; b) {
        int i = 0, j = 0
        final int newSize = a.size() + b.size()
        List&lt;Integer&gt; result = new ArrayList&lt;Integer&gt;(newSize)

        while ((i &lt; a.size()) &amp;&amp; (j &lt; b.size())) {
            if (a[i] &lt;= b[j]) result &lt;&lt; a[i++]
            else result &lt;&lt; b[j++]
        }

        if (i &lt; a.size()) result.addAll(a[i..-1])
        else result.addAll(b[j..-1])
        return result
    }

    /**
     * Sorts a small list or delegates to two children, if the list contains more than two elements.
     */
    @Override
    protected List&lt;Integer&gt; computeTask() {
        println "Thread ${Thread.currentThread().name[-1]}: Sorting $numbers"
        switch (numbers.size()) {
            case 0..1:
                return numbers                                   //store own result
            case 2:
                if (numbers[0] &lt;= numbers[1]) return numbers     //store own result
                else return numbers[-1..0]                       //store own result
            default:
                def splitList = split(numbers)
                [new SortWorker(splitList[0]), new SortWorker(splitList[1])].each{forkOffChild it}  //fork a child task
                return merge(* childrenResults)      //use results of children tasks to calculate and store own result
        }
    }
}

final def numbers = [1, 5, 2, 4, 3, 8, 6, 7, 3, 4, 5, 2, 2, 9, 8, 7, 6, 7, 8, 1, 4, 1, 7, 5, 8, 2, 3, 9, 5, 7, 4, 3]

withPool(1) {  //feel free to experiment with the number of fork/join threads in the pool
    println "Sorted numbers: ${runForkJoin(new SortWorker(numbers))}"
}</pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_running_child_tasks_directly">Running child tasks directly</h5>
<div class="paragraph">
<p>The <em>forkOffChild</em> method has a sibling&#8201;&#8212;&#8201;the <em>runChildDirectly</em> method, which will run the child task
directly and immediately within the current thread instead of scheduling the child task for asynchronous
processing on the thread pool. Typically you&#8217;ll call <em>forkOffChild</em> on all sub-tasks but the last, which
you invoke directly without the scheduling overhead.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>Closure fib = {number -&gt;
    if (number &lt;= 2) {
        return 1
    }
    forkOffChild(number - 1)                            //  This task will run asynchronously, probably in a different thread
    final def result = runChildDirectly(number - 2)     //  This task is run directly within the current thread
    return (Integer) getChildrenResults().sum() + result
}

withPool {
    assert 55 == runForkJoin(10, fib)
}</pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_availability_2">Availability</h5>
<div class="paragraph">
<p>This feature is only available when using in the Fork/Join-based <strong>GParsPool</strong> , not in <strong>GParsExecutorsPool</strong> .</p>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_parallel_speculations">Parallel Speculations</h3>
<div class="paragraph">
<p>With processor cores having become plentiful, some algorithms might benefit from brutal-force parallel
duplication.  Instead of deciding up-front about how to solve a problem, what algorithm to use or which
location to connect to, you run all potential solutions in parallel.</p>
</div>
<div class="sect3">
<h4 id="_parallel_speculations_2">Parallel speculations</h4>
<div class="paragraph">
<p>Imagine you need to perform a task like e.g. calculate an expensive function or read data from a file,
database or internet. Luckily, you know of several good ways (e.g. functions or urls) to achieve your
goal. However, they are not all equal. Although they return back the same (as far as your needs are
concerned) result, they may all take different amount of time to complete and some of them may even fail
(e.g. network issues). What&#8217;s worse, no-one is going to tell you which path gives you the solution first nor
which paths lead to no solution at all. Shall I run <em>quick sort</em> or <em>merge sort</em> on my list? Which url will
work best? Is this service available at its primary location or should I use the backup one?</p>
</div>
<div class="paragraph">
<p>GPars speculations give you the option to try all the available alternatives in parallel and so get the
result from the fastest functional path, silently ignoring the slow or broken ones.</p>
</div>
<div class="paragraph">
<p>This is what the <em>speculate</em> methods on <strong>GParsPool</strong> and <strong>GParsExecutorsPool</strong> can do.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def numbers = ...
def quickSort = ...
def mergeSort = ...
def sortedNumbers = speculate(quickSort, mergeSort)</pre>
</div>
</div>
<div class="paragraph">
<p>Here we&#8217;re performing both <em>quick sort</em> and <em>merge sort</em> <strong>concurrently</strong>, while getting the result of the
faster one. Given the parallel resources available these days on mainstream hardware, running the two
functions in parallel will not have dramatic impact on speed of calculation of either one, and so we get the
result in about the same time as if we ran solely the faster of the two calculations. And we get the result
sooner than when running the slower one. Yet we didn&#8217;t have to know up-front, which of the two sorting
algorithms would perform better on our data. Thus we speculated.</p>
</div>
<div class="paragraph">
<p>Similarly, downloading a document from multiple sources of different speed and reliability would look like
this:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import static groovyx.gpars.GParsPool.speculate
import static groovyx.gpars.GParsPool.withPool

def alternative1 = {
    'http://www.dzone.com/links/index.html'.toURL().text
}

def alternative2 = {
    'http://www.dzone.com/'.toURL().text
}

def alternative3 = {
    'http://www.dzzzzzone.com/'.toURL().text  //wrong url
}

def alternative4 = {
    'http://dzone.com/'.toURL().text
}

withPool(4){
    println speculate([alternative1, alternative2, alternative3, alternative4]).contains('groovy')
}</pre>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>Make sure the surrounding thread pool has enough threads to process all alternatives in parallel. The size of the pool should match
the number of closures supplied.</p>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_alternatives_using_dataflow_variables_and_streams">Alternatives using dataflow variables and streams</h4>
<div class="paragraph">
<p>In cases, when stopping unsuccessful alternatives is not needed, dataflow variables or streams may be used to obtain the result value
from the winning speculation.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>Please refer to the Dataflow Concurrency section of the User Guide for details on Dataflow variables and streams.</p>
</div>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.dataflow.DataflowQueue
import static groovyx.gpars.dataflow.Dataflow.task

def alternative1 = {
    'http://www.dzone.com/links/index.html'.toURL().text
}

def alternative2 = {
    'http://www.dzone.com/'.toURL().text
}

def alternative3 = {
    'http://www.dzzzzzone.com/'.toURL().text  //will fail due to wrong url
}

def alternative4 = {
    'http://dzone.com/'.toURL().text
}

//Pick either one of the following, both will work:
final def result = new DataflowQueue()
//  final def result = new DataflowVariable()

[alternative1, alternative2, alternative3, alternative4].each{code -&gt;
    task{
        try {
            result &lt;&lt; code()
        }
        catch (ignore) { }  // We deliberately ignore unsuccessful urls.
    }
}

println result.val.contains('groovy')</pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_groovy_csp">Groovy CSP</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The CSP (Communicating Sequential Processes) abstraction builds on independent composable processes, which
exchange messages in a synchronous manner.  GPars leverages <a href="http://www.cs.kent.ac.uk/projects/ofa/jcsp/">the
JCSP library</a> developed at the University of Kent, UK.</p>
</div>
<div class="paragraph">
<p>Jon Kerridge, the author of the CSP implementation in GPars, provides exhaustive examples on of GroovyCSP use at
<a href="http://www.soc.napier.ac.uk/~cs10/#_Toc271192596" class="bare">http://www.soc.napier.ac.uk/~cs10/#_Toc271192596</a></p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>The GroovyCSP implementation leverages JCSP, a Java-based CSP library, which is licensed under LGPL. There
are some differences between the Apache 2 license, which GPars uses, and LGPL. Please make sure your
application conforms to the LGPL rules before enabling the use of JCSP in your code.</p>
</div>
</div>
</div>
<div class="paragraph">
<p>If the LGPL license is not adequate for your use, you might consider checking out the Dataflow Concurrency
chapter of this User Guide to learn about <em>tasks</em> , <em>selectors</em> and <em>operators</em> , which may help you resolve
concurrency issues in ways similar to the CSP approach.  In fact the dataflow and CSP concepts, as
implemented in GPars, stand very close to each other.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>By default, without actively adding an explicit dependency on JCSP in your build file or downloading and
including the JCSP jar file in your project, the standard commercial-software-friendly Apache 2 License
terms apply to your project. GPars directly only depends on software licensed under licenses compatible with
the Apache 2 License.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_the_csp_model_principles">The CSP model principles</h3>
<div class="paragraph">
<p>In essence, the CSP model builds on independent concurrent processes, which mutually communicate through
channels using synchronous (i.e. rendezvous) message passing. Unlike actors or dataflow operators, which
revolve around the event-processing pattern, CSP processes place focus the their activities (aka sequences
of steps) and use communication to stay mutually in sync along the way.</p>
</div>
<div class="paragraph">
<p>Since the addressing is indirect through channels, the processes do not need to know about one another. They
typically consist of a set of input and output channels and a body. Once a CSP process is started, it
obtains a thread from a thread pool and starts processing its body, pausing only when reading from a channel
or writing into a channel. Some implementations (e.g. GoLang) can also detach the thread from the CSP
process when blocked on a channel.</p>
</div>
<div class="paragraph">
<p>CSP programs are deterministic. The same data on the program&#8217;s input will always generate the same output,
irrespective of the actual thread-scheduling scheme used. This helps a lot when debugging CSP programs as
well as analyzing deadlocks.</p>
</div>
<div class="paragraph">
<p>Determinism combined with indirect addressing result in a great level of composability of CSP processes. You
can combine small CSP processes into bigger ones just by connecting their input and output channels and then
wrapping them by another, bigger containing process.</p>
</div>
<div class="paragraph">
<p>The CSP model introduces non-determinism using <em>Alternatives</em>. A process can attempt to read a value from
multiple channels at the same time through a construct called <em>Alternative</em> or <em>Select</em>. The first value
that becomes available in any of the channels involved in the <em>Select</em> will be read and consumed by the
process. Since the order of messages received through a <em>Select</em> depends on unpredictable conditions during
program run-time, the value that will get read is non-deterministic.</p>
</div>
</div>
<div class="sect2">
<h3 id="_csp_with_gpars_dataflow">CSP with GPars dataflow</h3>
<div class="paragraph">
<p>GPars provides all the necessary building blocks to create CSP processes.</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>CSP Processes</strong> can be modelled through GPars tasks using a <em>Closure</em>, a <em>Runnable</em> or a <em>Callable</em> to
hold the actual implementation of the process</p>
</li>
<li>
<p><strong>CSP Channels</strong> should be modelled with <em>SyncDataflowQueue</em> and <em>SyncDataflowBroadcast</em> classes</p>
</li>
<li>
<p><strong>CSP Alternative</strong> is provided through the <em>Select</em> class with its <em>select</em> and _ prioritySelect_ methods</p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_processes">Processes</h4>
<div class="paragraph">
<p>To start a process simply use the <em>task</em> factory method.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.group.DefaultPGroup
import groovyx.gpars.scheduler.ResizeablePool

group = new DefaultPGroup(new ResizeablePool(true))

def t = group.task {
    println "I am a process"
}

t.join()</pre>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>Since each process consumes a thread for its lifetime, it is advisable to use resizeable thread pools as in the example above.</p>
</div>
</div>
</div>
<div class="paragraph">
<p>A process can also be created from a Runnable or Callable object:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.group.DefaultPGroup
import groovyx.gpars.scheduler.ResizeablePool

group = new DefaultPGroup(new ResizeablePool(true))

class MyProcess implements Runnable {

    @Override
    void run() {
        println "I am a process"
    }
}
def t = group.task new MyProcess()

t.join()</pre>
</div>
</div>
<div class="paragraph">
<p>Using Callable allows for values to be returned through the <em>get()</em> method:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.group.DefaultPGroup
import groovyx.gpars.scheduler.ResizeablePool

import java.util.concurrent.Callable

group = new DefaultPGroup(new ResizeablePool(true))

class MyProcess implements Callable&lt;String&gt; {

    @Override
    String call() {
        println "I am a process"
        return "CSP is great!"
    }
}
def t = group.task new MyProcess()

println t.get()</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_channels">Channels</h4>
<div class="paragraph">
<p>Processes typically need channels to communicate with the other processes as well as with the outside world:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovy.transform.TupleConstructor
import groovyx.gpars.dataflow.DataflowReadChannel
import groovyx.gpars.dataflow.DataflowWriteChannel
import groovyx.gpars.group.DefaultPGroup
import groovyx.gpars.scheduler.ResizeablePool

import java.util.concurrent.Callable
import groovyx.gpars.dataflow.SyncDataflowQueue

group = new DefaultPGroup(new ResizeablePool(true))

@TupleConstructor
class Greeter implements Callable&lt;String&gt; {
    DataflowReadChannel names
    DataflowWriteChannel greetings

    @Override
    String call() {
        while(!Thread.currentThread().isInterrupted()) {
            String name = names.val
            greetings &lt;&lt; "Hello " + name
        }
        return "CSP is great!"
    }
}

def a = new SyncDataflowQueue()
def b = new SyncDataflowQueue()

group.task new Greeter(a, b)

a &lt;&lt; "Joe"
a &lt;&lt; "Dave"
println b.val
println b.val</pre>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>The CSP model uses synchronous messaging, however, in GPars you may consider using asynchronous channels as well as synchronous ones.
You can also combine these two types of channels within the same process.</p>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_composition">Composition</h4>
<div class="paragraph">
<p>Grouping processes is then just a matter of connecting them with channels:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>group = new DefaultPGroup(new ResizeablePool(true))

@TupleConstructor
class Formatter implements Callable&lt;String&gt; {
    DataflowReadChannel rawNames
    DataflowWriteChannel formattedNames

    @Override
    String call() {
        while(!Thread.currentThread().isInterrupted()) {
            String name = rawNames.val
            formattedNames &lt;&lt; name.toUpperCase()
        }
    }
}

@TupleConstructor
class Greeter implements Callable&lt;String&gt; {
    DataflowReadChannel names
    DataflowWriteChannel greetings

    @Override
    String call() {
        while(!Thread.currentThread().isInterrupted()) {
            String name = names.val
            greetings &lt;&lt; "Hello " + name
        }
    }
}

def a = new SyncDataflowQueue()
def b = new SyncDataflowQueue()
def c = new SyncDataflowQueue()

group.task new Formatter(a, b)
group.task new Greeter(b, c)

a &lt;&lt; "Joe"
a &lt;&lt; "Dave"
println c.val
println c.val</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_alternatives">Alternatives</h4>
<div class="paragraph">
<p>To introduce non-determinist GPars offers the <em>Select</em> class with its <em>select</em> and <em>prioritySelect</em> methods:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovy.transform.TupleConstructor
import groovyx.gpars.dataflow.SyncDataflowQueue
import groovyx.gpars.dataflow.DataflowReadChannel
import groovyx.gpars.dataflow.DataflowWriteChannel
import groovyx.gpars.dataflow.Select
import groovyx.gpars.group.DefaultPGroup
import groovyx.gpars.scheduler.ResizeablePool

import static groovyx.gpars.dataflow.Dataflow.select

group = new DefaultPGroup(new ResizeablePool(true))

@TupleConstructor
class Receptionist implements Runnable {
    DataflowReadChannel emails
    DataflowReadChannel phoneCalls
    DataflowReadChannel tweets
    DataflowWriteChannel forwardedMessages

    private final Select incomingRequests = select([phoneCalls, emails, tweets])  //prioritySelect() would give highest precedence to phone calls

    @Override
    void run() {
        while(!Thread.currentThread().isInterrupted()) {
            String msg = incomingRequests.select()
            forwardedMessages &lt;&lt; msg.toUpperCase()
        }
    }
}

def a = new SyncDataflowQueue()
def b = new SyncDataflowQueue()
def c = new SyncDataflowQueue()
def d = new SyncDataflowQueue()

group.task new Receptionist(a, b, c, d)

a &lt;&lt; "my email"
b &lt;&lt; "my phone call"
c &lt;&lt; "my tweet"

//The values come in random order since the process uses a Select to read its input
3.times{
    println d.val.value
}</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_components">Components</h4>
<div class="paragraph">
<p>CSP processes can be composed into larger entities. Suppose you already have a set of CSP processes (aka
Runnable/Callable classes), you can compose them into a larger process:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>final class Prefix implements Callable {
    private final DataflowChannel inChannel
    private final DataflowChannel outChannel
    private final def prefix

    def Prefix(final inChannel, final outChannel, final prefix) {
        this.inChannel = inChannel;
        this.outChannel = outChannel;
        this.prefix = prefix
    }

    public def call() {
        outChannel &lt;&lt; prefix
        while (true) {
            sleep 200
            outChannel &lt;&lt; inChannel.val
        }
    }
}</pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre>final class Copy implements Callable {
    private final DataflowChannel inChannel
    private final DataflowChannel outChannel1
    private final DataflowChannel outChannel2

    def Copy(final inChannel, final outChannel1, final outChannel2) {
        this.inChannel = inChannel;
        this.outChannel1 = outChannel1;
        this.outChannel2 = outChannel2;
    }

    public def call() {
        final PGroup group = Dataflow.retrieveCurrentDFPGroup()
        while (true) {
            def i = inChannel.val
            group.task {
                outChannel1 &lt;&lt; i
                outChannel2 &lt;&lt; i
            }.join()
        }
    }
}</pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.dataflow.DataflowChannel
import groovyx.gpars.dataflow.SyncDataflowQueue
import groovyx.gpars.group.DefaultPGroup

group = new DefaultPGroup(6)

def fib(DataflowChannel out) {
    group.task {
        def a = new SyncDataflowQueue()
        def b = new SyncDataflowQueue()
        def c = new SyncDataflowQueue()
        def d = new SyncDataflowQueue()
        [new Prefix(d, a, 0L), new Prefix(c, d, 1L), new Copy(a, b, out), new StatePairs(b, c)].each { group.task it}
    }
}

final SyncDataflowQueue ch = new SyncDataflowQueue()
group.task new Print('Fibonacci numbers', ch)
fib(ch)

sleep 10000</pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_actors_3">Actors</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Actors allow for a message passing-based concurrency model: programs are collections of independent active
objects that exchange messages and have no mutable shared state.  Actors can help developers avoid issues
such as deadlock, live-lock and starvation, which are common problems for shared memory based approaches.
Actors are a way of leveraging the multi-core nature of today&#8217;s hardware without all the problems
traditionally associated with shared-memory multi-threading, which is why programming languages such as
Erlang and Scala have taken up this model.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
The actor support in GPars was originally inspired by the Actors library in Scala, but has since gone
well beyond what Scala offers as standard.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>A nice article summarizing the key <a href="http://ruben.savanne.be/articles/concurrency-in-erlang-scala">concepts
behind actors</a> has been written by Ruben Vermeersch.  Actors always guarantee that <strong>at most one thread
processes the actor&#8217;s body</strong> at any one time and also, under the covers, that the memory gets synchronized
each time a thread gets assigned to an actor so the actor&#8217;s state <strong>can be safely modified</strong> by code in the
body <strong>without any other extra (synchronization or locking) effort</strong> .  Ideally actor&#8217;s code should <strong>never be
invoked</strong> directly from outside so all the code of the actor class can only be executed by the thread
handling the last received message and so all the actor&#8217;s code is <strong>implicitly thread-safe</strong> .  If any of the
actor&#8217;s methods is allowed to be called by other objects directly, the thread-safety guarantee for the
actor&#8217;s code and state are <strong>no longer valid</strong> .</p>
</div>
<div class="sect2">
<h3 id="_types_of_actors">Types of actors</h3>
<div class="paragraph">
<p>In general, you can find two types of actors in the wild&#8201;&#8212;&#8201;ones that hold <strong>implicit state</strong> and ones that
don&#8217;t. GPars gives you both options.  <strong>Stateless</strong> actors, represented in <strong>GPars</strong> by the
<em>DynamicDispatchActor</em> and the <em>ReactiveActor</em> classes, keep no track of what messages have arrived
previously.  You may think of these as flat message handlers, which process messages as they come. Any
state-based behavior has to be implemented by the user.</p>
</div>
<div class="paragraph">
<p>The <strong>stateful</strong> actors, represented in GPars by the <em>DefaultActor</em> class (and previously also by the
<em>AbstractPooledActor</em> class), allow the user to handle implicit state directly.  After receiving a message
the actor moves into a new state with different ways to handle future messages.  To give you an example, a
freshly started actor may only accept some types of messages, e.g. encrypted messages for decryption, only
after it has received the encryption keys. The stateful actors allow to encode such dependencies directly in
the structure of the message-handling code.  Implicit state management, however, comes at a slight
performance cost, mainly due to the lack of continuations support on JVM.</p>
</div>
</div>
<div class="sect2">
<h3 id="_actor_threading_model">Actor threading model</h3>
<div class="paragraph">
<p>Since actors are detached from the system threads, a great number of actors can share a relatively small
thread pool.  This can go as far as having many concurrent actors that share a single pooled thread. This
architecture avoids some of the threading limitations of the JVM. In general, while the JVM can only give
you a limited number of threads (typically around a couple of thousands), the number of actors is only
limited by the available memory. If an actor has no work to do, it doesn&#8217;t consume threads.</p>
</div>
<div class="paragraph">
<p>Actor code is processed in chunks separated by quiet periods of waiting for new events (messages).  This can
be naturally modeled through <em>continuations</em> . As JVM doesn&#8217;t support continuations directly, they have to
be simulated in the actors frameworks, which has slight impact on organization of the actors' code. However,
the benefits in most cases outweigh the difficulties.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.actor.Actor
import groovyx.gpars.actor.DefaultActor

class GameMaster extends DefaultActor {
    int secretNum

    void afterStart() {
        secretNum = new Random().nextInt(10)
    }

    void act() {
        loop {
            react { int num -&gt;
                if (num &gt; secretNum) {
                    reply 'too large'
                }
                else if (num &lt; secretNum) {
                    reply 'too small'
                }
                else {
                    reply 'you win'
                    terminate()
                }
            }
        }
    }
}

class Player extends DefaultActor {
    String name
    Actor server
    int myNum

    void act() {
        loop {
            myNum = new Random().nextInt(10)
            server.send myNum
            react {
                switch (it) {
                  case 'too large': println "$name: $myNum was too large"; break
                  case 'too small': println "$name: $myNum was too small"; break
                  case 'you win': println "$name: I won $myNum"; terminate(); break
                }
            }
        }
    }
}

def master = new GameMaster().start()
def player = new Player(name: 'Player', server: master).start()

// This forces the main thread to wait until both actors have terminated.
[master, player]*.join()</pre>
</div>
</div>
<div class="paragraph">
<p>example by <em>Jordi Campos i Miralles, Departament de Matemàtica Aplicada i Anàlisi, MAiA Facultat de
Matemàtiques, Universitat de Barcelona</em></p>
</div>
</div>
<div class="sect2">
<h3 id="_usage_of_actors">Usage of actors</h3>
<div class="paragraph">
<p>GPars provides consistent Actor APIs and DSLs. Actors in principal perform three specific operations&#8201;&#8212;&#8201;send
messages, receive messages and create new actors. Although not specifically enforced by GPars messages
should be immutable or at least follow the <strong>hands-off</strong> policy when the sender never touches the messages
after the message has been sent off.</p>
</div>
<div class="sect3">
<h4 id="_sending_messages">Sending messages</h4>
<div class="paragraph">
<p>Messages can be sent to actors using the <em>send</em> method.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def passiveActor = Actors.actor{
    loop {
        react { msg -&gt; println "Received: $msg"; }
    }
}
passiveActor.send 'Message 1'
passiveActor &lt;&lt; 'Message 2'    //using the &lt;&lt; operator
passiveActor 'Message 3'       //using the implicit call() method</pre>
</div>
</div>
<div class="paragraph">
<p>Alternatively, the <em>&lt;&lt;</em> operator or the implicit <em>call</em> method can be used. A family of <em>sendAndWait</em>
methods is available to block the caller until a reply from the actor is available.  The <em>reply</em> is returned
from the <em>sendAndWait</em> method as a return value.  The <em>sendAndWait</em> methods may also return after a
timeout expires or in case of termination of the called actor.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def replyingActor = Actors.actor{
    loop {
        react { msg -&gt;
            println "Received: $msg";
            reply "I've got $msg"
        }
    }
}

def reply1 = replyingActor.sendAndWait('Message 4')

def reply2 = replyingActor.sendAndWait('Message 5', 10, TimeUnit.SECONDS)

use (TimeCategory) {
    def reply3 = replyingActor.sendAndWait('Message 6', 10.seconds)
}</pre>
</div>
</div>
<div class="paragraph">
<p>The <em>sendAndContinue</em> method allows the caller to continue its processing while the supplied closure is
waiting for a reply from the actor.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>friend.sendAndContinue 'I need money!', {money -&gt; pocket money}
println 'I can continue while my friend is collecting money for me'</pre>
</div>
</div>
<div class="paragraph">
<p>The <em>sendAndPromise</em> method returns a <strong>Promise</strong> (aka Future) to the final reply and so allows the caller
to continue its processing while the actor is handling the submitted message.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>Promise loan = friend.sendAndPromise 'I need money!'
println 'I can continue while my friend is collecting money for me'
loan.whenBound {money -&gt; pocket money}  // Asynchronous waiting for a reply.
println "Received ${loan.get()}"  // Synchronous waiting for a reply.</pre>
</div>
</div>
<div class="paragraph">
<p>All <em>send</em> , <em>sendAndWait</em> or <em>sendAndContinue</em> methods will throw an exception if invoked on a non-active actor.</p>
</div>
</div>
<div class="sect3">
<h4 id="_receiving_messages">Receiving messages</h4>
<div class="sect4">
<h5 id="_non_blocking_message_retrieval">Non-blocking message retrieval</h5>
<div class="paragraph">
<p>Calling the <em>react</em> method, optionally with a timeout parameter, from within the actor&#8217;s code will consume
the next message from the actor&#8217;s inbox, potentially waiting, if there is no message to be processed
immediately.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>println 'Waiting for a gift'
react {gift -&gt;
    if (mySpouse.likes gift) reply 'Thank you!'
}</pre>
</div>
</div>
<div class="paragraph">
<p>Under the covers the supplied closure is not invoked directly, but scheduled for processing by any thread in
the thread pool once a message is available. After scheduling the current thread will then be detached from
the actor and freed to process any other actor, which has received a message already.</p>
</div>
<div class="paragraph">
<p>To allow detaching actors from the threads the <em>react</em> method demands the code to be written in a special
<strong>continuation style</strong>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>Actors.actor {
    loop {
        println 'Waiting for a gift'
        react {gift -&gt;
            if (mySpouse.likes gift) reply 'Thank you!'
            else {
                reply 'Try again, please'
                react {anotherGift -&gt;
                    if (myChildren.like gift) reply 'Thank you!'
                }
                println 'Never reached'
            }
        }
        println 'Never reached'
    }
    println 'Never reached'
}</pre>
</div>
</div>
<div class="paragraph">
<p>The <em>react</em> method has a special semantics to allow actors to be detached from threads when no messages
are available in their mailbox.  Essentially, <em>react</em> schedules the supplied code (closure) to be executed
upon next message arrival and returns.  The closure supplied to the <em>react</em> methods is the code where the
computation should <strong>continue</strong> . Thus <strong>continuation style</strong> .</p>
</div>
<div class="paragraph">
<p>Since actors have to preserve the guarantee that at most one thread is active within the actor&#8217;s body, the
next message cannot be handled before the current message processing finishes. Typically, there shouldn&#8217;t be
a need to put code after calls to <em>react</em>.  Some actor implementations even enforce this. However, GPars
does not for performance reasons.  The <em>loop</em> method allows iteration within the actor body. Unlike typical
looping constructs, like <em>for</em> or <em>while</em> loops, <em>loop</em> cooperates with nested <em>react</em> blocks and will
ensure looping across subsequent message retrievals.</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_sending_replies">Sending replies</h4>
<div class="paragraph">
<p>The <em>reply</em> and <em>replyIfExists</em> methods are not only defined on the actors themselves, but for
<em>AbstractPooledActor</em> (not available in <em>DefaultActor</em> , <em>DynamicDispatchActor</em> nor <em>ReactiveActor</em> classes)
also on the processed messages themselves upon their reception, which is particularly handy when handling
multiple messages in a single call. In such cases <em>reply()</em> invoked on the actor sends a reply to authors of
all the currently processed message (the last one), whereas <em>reply()</em> called on messages sends a reply to
the author of the particular message only.</p>
</div>
<div class="paragraph">
<p><a href="http://git.codehaus.org/gitweb.cgi?p=gpars.git;a=blob_plain;f=src/test/groovy/groovyx/gpars/samples/actors/stateful/DemoMultiMessage.groovy;hb=HEAD">See
demo here</a></p>
</div>
<div class="sect4">
<h5 id="_the_sender_property">The sender property</h5>
<div class="paragraph">
<p>Messages upon retrieval offer the sender property to identify the originator of the message. The property is
available inside the Actor&#8217;s closure:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>react {tweet -&gt;
    if (isSpam(tweet)) ignoreTweetsFrom sender
    sender.send 'Never write to me again!'
}</pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_forwarding">Forwarding</h5>
<div class="paragraph">
<p>When sending a message, a different actor can be specified as the sender so that potential replies to the
message will be forwarded to the specified actor and not to the actual originator.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def decryptor = Actors.actor {
    react {message -&gt;
        reply message.reverse()
//        sender.send message.reverse()    //An alternative way to send replies
    }
}

def console = Actors.actor {  //This actor will print out decrypted messages, since the replies are forwarded to it
    react {
        println 'Decrypted message: ' + it
    }
}

decryptor.send 'lellarap si yvoorG', console  //Specify an actor to send replies to
console.join()</pre>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_creating_actors">Creating Actors</h4>
<div class="paragraph">
<p>Actors share a <strong>pool</strong> of threads, which are dynamically assigned to actors when the actors need to <strong>react</strong>
to messages sent to them. The threads are returned to back the pool once a message has been processed and
the actor is idle waiting for some more messages to arrive.</p>
</div>
<div class="paragraph">
<p>For example, this is how you create an actor that prints out all messages that it receives.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def console = Actors.actor {
    loop {
        react {
            println it
        }
    }
}</pre>
</div>
</div>
<div class="paragraph">
<p>Notice the <em>loop()</em> method call, which ensures that the actor doesn&#8217;t stop after having processed the first
message.</p>
</div>
<div class="paragraph">
<p>Here&#8217;s an example with a decryptor service, which can decrypt submitted messages and send the decrypted
messages back to the originators.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>final def decryptor = Actors.actor {
    loop {
        react {String message -&gt;
            if ('stopService' == message) {
                println 'Stopping decryptor'
                stop()
            }
            else reply message.reverse()
        }
    }
}

Actors.actor {
    decryptor.send 'lellarap si yvoorG'
    react {
        println 'Decrypted message: ' + it
        decryptor.send 'stopService'
    }
}.join()</pre>
</div>
</div>
<div class="paragraph">
<p>Here&#8217;s an example of an actor that waits for up to 30 seconds to receive a reply to its message.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def friend = Actors.actor {
    react {
        //this doesn't reply -&gt; caller won't receive any answer in time
        println it
        //reply 'Hello' //uncomment this to answer conversation
        react {
            println it
        }
    }
}

def me = Actors.actor {
    friend.send('Hi')
    //wait for answer 1sec
    react(1000) {msg -&gt;
        if (msg == Actor.TIMEOUT) {
            friend.send('I see, busy as usual. Never mind.')
            stop()
        } else {
            //continue conversation
            println "Thank you for $msg"
        }
    }
}

me.join()</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_undelivered_messages">Undelivered messages</h4>
<div class="paragraph">
<p>Sometimes messages cannot be delivered to the target actor. When special action needs to be taken for
undelivered messages, at actor termination all unprocessed messages from its queue have their
<em>onDeliveryError()</em> method called. The <em>onDeliveryError()</em> method or closure defined on the message can, for
example, send a notification back to the original sender of the message.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>final DefaultActor me
me = Actors.actor {
    def message = 1

    message.metaClass.onDeliveryError = {-&gt;
        //send message back to the caller
        me &lt;&lt; "Could not deliver $delegate"
    }

    def actor = Actors.actor {
        react {
            //wait 2sec in order next call in demo can be emitted
            Thread.sleep(2000)
            //stop actor after first message
            stop()
        }
    }

    actor &lt;&lt; message
    actor &lt;&lt; message

    react {
        //print whatever comes back
        println it
    }

}

me.join()</pre>
</div>
</div>
<div class="paragraph">
<p>Alternatively the <em>onDeliveryError()</em> method can be specified on the sender itself. The method can be added
both dynamically</p>
</div>
<div class="listingblock">
<div class="content">
<pre>final DefaultActor me
me = Actors.actor {
    def message1 = 1
    def message2 = 2

    def actor = Actors.actor {
        react {
            //wait 2sec in order next call in demo can be emitted
            Thread.sleep(2000)
            //stop actor after first message
            stop()
        }
    }

    me.metaClass.onDeliveryError = {msg -&gt;
        //callback on actor inaccessibility
        println "Could not deliver message $msg"
    }

    actor &lt;&lt; message1
    actor &lt;&lt; message2

    actor.join()

}

me.join()</pre>
</div>
</div>
<div class="paragraph">
<p>and statically in actor definition:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>class MyActor extends DefaultActor {
    public void onDeliveryError(msg) {
        println "Could not deliver message $msg"
    }
    ...
}</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_joining_actors">Joining actors</h4>
<div class="paragraph">
<p>Actors provide a <em>join()</em> method to allow callers to wait for the actor to terminate. A variant accepting a
timeout is also available. The Groovy <em>spread-dot</em> operator comes in handy when joining multiple actors at a
time.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def master = new GameMaster().start()
def player = new Player(name: 'Player', server: master).start()

[master, player]*.join()</pre>
</div>
</div>
<div class="sect4">
<h5 id="_conditional_and_counting_loops">Conditional and counting loops</h5>
<div class="paragraph">
<p>The <em>loop()</em> method allows for either a condition or a number of iterations to be specified, optionally
accompanied with a closure to invoke once the loop finishes - <em>After Loop Termination Code Handler</em> .</p>
</div>
<div class="paragraph">
<p>The following actor will loop three times to receive 3 messages and then prints out the maximum of the
received messages.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>final Actor actor = Actors.actor {
    def candidates = []
    def printResult = {-&gt; println "The best offer is ${candidates.max()}"}

    loop(3, printResult) {
        react {
            candidates &lt;&lt; it
        }
    }
}

actor 10
actor 30
actor 20
actor.join()</pre>
</div>
</div>
<div class="paragraph">
<p>The following actor will receive messages until a value greater then 30 arrives.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>final Actor actor = Actors.actor {
    def candidates = []
    final Closure printResult = {-&gt; println "Reached best offer - ${candidates.max()}"}

    loop({-&gt; candidates.max() &lt; 30}, printResult) {
        react {
            candidates &lt;&lt; it
        }
    }
}

actor 10
actor 20
actor 25
actor 31
actor 20
actor.join()</pre>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>The <em>After Loop Termination Code Handler</em> can use actor&#8217;s <em>react{}</em> but not <em>loop()</em> .</p>
</div>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p><em>DefaultActor</em> can be set to behave in a fair on non-fair (default) manner. Depending on the strategy
chosen, the actor either makes the thread available to other actors sharing the same parallel group (fair),
or keeps the thread fot itself until the message queue gets empty (non-fair). Generally, non-fair actors
perform 2 - 3 times better than fair ones.</p>
</div>
<div class="paragraph">
<p>Use either the <em>fairActor()</em> factory method or the actor&#8217;s makeFair() method.</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_custom_schedulers">Custom schedulers</h4>
<div class="paragraph">
<p>Actors leverage the standard JDK concurrency library by default.  To provide a custom thread scheduler use
the appropriate constructor parameter when creating a parallel group (PGroup class). The supplied scheduler
will orchestrate threads in the group&#8217;s thread pool.</p>
</div>
<div class="paragraph">
<p>Please also see the numerous
<a href="http://git.codehaus.org/gitweb.cgi?p=gpars.git;a=tree;f=src/test/groovy/groovyx/gpars/samples;h=f9a751689a034a1d3de13c4874f4f4e839cb1026;hb=HEAD">Actor
Demos</a>.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_actors_principles">Actors Principles</h3>
<div class="paragraph">
<p>Actors share a <strong>pool</strong> of threads, which are dynamically assigned to actors when the actors need to <strong>react</strong>
to messages sent to them.  The threads are returned back to the pool once a message has been processed and
the actor is idle waiting for some more messages to arrive.  Actors become detached from the underlying
threads and so a relatively small thread pool can serve potentially unlimited number of actors.  Virtually
unlimited scalability in number of actors is the main advantage of <em>event-based actors</em> , which are detached
from the underlying physical threads.</p>
</div>
<div class="paragraph">
<p>Here are some examples of how to use actors. This is how you create an actor that prints out all messages
that it receives.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import static groovyx.gpars.actor.Actors.actor

def console = actor {
    loop {
        react {
            println it
        }
    }</pre>
</div>
</div>
<div class="paragraph">
<p>Notice the <em>loop()</em> method call, which ensures that the actor doesn&#8217;t stop after having processed the first
message.</p>
</div>
<div class="paragraph">
<p>As an alternative you can extend the <em>DefaultActor</em> class and override the <em>act()</em> method. Once you
instantiate the actor, you need to start it so that it attaches itself to the thread pool and can start
accepting messages.  The <em>actor()</em> factory method will take care of starting the actor.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>class CustomActor extends DefaultActor {
    @Override
    protected void act() {
        loop {
            react {
                println it
            }
        }
    }
}

def console=new CustomActor()
console.start()</pre>
</div>
</div>
<div class="paragraph">
<p>Messages can be sent to the actor using multiple methods</p>
</div>
<div class="listingblock">
<div class="content">
<pre>console.send('Message')
console 'Message'
console.sendAndWait 'Message'                                                     //Wait for a reply
console.sendAndContinue 'Message', {reply -&gt; println "I received reply: $reply"}  //Forward the reply to a function</pre>
</div>
</div>
<div class="sect3">
<h4 id="_creating_an_asynchronous_service">Creating an asynchronous service</h4>
<div class="listingblock">
<div class="content">
<pre>import static groovyx.gpars.actor.Actors.actor

final def decryptor = actor {
    loop {
        react {String message-&gt;
            reply message.reverse()
        }
    }
}

def console = actor {
    decryptor.send 'lellarap si yvoorG'
    react {
        println 'Decrypted message: ' + it
    }
}

console.join()</pre>
</div>
</div>
<div class="paragraph">
<p>As you can see, you create new actors with the <em>actor()</em> method passing in the actor&#8217;s body as a closure
parameter. Inside the actor&#8217;s body you can use <em>loop()</em> to iterate, <em>react()</em> to receive messages and
<em>reply()</em> to send a message to the actor, which has sent the currently processed message. The sender of the
current message is also available through the actor&#8217;s <em>sender</em> property.  When the decryptor actor doesn&#8217;t
find a message in its message queue at the time when <em>react()</em> is called, the <em>react()</em> method gives up the
thread and returns it back to the thread pool for other actors to pick it up.  Only after a new message
arrives to the actor&#8217;s message queue, the closure of the <em>react()</em> method gets scheduled for processing with
the pool.  Event-based actors internally simulate continuations - actor&#8217;s work is split into sequentially
run chunks, which get invoked once a message is available in the inbox. Each chunk for a single actor can be
performed by a different thread from the thread pool.</p>
</div>
<div class="paragraph">
<p>Groovy flexible syntax with closures allows our library to offer multiple ways to define actors.  For
instance, here&#8217;s an example of an actor that waits for up to 30 seconds to receive a reply to its message.
Actors allow time DSL defined by org.codehaus.groovy.runtime.TimeCategory class to be used for timeout
specification to the <em>react()</em> method, provided the user wraps the call within a <em>TimeCategory</em> use block.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def friend = Actors.actor {
    react {
        //this doesn't reply -&gt; caller won't receive any answer in time
        println it
        //reply 'Hello' //uncomment this to answer conversation
        react {
            println it
        }
    }
}

def me = Actors.actor {
    friend.send('Hi')
    //wait for answer 1sec
    react(1000) {msg -&gt;
        if (msg == Actor.TIMEOUT) {
            friend.send('I see, busy as usual. Never mind.')
            stop()
        } else {
            //continue conversation
            println "Thank you for $msg"
        }
    }
}

me.join()</pre>
</div>
</div>
<div class="paragraph">
<p>When a timeout expires when waiting for a message, the Actor.TIMEOUT message arrives instead. Also the
<em>onTimeout()</em> handler is invoked, if present on the actor:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def friend = Actors.actor {
    react {
        //this doesn't reply -&gt; caller won't receive any answer in time
        println it
        //reply 'Hello' //uncomment this to answer conversation
        react {
            println it
        }
    }
}

def me = Actors.actor {
    friend.send('Hi')

    delegate.metaClass.onTimeout = {-&gt;
        friend.send('I see, busy as usual. Never mind.')
        stop()
    }

    //wait for answer 1sec
    react(1000) {msg -&gt;
        if (msg != Actor.TIMEOUT) {
            //continue conversation
            println "Thank you for $msg"
        }
    }
}

me.join()</pre>
</div>
</div>
<div class="paragraph">
<p>Notice the possibility to use Groovy meta-programming to define actor&#8217;s lifecycle notification methods
(e.g. <em>onTimeout()</em> ) dynamically.  Obviously, the lifecycle methods can be defined the usual way when you
decide to define a new class for your actor.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>class MyActor extends DefaultActor {
    public void onTimeout() {
        ...
    }

    protected void act() {
       ...
    }
}</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_actors_guarantee_thread_safety_for_non_thread_safe_code">Actors guarantee thread-safety for non-thread-safe code</h4>
<div class="paragraph">
<p>Actors guarantee that always at most one thread processes the actor&#8217;s body at a time and also under the
covers the memory gets synchronized each time a thread gets assigned to an actor so the actor&#8217;s state <strong>can
be safely modified</strong> by code in the body <strong>without any other extra (synchronization or locking) effort</strong> .</p>
</div>
<div class="listingblock">
<div class="content">
<pre>class MyCounterActor extends DefaultActor {
    private Integer counter = 0

    protected void act() {
        loop {
            react {
                counter++
            }
        }
    }
}</pre>
</div>
</div>
<div class="paragraph">
<p>Ideally actor&#8217;s code should <strong>never be invoked</strong> directly from outside so all the code of the actor class can
only be executed by the thread handling the last received message and so all the actor&#8217;s code is <strong>implicitly
thread-safe</strong> .  If any of the actor&#8217;s methods is allowed to be called by other objects directly, the
thread-safety guarantee for the actor&#8217;s code and state are <strong>no longer valid</strong> .</p>
</div>
</div>
<div class="sect3">
<h4 id="_simple_calculator">Simple calculator</h4>
<div class="paragraph">
<p>A little bit more realistic example of an event-driven actor that receives two numeric messages, sums them
up and sends the result to the console actor.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.group.DefaultPGroup

//not necessary, just showing that a single-threaded pool can still handle multiple actors
def group = new DefaultPGroup(1);

final def console = group.actor {
    loop {
        react {
            println 'Result: ' + it
        }
    }
}

final def calculator = group.actor {
    react {a -&gt;
        react {b -&gt;
            console.send(a + b)
        }
    }
}

calculator.send 2
calculator.send 3

calculator.join()
group.shutdown()</pre>
</div>
</div>
<div class="paragraph">
<p>Notice that event-driven actors require special care regarding the <em>react()</em> method. Since <em>event_driven
actors</em> need to split the code into independent chunks assignable to different threads sequentially and
<strong>continuations</strong> are not natively supported on JVM, the chunks are created artificially. The <em>react()</em> method
creates the next message handler.  As soon as the current message handler finishes, the next message handler
(continuation) gets scheduled.</p>
</div>
<div class="sect4">
<h5 id="_concurrent_merge_sort_example">Concurrent Merge Sort Example</h5>
<div class="paragraph">
<p>For comparison I&#8217;m also including a more involved example performing a concurrent merge sort of a list of
integers using actors. You can see that thanks to flexibility of Groovy we came pretty close to the Scala
model, although I still miss Scala pattern matching for message handling.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.group.DefaultPGroup
import static groovyx.gpars.actor.Actors.actor

Closure createMessageHandler(def parentActor) {
    return {
        react {List&lt;Integer&gt; message -&gt;
            assert message != null
            switch (message.size()) {
                case 0..1:
                    parentActor.send(message)
                    break
                case 2:
                    if (message[0] &lt;= message[1]) parentActor.send(message)
                    else parentActor.send(message[-1..0])
                    break
                default:
                    def splitList = split(message)

                    def child1 = actor(createMessageHandler(delegate))
                    def child2 = actor(createMessageHandler(delegate))
                    child1.send(splitList[0])
                    child2.send(splitList[1])

                    react {message1 -&gt;
                        react {message2 -&gt;
                            parentActor.send merge(message1, message2)
                        }
                    }
            }
        }
    }
}

def console = new DefaultPGroup(1).actor {
    react {
        println "Sorted array:\t${it}"
        System.exit 0
    }
}

def sorter = actor(createMessageHandler(console))
sorter.send([1, 5, 2, 4, 3, 8, 6, 7, 3, 9, 5, 3])
console.join()

def split(List&lt;Integer&gt; list) {
    int listSize = list.size()
    int middleIndex = listSize / 2
    def list1 = list[0..&lt;middleIndex]
    def list2 = list[middleIndex..listSize - 1]
    return [list1, list2]
}

List&lt;Integer&gt; merge(List&lt;Integer&gt; a, List&lt;Integer&gt; b) {
    int i = 0, j = 0
    final int newSize = a.size() + b.size()
    List&lt;Integer&gt; result = new ArrayList&lt;Integer&gt;(newSize)

    while ((i &lt; a.size()) &amp;&amp; (j &lt; b.size())) {
        if (a[i] &lt;= b[j]) result &lt;&lt; a[i++]
        else result &lt;&lt; b[j++]
    }

    if (i &lt; a.size()) result.addAll(a[i..-1])
    else result.addAll(b[j..-1])
    return result
}</pre>
</div>
</div>
<div class="paragraph">
<p>Since <em>actors</em> reuse threads from a pool, the script will work with virtually <strong>any size of a thread pool</strong>,
no matter how many actors are created along the way.</p>
</div>
</div>
<div class="sect4">
<h5 id="_actor_lifecycle_methods">Actor lifecycle methods</h5>
<div class="paragraph">
<p>Each Actor can define lifecycle observing methods, which will be called whenever a certain lifecycle event
occurs.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>afterStart() - called right after the actor has been started.</p>
</li>
<li>
<p>afterStop(List undeliveredMessages) - called right after the actor is stopped, passing in all the unprocessed messages from the queue.</p>
</li>
<li>
<p>onInterrupt(InterruptedException e) - called when the actor&#8217;s thread gets interrupted. Thread interruption will result in the stopping the actor in any case.</p>
</li>
<li>
<p>onTimeout() - called when no messages are sent to the actor within the timeout specified for the currently blocking react method.</p>
</li>
<li>
<p>onException(Throwable e) - called when an exception occurs in the actor&#8217;s event handler. Actor will stop after return from this method.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>You can either define the methods statically in your Actor class or add them dynamically to the actor&#8217;s metaclass:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>class MyActor extends DefaultActor {
    public void afterStart() {
        ...
    }
    public void onTimeout() {
        ...
    }

    protected void act() {
       ...
    }
}</pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre>def myActor = actor {
    delegate.metaClass.onException = {
        log.error('Exception occurred', it)
    }

...
}</pre>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>To help performance, you may consider using the <em>silentStart()</em> method instead of <em>start()</em> when starting a <em>DynamicDispatchActor</em> or a <em>ReactiveActor</em> .
Calling <em>silentStart()</em> will by-pass some of the start-up machinery and as a result will also avoid calling the <em>afterStart()</em> method.
Due to its stateful nature, <em>DefaultActor</em> cannot be started silently.</p>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_pool_management">Pool management</h5>
<div class="paragraph">
<p><em>Actors</em> can be organized into groups and as a default there&#8217;s always an application-wide pooled actor group
available. And just like the <em>Actors</em> abstract factory can be used to create actors in the default group,
custom groups can be used as abstract factories to create new actors instances belonging to these groups.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def myGroup = new DefaultPGroup()

def actor1 = myGroup.actor {
...
}

def actor2 = myGroup.actor {
...
}</pre>
</div>
</div>
<div class="paragraph">
<p>The <em>parallelGroup</em> property of an actor points to the group it belongs to. It by default points to the
default actor group, which is <em>Actors.defaultActorPGroup</em> , and can only be changed before the actor is
started.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>class MyActor extends StaticDispatchActor&lt;Integer&gt; {
    private static PGroup group = new DefaultPGroup(100)

    MyActor(...) {
        this.parallelGroup = group
        ...
    }
}</pre>
</div>
</div>
<div class="paragraph">
<p>The actors belonging to the same group share the <strong>underlying thread pool</strong> of that group. The pool by default
contains <strong>n + 1 threads</strong>, where <strong>n</strong> stands for the number of <strong>CPUs</strong> detected by the JVM. The <strong>pool size</strong> can
be set <strong>explicitly</strong> either by setting the <em>gpars.poolsize</em> system property or individually for each actor
group by specifying the appropriate constructor parameter.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def myGroup = new DefaultPGroup(10)  //the pool will contain 10 threads</pre>
</div>
</div>
<div class="paragraph">
<p>The thread pool can be manipulated through the appropriate <em>DefaultPGroup</em> class, which <strong>delegates</strong> to the
<em>Pool</em> interface of the thread pool. For example, the <em>resize()</em> method allows you to change the pool size
any time and the <em>resetDefaultSize()</em> sets it back to the default value. The <em>shutdown()</em> method can be
called when you need to safely finish all tasks, destroy the pool and stop all the threads in order to exit
JVM in an organized manner.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>... (n+1 threads in the default pool after startup)

Actors.defaultActorPGroup.resize 1  //use one-thread pool

... (1 thread in the pool)

Actors.defaultActorPGroup.resetDefaultSize()

... (n+1 threads in the pool)

Actors.defaultActorPGroup.shutdown()</pre>
</div>
</div>
<div class="paragraph">
<p>As an alternative to the <em>DefaultPGroup</em>, which creates a pool of daemon threads, the <em>NonDaemonPGroup</em>
class can be used when non-daemon threads are required.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def daemonGroup = new DefaultPGroup()

def actor1 = daemonGroup.actor {
...
}

def nonDaemonGroup = new NonDaemonPGroup()

def actor2 = nonDaemonGroup.actor {
...
}

class MyActor {
    def MyActor() {
        this.parallelGroup = nonDaemonGroup
    }

    void act() {...}
}</pre>
</div>
</div>
<div class="paragraph">
<p>Actors belonging to the same group share the <strong>underlying thread pool</strong>. With pooled actor groups you can
split your actors to leverage multiple thread pools of different sizes and so assign resources to different
components of your system and tune their performance.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def coreActors = new NonDaemonPGroup(5)  //5 non-daemon threads pool
def helperActors = new DefaultPGroup(1)  //1 daemon thread pool

def priceCalculator = coreActors.actor {
...
}

def paymentProcessor = coreActors.actor {
...
}

def emailNotifier = helperActors.actor {
...
}

def cleanupActor = helperActors.actor {
...
}

//increase size of the core actor group
coreActors.resize 6

//shutdown the group's pool once you no longer need the group to release resources
helperActors.shutdown()</pre>
</div>
</div>
<div class="paragraph">
<p>Do not forget to shutdown custom pooled actor groups, once you no longer need them and their actors, to
preserve system resources.</p>
</div>
</div>
<div class="sect4">
<h5 id="_the_default_actor_group">The default actor group</h5>
<div class="paragraph">
<p>Actors that didn&#8217;t have their parallelGroup property changed or that were created through any of the factory
methods on the <em>Actors</em> class share a common group <em>Actors.defaultActorPGroup</em> . This group uses a
<strong>resizeable thread pool</strong> with an upper limit of <strong>1000 threads</strong> .  This gives you the comfort of having the
pool automatically adjust to the demand of the actors. On the other hand, with a growing number of actors
the pool may become too big an inefficient.  It is advisable to group your actors into your own PGroups with
fixed size thread pools for all but trivial applications.</p>
</div>
</div>
<div class="sect4">
<h5 id="_common_trap_app_terminates_while_actors_do_not_receive_messages">Common trap: App terminates while actors do not receive messages</h5>
<div class="paragraph">
<p>Most likely you&#8217;re using daemon threads and pools, which is the default setting, and your main thread
finishes. Calling <em>actor.join()</em> on any, some or all of your actors would block the main thread until the
actor terminates and thus keep all your actors running.  Alternatively use instances of <em>NonDaemonPGroup</em>
and assign some of your actors to these groups.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def nonDaemonGroup = new NonDaemonPGroup()
def myActor = nonDaemonGroup.actor {...}</pre>
</div>
</div>
<div class="paragraph">
<p>alternatively</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def nonDaemonGroup = new NonDaemonPGroup()

class MyActor extends DefaultActor {
    def MyActor() {
        this.parallelGroup = nonDaemonGroup
    }

    void act() {...}
}

def myActor = new MyActor()</pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_blocking_actors">Blocking Actors</h5>
<div class="paragraph">
<p>Instead of event-driven continuation-styled actors, you may in some scenarios prefer using blocking actors.
Blocking actors hold a single pooled thread for their whole life-time including the time when waiting for
messages.  They avoid some of the thread management overhead, since they never fight for threads after
start, and also they let you write straight code without the necessity of continuation style, since they
only do blocking message reads via the <em>receive</em> method.  Obviously the number of blocking actors running
concurrently is limited by the number of threads available in the shared pool.  On the other hand, blocking
actors typically provide better performance compared to continuation-style actors, especially when the
actor&#8217;s message queue rarely gets empty.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def decryptor = blockingActor {
    while (true) {
        receive {message -&gt;
            if (message instanceof String) reply message.reverse()
            else stop()
        }
    }
}

def console = blockingActor {
    decryptor.send 'lellarap si yvoorG'
    println 'Decrypted message: ' + receive()
    decryptor.send false
}

[decryptor, console]*.join()</pre>
</div>
</div>
<div class="paragraph">
<p>Blocking actors increase the number of options to tune performance of your applications. They may in
particular be good candidates for high-traffic positions in your actor network.</p>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_stateless_actors">Stateless Actors</h3>
<div class="sect3">
<h4 id="_dynamic_dispatch_actor">Dynamic Dispatch Actor</h4>
<div class="paragraph">
<p>The <em>DynamicDispatchActor</em> class is an actor allowing for an alternative structure of the message handling
code. In general <em>DynamicDispatchActor</em> repeatedly scans for messages and dispatches arrived messages to one
of the <em>onMessage(message)</em> methods defined on the actor. The <em>DynamicDispatchActor</em> leverages the Groovy
dynamic method dispatch mechanism under the covers.  Since, unlike <em>DefaultActor</em> descendants, a
<em>DynamicDispatchActor</em> not <em>ReactiveActor</em> (discussed below) do not need to implicitly remember actor&#8217;s
state between subsequent message receptions, they provide much better performance characteristics, generally
comparable to other actor frameworks, like e.g. Scala Actors.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.actor.Actors
import groovyx.gpars.actor.DynamicDispatchActor

final class MyActor extends DynamicDispatchActor {

    void onMessage(String message) {
        println 'Received string'
    }

    void onMessage(Integer message) {
        println 'Received integer'
        reply 'Thanks!'
    }

    void onMessage(Object message) {
        println 'Received object'
        sender.send 'Thanks!'
    }

    void onMessage(List message) {
        println 'Received list'
        stop()
    }
}

final def myActor = new MyActor().start()

Actors.actor {
    myActor 1
    myActor ''
    myActor 1.0
    myActor(new ArrayList())
    myActor.join()
}.join()</pre>
</div>
</div>
<div class="paragraph">
<p>In some scenarios, typically when no implicit conversation-history-dependent state needs to be preserved for
the actor, the dynamic dispatch code structure may be more intuitive than the traditional one using nested
<em>loop</em> and <em>react</em> statements.</p>
</div>
<div class="paragraph">
<p>The <em>DynamicDispatchActor</em> class also provides a handy facility to add message handlers dynamically at actor
construction time or any time later using the <em>when</em> handlers, optionally wrapped inside a <em>become</em> method:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>final Actor myActor = new DynamicDispatchActor().become {
    when {String msg -&gt; println 'A String'; reply 'Thanks'}
    when {Double msg -&gt; println 'A Double'; reply 'Thanks'}
    when {msg -&gt; println 'A something ...'; reply 'What was that?';stop()}
}
myActor.start()
Actors.actor {
    myActor 'Hello'
    myActor 1.0d
    myActor 10 as BigDecimal
    myActor.join()
}.join()</pre>
</div>
</div>
<div class="paragraph">
<p>Obviously the two approaches can be combined:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>final class MyDDA extends DynamicDispatchActor {

    void onMessage(String message) {
        println 'Received string'
    }

    void onMessage(Integer message) {
        println 'Received integer'
    }

    void onMessage(Object message) {
        println 'Received object'
    }

    void onMessage(List message) {
        println 'Received list'
        stop()
    }
}

final def myActor = new MyDDA().become {
    when {BigDecimal num -&gt; println 'Received BigDecimal'}
    when {Float num -&gt; println 'Got a float'}
}.start()
Actors.actor {
    myActor 'Hello'
    myActor 1.0f
    myActor 10 as BigDecimal
    myActor.send([])
    myActor.join()
}.join()</pre>
</div>
</div>
<div class="paragraph">
<p>The dynamic message handlers registered via <em>when</em> take precedence over the static <em>onMessage</em> handlers.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p><em>DynamicDispatchActor</em> can be set to behave in a fair on non-fair (default) manner. Depending on the
strategy chosen, the actor either makes the thread available to other actors sharing the same parallel group
(fair), or keeps the thread fot itself until the message queue gets empty (non-fair). Generally, non-fair
actors perform 2 - 3 times better than fair ones.</p>
</div>
<div class="paragraph">
<p>Use either the <em>fairMessageHandler()</em> factory method or the actor&#8217;s makeFair() method.</p>
</div>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre>    def fairActor = Actors.fairMessageHandler {...}</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_static_dispatch_actor">Static Dispatch Actor</h4>
<div class="paragraph">
<p>While <em>DynamicDispatchActor</em> dispatches messages based on their run-time type and so pays extra performance penalty for each message,
<em>StaticDispatchActor</em> avoids run-time message checks and dispatches the message solely based on the compile-time information.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>final class MyActor extends StaticDispatchActor&lt;String&gt; {
    void onMessage(String message) {
        println 'Received string ' + message

        switch (message) {
            case 'hello':
                reply 'Hi!'
                break
            case 'stop':
                stop()
        }
    }
}</pre>
</div>
</div>
<div class="paragraph">
<p>Instances of <em>StaticDispatchActor</em> have to override the <em>onMessage</em> method appropriate for the actor&#8217;s
declared type parameter.  The <em>onMessage(T message)</em> method is then invoked with every received message.</p>
</div>
<div class="paragraph">
<p>A shorter route towards both fair and non-fair static dispatch actors is available through the helper
factory methods:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>final actor = staticMessageHandler {String message -&gt;
    println 'Received string ' + message

    switch (message) {
        case 'hello':
            reply 'Hi!'
            break
        case 'stop':
            stop()
    }
}

println 'Reply: ' + actor.sendAndWait('hello')
actor 'bye'
actor 'stop'
actor.join()</pre>
</div>
</div>
<div class="paragraph">
<p>Although when compared to <em>DynamicDispatchActor</em> the <em>StaticDispatchActor</em> class is limited to a single
handler method, the simplified creation without any <em>when</em> handlers plus the considerable performance
benefits should make <em>StaticDispatchActor</em> your default choice for straightforward message handlers, when
dispatching based on message run-time type is not necessary.  For example, <em>StaticDispatchActors</em> make
dataflow operators four times faster compared to when using <em>DynamicDispatchActor</em> .</p>
</div>
</div>
<div class="sect3">
<h4 id="_reactive_actor">Reactive Actor</h4>
<div class="paragraph">
<p>The <em>ReactiveActor</em> class, constructed typically by calling <em>Actors.reactor()</em> or <em>DefaultPGroup.reactor()</em>,
allow for more event-driven like approach. When a reactive actor receives a message, the supplied block of
code, which makes up the reactive actor&#8217;s body, is run with the message as a parameter. The result returned
from the code is sent in reply.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>final def group = new DefaultPGroup()

final def doubler = group.reactor {
    2 * it
}

group.actor {
    println 'Double of 10 = ' + doubler.sendAndWait(10)
}

group.actor {
    println 'Double of 20 = ' + doubler.sendAndWait(20)
}

group.actor {
    println 'Double of 30 = ' + doubler.sendAndWait(30)
}

for(i in (1..10)) {
    println "Double of $i = ${doubler.sendAndWait(i)}"
}

doubler.stop()
doubler.join()</pre>
</div>
</div>
<div class="paragraph">
<p>Here&#8217;s an example of an actor, which submits a batch of numbers to a <em>ReactiveActor</em> for processing and then
prints the results gradually as they arrive.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.actor.Actor
import groovyx.gpars.actor.Actors

final def doubler = Actors.reactor {
    2 * it
}

Actor actor = Actors.actor {
    (1..10).each {doubler &lt;&lt; it}
    int i = 0
    loop {
        i += 1
        if (i &gt; 10) stop()
        else {
            react {message -&gt;
                println "Double of $i = $message"
            }
        }
    }
}

actor.join()
doubler.stop()
doubler.join()</pre>
</div>
</div>
<div class="paragraph">
<p>Essentially reactive actors provide a convenience shortcut for an actor that would wait for messages in a
loop, process them and send back the result. This is schematically how the reactive actor looks inside:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>public class ReactiveActor extends DefaultActor {
    Closure body

    void act() {
        loop {
            react {message -&gt;
                reply body(message)
            }
        }
    }
}</pre>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p><em>ReactiveActor</em> can be set to behave in a fair on non-fair (default) manner. Depending on the strategy
chosen, the actor either makes the thread available to other actors sharing the same parallel group (fair),
or keeps the thread fot itself until the message queue gets empty (non-fair). Generally, non-fair actors
perform 2–3 times better than fair ones.</p>
</div>
<div class="paragraph">
<p>Use either the <em>fairReactor()</em> factory method or the actor&#8217;s makeFair() method.</p>
</div>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre>    def fairActor = Actors.fairReactor {...}</pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_tips_and_tricks">Tips and Tricks</h3>
<div class="sect3">
<h4 id="_structuring_actor_s_code">Structuring actor&#8217;s code</h4>
<div class="paragraph">
<p>When extending the <em>DefaultActor</em> class, you can call any actor&#8217;s methods from within the <em>act()</em> method and
use the <em>react()</em> or <em>loop()</em> methods in them.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>class MyDemoActor extends DefaultActor {

    protected void act() {
        handleA()
    }

    private void handleA() {
        react {a -&gt;
            handleB(a)
        }
    }

    private void handleB(int a) {
        react {b -&gt;
            println a + b
            reply a + b
        }
    }
}

final def demoActor = new MyDemoActor()
demoActor.start()

Actors.actor {
    demoActor 10
    demoActor 20
    react {
        println "Result: $it"
    }
}.join()</pre>
</div>
</div>
<div class="paragraph">
<p>Bear in mind that the methods <em>handleA()</em> and <em>handleB()</em> in all our examples will only schedule the supplied message handlers to run as continuations of the current calculation in reaction to the next message arriving.</p>
</div>
<div class="paragraph">
<p>Alternatively, when using the <em>actor()</em> factory method, you can add event-handling code through the meta class as closures.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>Actor demoActor = Actors.actor {
    delegate.metaClass {
        handleA = {-&gt;
            react {a -&gt;
                 handleB(a)
            }
        }

        handleB = {a -&gt;
            react {b -&gt;
                println a + b
                reply a + b
            }
        }
    }

    handleA()
}

Actors.actor {
    demoActor 10
    demoActor 20
    react {
        println "Result: $it"
    }
}.join()</pre>
</div>
</div>
<div class="paragraph">
<p>Closures, which have the actor set as their delegate can also be used to structure event-handling code.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>Closure handleB = {a -&gt;
    react {b -&gt;
        println a + b
        reply a + b
    }
}

Closure handleA = {-&gt;
    react {a -&gt;
        handleB(a)
    }
}

Actor demoActor = Actors.actor {
    handleA.delegate = delegate
    handleB.delegate = delegate

    handleA()
}

Actors.actor {
    demoActor 10
    demoActor 20
    react {
        println "Result: $it"
    }
}.join()</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_event_driven_loops">Event-driven loops</h4>
<div class="paragraph">
<p>When coding event-driven actors you have to have in mind that calls to <em>react()</em> and <em>loop()</em> methods have
slightly different semantics. This becomes a bit of a challenge once you try to implement any types of loops
in your actors.  On the other hand, if you leverage the fact that <em>react()</em> only schedules a continuation
and returns, you may call methods recursively without fear to fill up the stack. Look at the examples below,
which respectively use the three described techniques for structuring actor&#8217;s code.</p>
</div>
<div class="paragraph">
<p>A subclass of <em>DefaultActor</em></p>
</div>
<div class="listingblock">
<div class="content">
<pre>class MyLoopActor extends DefaultActor {

    protected void act() {
        outerLoop()
    }

    private void outerLoop() {
        react {a -&gt;
            println 'Outer: ' + a
            if (a != 0) innerLoop()
            else println 'Done'
        }
    }

    private void innerLoop() {
        react {b -&gt;
            println 'Inner ' + b
            if (b == 0) outerLoop()
            else innerLoop()
        }
    }
}

final def actor = new MyLoopActor().start()
actor 10
actor 20
actor 0
actor 0
actor.join()</pre>
</div>
</div>
<div class="paragraph">
<p>Enhancing the actor&#8217;s metaClass</p>
</div>
<div class="listingblock">
<div class="content">
<pre>Actor actor = Actors.actor {

  delegate.metaClass {
      outerLoop = {-&gt;
          react {a -&gt;
              println 'Outer: ' + a
              if (a!=0) innerLoop()
              else println 'Done'
          }
      }

      innerLoop = {-&gt;
          react {b -&gt;
              println 'Inner ' + b
              if (b==0) outerLoop()
              else innerLoop()
          }
      }
  }

  outerLoop()
}

actor 10
actor 20
actor 0
actor 0
actor.join()</pre>
</div>
</div>
<div class="paragraph">
<p>Using Groovy closures</p>
</div>
<div class="listingblock">
<div class="content">
<pre>Closure innerLoop

Closure outerLoop = {-&gt;
    react {a -&gt;
        println 'Outer: ' + a
        if (a!=0) innerLoop()
        else println 'Done'
    }
}

innerLoop = {-&gt;
    react {b -&gt;
        println 'Inner ' + b
        if (b==0) outerLoop()
        else innerLoop()
    }
}

Actor actor = Actors.actor {
    outerLoop.delegate = delegate
    innerLoop.delegate = delegate

    outerLoop()
}

actor 10
actor 20
actor 0
actor 0
actor.join()</pre>
</div>
</div>
<div class="paragraph">
<p>Plus don&#8217;t forget about the possibility to use the actor&#8217;s <em>loop()</em> method to create a loop that runs until
the actor terminates.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>class MyLoopingActor extends DefaultActor {

  protected void act() {
      loop {
          outerLoop()
      }
  }

  private void outerLoop() {
      react {a -&gt;
          println 'Outer: ' + a
          if (a!=0) innerLoop()
          else println 'Done for now, but will loop again'
      }
  }

  private void innerLoop() {
      react {b -&gt;
          println 'Inner ' + b
          if (b == 0) outerLoop()
          else innerLoop()
      }
  }
}

final def actor = new MyLoopingActor().start()
actor 10
actor 20
actor 0
actor 0
actor 10
actor.stop()
actor.join()</pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_active_objects">Active Objects</h3>
<div class="paragraph">
<p>Active objects provide an OO facade on top of actors, allowing you to avoid dealing directly with the actor
machinery, having to match messages, wait for results and send replies.</p>
</div>
<div class="sect3">
<h4 id="_actors_with_a_friendly_facade">Actors with a friendly facade</h4>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.activeobject.ActiveObject
import groovyx.gpars.activeobject.ActiveMethod

@ActiveObject
class Decryptor {
    @ActiveMethod
    def decrypt(String encryptedText) {
        return encryptedText.reverse()
    }

    @ActiveMethod
    def decrypt(Integer encryptedNumber) {
        return -1*encryptedNumber + 142
    }
}

final Decryptor decryptor = new Decryptor()
def part1 = decryptor.decrypt(' noitcA ni yvoorG')
def part2 = decryptor.decrypt(140)
def part3 = decryptor.decrypt('noitide dn')

print part1.get()
print part2.get()
println part3.get()</pre>
</div>
</div>
<div class="paragraph">
<p>You mark active objects with the <em>@ActiveObject</em> annotation. This will ensure a hidden actor instance is
created for each instance of your class.  Now you can mark methods with the <em>@ActiveMethod</em> annotation
indicating that you want the method to be invoked asynchronously by the target object&#8217;s internal actor.  An
optional boolean <em>blocking</em> parameter to the <em>@ActiveMethod</em> annotation specifies, whether the caller should
block until a result is available or whether instead the caller should only receive a <em>promise</em> for a future
result in a form of a <em>DataflowVariable</em> and so the caller is not blocked waiting.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>By default, all active methods are set to be <strong>non-blocking</strong> . However, methods, which declare their return
type explicitly, must be configured as blocking, otherwise the compiler will report an error. Only <em>def</em> ,
<em>void</em> and <em>DataflowVariable</em> are allowed return types for non-blocking methods.</p>
</div>
</div>
</div>
<div class="paragraph">
<p>Under the covers, GPars will translate your method call to <strong>a message being sent to the internal
actor</strong> . The actor will eventually handle that message by invoking the desired method on behalf of the
caller and once finished a reply will be sent back to the caller.  Non-blocking methods return promises for
results, aka <em>DataflowVariables</em> .</p>
</div>
<div class="sect4">
<h5 id="_but_blocking_means_we_re_not_really_asynchronous_are_we">But blocking means we&#8217;re not really asynchronous, are we?</h5>
<div class="paragraph">
<p>Indeed, if you mark your active methods as <em>blocking</em> , the caller will be blocked waiting for the result,
just like when doing normal plain method invocation.  All we&#8217;ve achieved is being thread-safe inside the
Active object from concurrent access. Something the <em>synchronized</em> keyword could give you as well.  So it is
the <strong>non-blocking</strong> methods that should drive your decision towards using active objects. Blocking methods
will then provide the usual synchronous semantics yet give the consistency guarantees across concurrent
method invocations. The blocking methods are then still very useful when used in combination with
non-blocking ones.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.activeobject.ActiveMethod
import groovyx.gpars.activeobject.ActiveObject
import groovyx.gpars.dataflow.DataflowVariable

@ActiveObject
class Decryptor {
    @ActiveMethod(blocking=true)
    String decrypt(String encryptedText) {
        encryptedText.reverse()
    }

    @ActiveMethod(blocking=true)
    Integer decrypt(Integer encryptedNumber) {
        -1*encryptedNumber + 142
    }
}

final Decryptor decryptor = new Decryptor()
print decryptor.decrypt(' noitcA ni yvoorG')
print decryptor.decrypt(140)
println decryptor.decrypt('noitide dn')</pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_non_blocking_semantics">Non-blocking semantics</h5>
<div class="paragraph">
<p>Now calling the non-blocking active method will return as soon as the actor has been sent a message.  The
caller is now allowed to do whatever he likes, while the actor is taking care of the calculation.  The state
of the calculation can be polled using the <em>bound</em> property on the promise.  Calling the <em>get()</em> method on
the returned promise will block the caller until a value is available.  The call to <em>get()</em> will eventually
return a value or throw an exception, depending on the outcome of the actual calculation.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>The <em>get()</em> method has also a variant with a timeout parameter, if you want to avoid the risk of waiting indefinitely.</p>
</div>
</div>
</div>
<div class="sect5">
<h6 id="_annotation_rules">Annotation rules</h6>
<div class="paragraph">
<p>There are a few rules to follow when annotating your objects:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The <em>ActiveMethod</em> annotations are only accepted in classes annotated as <em>ActiveObject</em></p>
</li>
<li>
<p>Only instance (non-static) methods can be annotated as <em>ActiveMethod</em></p>
</li>
<li>
<p>You can override active methods with non-active ones and vice versa</p>
</li>
<li>
<p>Subclasses of active objects can declare additional active methods, provided they are themselves annotated
as <em>ActiveObject</em></p>
</li>
<li>
<p>Combining concurrent use of active and non-active methods may result in race conditions. Ideally design
your active objects as completely encapsulated classes with all non-private methods marked as active</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_inheritance">Inheritance</h5>
<div class="paragraph">
<p>The <em>@ActiveObject</em> annotation can appear on any class in an inheritance hierarchy. The actor field will
only be created in top-most annotated class in the hierarchy, the subclasses will reuse the field.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.activeobject.ActiveObject
import groovyx.gpars.activeobject.ActiveMethod
import groovyx.gpars.dataflow.DataflowVariable

@ActiveObject
class A {
    @ActiveMethod
    def fooA(value) {
        ...
    }
}

class B extends A {
}

@ActiveObject
class C extends B {
    @ActiveMethod
    def fooC(value1, value2) {
        ...
    }
}</pre>
</div>
</div>
<div class="paragraph">
<p>In our example the actor field will be generated into class <em>A</em> . Class <em>C</em> has to be annotated with
<em>@ActiveObject</em> since it holds the <em>@ActiveMethod</em> annotation on method <em>fooC()</em> , while class <em>B</em> does not
need the annotation, since none of its methods is active.</p>
</div>
</div>
<div class="sect4">
<h5 id="_groups">Groups</h5>
<div class="paragraph">
<p>Just like actors can be grouped around thread pools, active objects can be configured to use threads from
particular parallel groups.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>@ActiveObject("group1")
class MyActiveObject {
    ...
}</pre>
</div>
</div>
<div class="paragraph">
<p>The <em>value</em> parameter to the <em>@ActiveObject</em> annotation specifies a name of parallel group to bind the
internal actor to.  Only threads from the specified group will be used to run internal actors of instances
of the class.  The groups, however, need to be created and registered prior to creation of any of the active
object instances belonging to that group.  If not specified explicitly, an active object will use the
default actor group - <em>Actors.defaultActorPGroup</em> .</p>
</div>
<div class="listingblock">
<div class="content">
<pre>final DefaultPGroup group = new DefaultPGroup(10)
ActiveObjectRegistry.instance.register("group1", group)</pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_alternative_names_for_the_internal_actor">Alternative names for the internal actor</h5>
<div class="paragraph">
<p>You will probably only rarely run into name collisions with the default name for the active object&#8217;s
internal actor field.  May you need to change the default name <em>internalActiveObjectActor</em> , use the
<em>actorName</em> parameter to the <em>@ActiveObject</em> annotation.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>@ActiveObject(actorName = "alternativeActorName")
class MyActiveObject {
    ...
}</pre>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>Alternative names for internal actors as well as their desired groups cannot be overriden in subclasses.
Make sure you only specify these values in the top-most active objects in your inheritance
hierarchy. Obviously, the top most active object is still allowed to subclass other classes, just none of
the predecessors must be an active object.</p>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_classic_examples">Classic Examples</h3>

</div>
<div class="sect2">
<h3 id="_a_few_examples_on_actors_use">A few examples on Actors use</h3>
<div class="ulist">
<ul>
<li>
<p>The Sieve of Eratosthenes</p>
</li>
<li>
<p>Sleeping Barber</p>
</li>
<li>
<p>Dining Philosophers</p>
</li>
<li>
<p>Word Sort</p>
</li>
<li>
<p>Load Balancer</p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_the_sieve_of_eratosthenes">The Sieve of Eratosthenes</h4>
<div class="paragraph">
<p><a href="http://en.wikipedia.org/wiki/Sieve_of_Eratosthenes">Problem description</a></p>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.actor.DynamicDispatchActor

/**
 * Demonstrates concurrent implementation of the Sieve of Eratosthenes using actors
 *
 * In principle, the algorithm consists of concurrently run chained filters,
 * each of which detects whether the current number can be divided by a single prime number.
 * (generate nums 1, 2, 3, 4, 5, ...) -&gt; (filter by mod 2) -&gt; (filter by mod 3) -&gt; (filter by mod 5) -&gt; (filter by mod 7) -&gt; (filter by mod 11) -&gt; (caution! Primes falling out here)
 * The chain is built (grows) on the fly, whenever a new prime is found.
 */

int requestedPrimeNumberBoundary = 1000

final def firstFilter = new FilterActor(2).start()

/**
 * Generating candidate numbers and sending them to the actor chain
 */
(2..requestedPrimeNumberBoundary).each {
    firstFilter it
}
firstFilter.sendAndWait 'Poison'

/**
 * Filter out numbers that can be divided by a single prime number
 */
final class FilterActor extends DynamicDispatchActor {
    private final int myPrime
    private def follower

    def FilterActor(final myPrime) { this.myPrime = myPrime; }

    /**
     * Try to divide the received number with the prime. If the number cannot be divided, send it along the chain.
     * If there's no-one to send it to, I'm the last in the chain, the number is a prime and so I will create and chain
     * a new actor responsible for filtering by this newly found prime number.
     */
    def onMessage(int value) {
        if (value % myPrime != 0) {
            if (follower) follower value
            else {
                println "Found $value"
                follower = new FilterActor(value).start()
            }
        }
    }

    /**
     * Stop the actor on poisson reception
     */
    def onMessage(def poisson) {
        if (follower) {
            def sender = sender
            follower.sendAndContinue(poisson, {this.stop(); sender?.send('Done')})  //Pass the poisson along and stop after a reply
        } else {  //I am the last in the chain
            stop()
            reply 'Done'
        }
    }
}</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_sleeping_barber">Sleeping Barber</h4>
<div class="paragraph">
<p><a href="http://en.wikipedia.org/wiki/Sleeping_barber_problem">Problem description</a></p>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.group.DefaultPGroup
import groovyx.gpars.actor.DefaultActor
import groovyx.gpars.group.DefaultPGroup
import groovyx.gpars.actor.Actor

final def group = new DefaultPGroup()

final def barber = group.actor {
    final def random = new Random()
    loop {
        react {message -&gt;
            switch (message) {
                case Enter:
                    message.customer.send new Start()
                    println "Barber: Processing customer ${message.customer.name}"
                    doTheWork(random)
                    message.customer.send new Done()
                    reply new Next()
                    break
                case Wait:
                    println "Barber: No customers. Going to have a sleep"
                    break
            }
        }
    }
}

private def doTheWork(Random random) {
    Thread.sleep(random.nextInt(10) * 1000)
}

final Actor waitingRoom

waitingRoom = group.actor {
    final int capacity = 5
    final List&lt;Customer&gt; waitingCustomers = []
    boolean barberAsleep = true

    loop {
        react {message -&gt;
            switch (message) {
                case Enter:
                    if (waitingCustomers.size() == capacity) {
                        reply new Full()
                    } else {
                        waitingCustomers &lt;&lt; message.customer
                        if (barberAsleep) {
                            assert waitingCustomers.size() == 1
                            barberAsleep = false
                            waitingRoom.send new Next()
                        }
                        else reply new Wait()
                    }
                    break
                case Next:
                    if (waitingCustomers.size()&gt;0) {
                        def customer = waitingCustomers.remove(0)
                        barber.send new Enter(customer:customer)
                    } else {
                        barber.send new Wait()
                        barberAsleep = true
                    }
            }
        }
    }

}

class Customer extends DefaultActor {
    String name
    Actor localBarbers

    void act() {
        localBarbers &lt;&lt; new Enter(customer:this)
        loop {
            react {message -&gt;
                switch (message) {
                    case Full:
                        println "Customer: $name: The waiting room is full. I am leaving."
                        stop()
                        break
                    case Wait:
                        println "Customer: $name: I will wait."
                        break
                    case Start:
                        println "Customer: $name: I am now being served."
                        break
                    case Done:
                        println "Customer: $name: I have been served."
                        stop();
                        break

                }
            }
        }
    }
}

class Enter { Customer customer }
class Full {}
class Wait {}
class Next {}
class Start {}
class Done {}

def customers = []
customers &lt;&lt; new Customer(name:'Joe', localBarbers:waitingRoom).start()
customers &lt;&lt; new Customer(name:'Dave', localBarbers:waitingRoom).start()
customers &lt;&lt; new Customer(name:'Alice', localBarbers:waitingRoom).start()

sleep 15000
customers &lt;&lt; new Customer(name: 'James', localBarbers: waitingRoom).start()
sleep 5000
customers*.join()
barber.stop()
waitingRoom.stop()</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_dining_philosophers">Dining Philosophers</h4>
<div class="paragraph">
<p><a href="http://en.wikipedia.org/wiki/Dining_philosophers_problem">Problem description</a></p>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.actor.DefaultActor
import groovyx.gpars.actor.Actors

Actors.defaultActorPGroup.resize 5

final class Philosopher extends DefaultActor {
    private Random random = new Random()

    String name
    def forks = []

    void act() {
        assert 2 == forks.size()
        loop {
            think()
            forks*.send new Take()
            def messages = []
            react {a -&gt;
                messages &lt;&lt; [a, sender]
                react {b -&gt;
                    messages &lt;&lt; [b, sender]
                    if ([a, b].any {Rejected.isCase it}) {
                        println "$name: \tOops, can't get my forks! Giving up."
                        final def accepted = messages.find {Accepted.isCase it[0]}
                        if (accepted!=null) accepted[1].send new Finished()
                    } else {
                        eat()
                        reply new Finished()
                    }
                }
            }
        }
    }

    void think() {
        println "$name: \tI'm thinking"
        Thread.sleep random.nextInt(5000)
        println "$name: \tI'm done thinking"
    }

    void eat() {
        println "$name: \tI'm EATING"
        Thread.sleep random.nextInt(2000)
        println "$name: \tI'm done EATING"
    }
}

final class Fork extends DefaultActor {

    String name
    boolean available = true

    void act() {
        loop {
            react {message -&gt;
                switch (message) {
                    case Take:
                        if (available) {
                            available = false
                            reply new Accepted()
                        } else reply new Rejected()
                        break
                    case Finished:
                        assert !available
                        available = true
                        break
                    default: throw new IllegalStateException("Cannot process the message: $message")
                }
            }
        }
    }
}

final class Take {}
final class Accepted {}
final class Rejected {}
final class Finished {}

def forks = [
        new Fork(name:'Fork 1'),
        new Fork(name:'Fork 2'),
        new Fork(name:'Fork 3'),
        new Fork(name:'Fork 4'),
        new Fork(name:'Fork 5')
]

def philosophers = [
        new Philosopher(name:'Joe', forks:[forks[0], forks[1]]),
        new Philosopher(name:'Dave', forks:[forks[1], forks[2]]),
        new Philosopher(name:'Alice', forks:[forks[2], forks[3]]),
        new Philosopher(name:'James', forks:[forks[3], forks[4]]),
        new Philosopher(name:'Phil', forks:[forks[4], forks[0]]),
]

forks*.start()
philosophers*.start()

sleep 10000
forks*.stop()
philosophers*.stop()</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_word_sort">Word sort</h4>
<div class="paragraph">
<p>Given a folder name, the script will sort words in all files in the folder. The <em>SortMaster</em> actor creates a
given number of <em>WordSortActors</em> , splits among them the files to sort words in and collects the results.</p>
</div>
<div class="paragraph">
<p><a href="http://fupeg.blogspot.com/2009/06/scala-concurrency.html">Inspired by Scala Concurrency blog post by Michael Galpin</a></p>
</div>
<div class="listingblock">
<div class="content">
<pre>//Messages
private final class FileToSort { String fileName }
private final class SortResult { String fileName; List&lt;String&gt; words }

//Worker actor
class WordSortActor extends DefaultActor {

    private List&lt;String&gt; sortedWords(String fileName) {
        parseFile(fileName).sort {it.toLowerCase()}
    }

    private List&lt;String&gt; parseFile(String fileName) {
        List&lt;String&gt; words = []
        new File(fileName).splitEachLine(' ') {words.addAll(it)}
        return words
    }

    void act() {
        loop {
            react {message -&gt;
                switch (message) {
                    case FileToSort:
                        println "Sorting file=${message.fileName} on thread ${Thread.currentThread().name}"
                        reply new SortResult(fileName: message.fileName, words: sortedWords(message.fileName))
                }
            }
        }
    }
}

//Master actor
final class SortMaster extends DefaultActor {

    String docRoot = '/'
    int numActors = 1

    List&lt;List&lt;String&gt;&gt; sorted = []
    private CountDownLatch startupLatch = new CountDownLatch(1)
    private CountDownLatch doneLatch

    private void beginSorting() {
        int cnt = sendTasksToWorkers()
        doneLatch = new CountDownLatch(cnt)
    }

    private List createWorkers() {
        return (1..numActors).collect {new WordSortActor().start()}
    }

    private int sendTasksToWorkers() {
        List&lt;Actor&gt; workers = createWorkers()
        int cnt = 0
        new File(docRoot).eachFile {
            workers[cnt % numActors] &lt;&lt; new FileToSort(fileName: it)
            cnt += 1
        }
        return cnt
    }

    public void waitUntilDone() {
        startupLatch.await()
        doneLatch.await()
    }

    void act() {
        beginSorting()
        startupLatch.countDown()
        loop {
            react {
                switch (it) {
                    case SortResult:
                        sorted &lt;&lt; it.words
                        doneLatch.countDown()
                        println "Received results for file=${it.fileName}"
                }
            }
        }
    }
}

//start the actors to sort words
def master = new SortMaster(docRoot: 'c:/tmp/Logs/', numActors: 5).start()
master.waitUntilDone()
println 'Done'

File file = new File("c:/tmp/Logs/sorted_words.txt")
file.withPrintWriter { printer -&gt;
    master.sorted.each { printer.println it }
}</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_load_balancer">Load Balancer</h4>
<div class="paragraph">
<p>Demonstrates work balancing among adaptable set of workers. The load balancer receives tasks and queues them
in a temporary task queue. When a worker finishes his assignment, it asks the load balancer for a new task.</p>
</div>
<div class="paragraph">
<p>If the load balancer doesn&#8217;t have any tasks available in the task queue, the worker is stopped.  If the
number of tasks in the task queue exceeds certain limit, a new worker is created to increase size of the
worker pool.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.actor.Actor
import groovyx.gpars.actor.DefaultActor

/**
 * Demonstrates work balancing among adaptable set of workers.
 * The load balancer receives tasks and queues them in a temporary task queue.
 * When a worker finishes his assignment, it asks the load balancer for a new task.
 * If the load balancer doesn't have any tasks available in the task queue, the worker is stopped.
 * If the number of tasks in the task queue exceeds certain limit, a new worker is created
 * to increase size of the worker pool.
 */

final class LoadBalancer extends DefaultActor {
    int workers = 0
    List taskQueue = []
    private static final QUEUE_SIZE_TRIGGER = 10

    void act() {
        loop {
            react { message -&gt;
                switch (message) {
                    case NeedMoreWork:
                        if (taskQueue.size() == 0) {
                            println 'No more tasks in the task queue. Terminating the worker.'
                            reply DemoWorker.EXIT
                            workers -= 1
                        } else reply taskQueue.remove(0)
                        break
                    case WorkToDo:
                        taskQueue &lt;&lt; message
                        if ((workers == 0) || (taskQueue.size() &gt;= QUEUE_SIZE_TRIGGER)) {
                            println 'Need more workers. Starting one.'
                            workers += 1
                            new DemoWorker(this).start()
                        }
                }
                println "Active workers=${workers}\tTasks in queue=${taskQueue.size()}"
            }
        }
    }
}

final class DemoWorker extends DefaultActor {
    final static Object EXIT = new Object()
    private static final Random random = new Random()

    Actor balancer

    def DemoWorker(balancer) {
        this.balancer = balancer
    }

    void act() {
        loop {
            this.balancer &lt;&lt; new NeedMoreWork()
            react {
                switch (it) {
                    case WorkToDo:
                        processMessage(it)
                        break
                    case EXIT: terminate()
                }
            }
        }

    }

    private void processMessage(message) {
        synchronized (random) {
            Thread.sleep random.nextInt(5000)
        }
    }
}
final class WorkToDo {}
final class NeedMoreWork {}

final Actor balancer = new LoadBalancer().start()

//produce tasks
for (i in 1..20) {
    Thread.sleep 100
    balancer &lt;&lt; new WorkToDo()
}

//produce tasks in a parallel thread
Thread.start {
    for (i in 1..10) {
        Thread.sleep 1000
        balancer &lt;&lt; new WorkToDo()
    }
}

Thread.sleep 35000  //let the queues get empty
balancer &lt;&lt; new WorkToDo()
balancer &lt;&lt; new WorkToDo()
Thread.sleep 10000

balancer.stop()
balancer.join()</pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_agents_2">Agents</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The Agent class, which is a thread-safe non-blocking shared mutable state wrapper implementation inspired by
Agents in Clojure.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">Shared Mutable State can&#8217;t be avoided</div>
<div class="paragraph">
<p>A lot of the concurrency problems disappear when you eliminate the need for Shared Mutable State with your
architecture.  Indeed, concepts like actors, CSP or dataflow concurrency avoid or isolate mutable state
completely.  In some cases, however, sharing mutable data is either inevitable or makes the design more
natural and understandable. Think, for example, of a shopping cart in a typical e-commerce application, when
multiple AJAX requests may hit the cart with read or write requests concurrently.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_introduction_2">Introduction</h3>
<div class="paragraph">
<p>In the Clojure programing language you can find a concept of Agents, the purpose of which is to protect
mutable data that need to be shared across threads.  Agents hide the data and protect it from direct
access. Clients can only send commands (functions) to the agent. The commands will be serialized and
processed against the data one-by-one in turn.  With the commands being executed serially the commands do
not need to care about concurrency and can assume the data is all theirs when run.  Although implemented
differently, GPars Agents, called <em>Agent</em> , fundamentally behave like actors. They accept messages and
process them asynchronously.  The messages, however, must be commands (functions or Groovy closures) and
will be executed inside the agent.  After reception the received function is run against the internal state
of the Agent and the return value of the function is considered to be the new internal state of the Agent.</p>
</div>
<div class="paragraph">
<p>Essentially, agents safe-guard mutable values by allowing only a single <strong>agent-managed thread</strong> to make
modifications to them. The mutable values are <strong>not directly accessible</strong> from outside, but instead <strong>requests
have to be sent to the agent</strong> and the agent guarantees to process the requests sequentially on behalf of the
callers.  Agents guarantee sequential execution of all requests and so consistency of the values.</p>
</div>
<div class="paragraph">
<p>Schematically:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>agent = new Agent(0)  //created a new Agent wrapping an integer with initial value 0
agent.send {increment()}  //asynchronous send operation, sending the increment() function
...
//after some delay to process the message the internal Agent's state has been updated
...
assert agent.val== 1</pre>
</div>
</div>
<div class="paragraph">
<p>To wrap integers, we can certainly use AtomicXXX types on the Java platform, but when the state is a more
complex object we need more support.</p>
</div>
</div>
<div class="sect2">
<h3 id="_concepts">Concepts</h3>
<div class="paragraph">
<p>GPars provides an Agent class, which is a special-purpose thread-safe non-blocking implementation inspired
by Agents in Clojure.</p>
</div>
<div class="paragraph">
<p>An Agent wraps a reference to mutable state, held inside a single field, and accepts code (closures /
commands) as messages, which can be sent to the Agent just like to any other actor using the '&lt;&lt;' operator,
the send() methods or the implicit <em>call()</em> method.  At some point after reception of a closure / command,
the closure is invoked against the internal mutable field and can make changes to it. The closure is
guaranteed to be run without intervention from other threads and so may freely alter the internal state of
the Agent held in the internal <em>data</em> field.</p>
</div>
<div class="paragraph">
<p>The whole update process is of the fire-and-forget type, since once the message (closure) is sent to the
Agent, the caller thread can go off to do other things and come back later to check the current value with
Agent.val or Agent.valAsync(closure).</p>
</div>
<div class="sect3">
<h4 id="_basic_rules">Basic rules</h4>
<div class="ulist">
<ul>
<li>
<p>When executed, the submitted commands obtain the agent&#8217;s state as a parameter.</p>
</li>
<li>
<p>The submitted commands /closures can call any methods on the agent&#8217;s state.</p>
</li>
<li>
<p>Replacing the state object with a new one is also possible and is done using the <strong>updateValue() method</strong>.</p>
</li>
<li>
<p>The <strong>return value</strong> of the submitted closure doesn&#8217;t have a special meaning and is ignored.</p>
</li>
<li>
<p>If the message sent to an <em>Agent</em> is <strong>not a closure</strong>, it is considered to be a <strong>new value</strong> for the internal reference field.</p>
</li>
<li>
<p>The <em>val</em> property of an <em>Agent</em> will wait until all preceding commands in the agent&#8217;s queue are consumed and then safely return the value of the Agent.</p>
</li>
<li>
<p>The <em>valAsync()</em> method will do the same <strong>without blocking</strong> the caller.</p>
</li>
<li>
<p>The <em>instantVal</em> property will return an immediate snapshot of the internal agent&#8217;s state.</p>
</li>
<li>
<p>All Agent instances share a default daemon thread pool. Setting the <em>threadPool</em> property of an Agent instance will allow it to use a different thread pool.</p>
</li>
<li>
<p>Exceptions thrown by the commands can be collected using the <em>errors</em> property.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_examples">Examples</h3>
<div class="sect3">
<h4 id="_shared_list_of_members">Shared list of members</h4>
<div class="paragraph">
<p>The Agent wraps a list of members, who have been added to the jug. To add a new member a message (command to
add a member) has to be sent to the <em>jugMembers</em> Agent.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.agent.Agent import
java.util.concurrent.ExecutorService import java.util.concurrent.Executors

/**
 * Create a new Agent wrapping a list of strings
 */
def jugMembers = new Agent&lt;List&lt;String&gt;&gt;(['Me'])  //add Me

jugMembers.send {it.add 'James'}  //add James

final Thread t1 = Thread.start {
    jugMembers.send {it.add 'Joe'}  //add Joe
}

final Thread t2 = Thread.start {
    jugMembers &lt;&lt; {it.add 'Dave'}  //add Dave
    jugMembers {it.add 'Alice'}    //add Alice (using the implicit call() method)
}

[t1, t2]*.join()
println jugMembers.val
jugMembers.valAsync {println "Current members: $it"}

jugMembers.await()</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_shared_conference_counting_number_of_registrations">Shared conference counting number of registrations</h4>
<div class="paragraph">
<p>The Conference class allows registration and un-registration, however these methods can only be called from
the commands sent to the <em>conference</em> Agent.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.agent.Agent

/**
 * Conference stores number of registrations and allows parties to register and unregister.
 * It inherits from the Agent class and adds the register() and unregister() private methods,
 * which callers may use it the commands they submit to the Conference.
 */
class Conference extends Agent&lt;Long&gt; {
    def Conference() { super(0) }
    private def register(long num) { data += num }
    private def unregister(long num) { data -= num }
}

final Agent conference = new Conference()  //new Conference created

/**
 * Three external parties will try to register/unregister concurrently
 */

final Thread t1 = Thread.start {
    conference &lt;&lt; {register(10L)}               //send a command to register 10 attendees
}

final Thread t2 = Thread.start {
    conference &lt;&lt; {register(5L)}                //send a command to register 5 attendees
}

final Thread t3 = Thread.start {
    conference &lt;&lt; {unregister(3L)}              //send a command to unregister 3 attendees
}

[t1, t2, t3]*.join()

assert 12L == conference.val</pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_factory_methods">Factory methods</h3>
<div class="paragraph">
<p>Agent instances can also be created using the <em>Agent.agent()</em> factory method.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def jugMembers = Agent.agent ['Me']  //add Me</pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_listeners_and_validators">Listeners and validators</h3>
<div class="paragraph">
<p>Agents allow the user to add listeners and validators. While listeners will get notified each time the
internal state changes, validators get a chance to reject a coming change by throwing an exception.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>final Agent counter = new Agent()

counter.addListener {oldValue, newValue -&gt; println "Changing value from $oldValue to $newValue"}
counter.addListener {agent, oldValue, newValue -&gt; println "Agent $agent changing value from $oldValue to $newValue"}

counter.addValidator {oldValue, newValue -&gt; if (oldValue &gt; newValue) throw new IllegalArgumentException('Things can only go up in Groovy')}
counter.addValidator {agent, oldValue, newValue -&gt; if (oldValue == newValue) throw new IllegalArgumentException('Things never stay the same for $agent')}

counter 10
counter 11
counter {updateValue 12}
counter 10  //Will be rejected
counter {updateValue it - 1}  //Will be rejected
counter {updateValue it}  //Will be rejected
counter {updateValue 11}  //Will be rejected
counter 12  //Will be rejected
counter 20
counter.await()</pre>
</div>
</div>
<div class="paragraph">
<p>Both listeners and validators are essentially closures taking two or three arguments. Exceptions thrown from the validators
will be logged inside the agent and can be tested using the <em>hasErrors()</em> method or retrieved through the <em>errors</em> property.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>assert counter.hasErrors()
assert counter.errors.size() == 5</pre>
</div>
</div>
<div class="sect3">
<h4 id="_validator_gotchas">Validator gotchas</h4>
<div class="paragraph">
<p>With Groovy being not very strict on data types and immutability, agent users should be aware of potential bumps on the road.
If the submitted code modifies the state directly, validators will not be able to un-do the change in case of a validation rule violation.
There are two possible solutions available:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Make sure you never change the supplied object representing current agent state</p>
</li>
<li>
<p>Use custom copy strategy on the agent to allow the agent to create copies of the internal state</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>In both cases you need to call <em>updateValue()</em> to set and validate the new state properly.</p>
</div>
<div class="paragraph">
<p>The problem as well as both of the solutions are shown below:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>//Create an agent storing names, rejecting 'Joe'
final Closure rejectJoeValidator = {oldValue, newValue -&gt; if ('Joe' in newValue) throw new IllegalArgumentException('Joe is not allowed to enter our list.')}

Agent agent = new Agent([])
agent.addValidator rejectJoeValidator

agent {it &lt;&lt; 'Dave'}                    //Accepted
agent {it &lt;&lt; 'Joe'}                     //Erroneously accepted, since by-passes the validation mechanism
println agent.val

//Solution 1 - never alter the supplied state object
agent = new Agent([])
agent.addValidator rejectJoeValidator

agent {updateValue(['Dave', * it])}      //Accepted
agent {updateValue(['Joe', * it])}       //Rejected
println agent.val

//Solution 2 - use custom copy strategy on the agent
agent = new Agent([], {it.clone()})
agent.addValidator rejectJoeValidator

agent {updateValue it &lt;&lt; 'Dave'}        //Accepted
agent {updateValue it &lt;&lt; 'Joe'}         //Rejected, since 'it' is now just a copy of the internal agent's state
println agent.val</pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_grouping">Grouping</h3>
<div class="paragraph">
<p>By default all Agent instances belong to the same group sharing its daemon thread pool.</p>
</div>
<div class="paragraph">
<p>Custom groups can also create instances of Agent. These instances will belong to the group, which created
them, and will share a thread pool.  To create an Agent instance belonging to a group, call the <em>agent()</em>
factory method on the group. This way you can organize and tune performance of agents.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>final def group = new NonDaemonPGroup(5)  //create a group around a thread pool
def jugMembers = group.agent(['Me'])  //add Me</pre>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">Custom thread pools for agents</div>
<div class="paragraph">
<p>The default thread pool for agents contains daemon threads. Make sure that your custom thread pools either
use daemon threads, too, which can be achieved either by using DefaultPGroup or by providing your own thread
factory to a thread pool constructor, or in case your thread pools use non-daemon threads, such as when
using the NonDaemonPGroup group class, make sure you shutdown the group or the thread pool explicitly by
calling its shutdown() method, otherwise your applications will not exit.</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_direct_pool_replacement">Direct pool replacement</h4>
<div class="paragraph">
<p>Alternatively, by calling the <em>attachToThreadPool()</em> method on an Agent instance a custom thread pool can be specified for it.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def jugMembers = new Agent&lt;List&lt;String&gt;&gt;(['Me'])  //add Me

final ExecutorService pool = Executors.newFixedThreadPool(10)
jugMembers.attachToThreadPool(new DefaultPool(pool))</pre>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>Remember, like actors, a single Agent instance (aka agent) can never use more than one thread at a time</p>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_the_shopping_cart_example">The shopping cart example</h4>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.agent.Agent

class ShoppingCart {
    private def cartState = new Agent([:])
//----------------- public methods below here ----------------------------------
    public void addItem(String product, int quantity) {
        cartState &lt;&lt; {it[product] = quantity}  //the &lt;&lt; operator sends
                                               //a message to the Agent
    }    public void removeItem(String product) {
        cartState &lt;&lt; {it.remove(product)}
    }    public Object listContent() {
        return cartState.val
    }    public void clearItems() {
        cartState &lt;&lt; performClear
    }

    public void increaseQuantity(String product, int quantityChange) {
        cartState &lt;&lt; this.&amp;changeQuantity.curry(product, quantityChange)
    }
//----------------- private methods below here ---------------------------------
    private void changeQuantity(String product, int quantityChange, Map items) {
        items[product] = (items[product] ?: 0) + quantityChange
    }    private Closure performClear = { it.clear() }
}
//----------------- script code below here -------------------------------------
final ShoppingCart cart = new ShoppingCart()
cart.addItem 'Pilsner', 10
cart.addItem 'Budweisser', 5
cart.addItem 'Staropramen', 20

cart.removeItem 'Budweisser'
cart.addItem 'Budweisser', 15

println "Contents ${cart.listContent()}"

cart.increaseQuantity 'Budweisser', 3
println "Contents ${cart.listContent()}"

cart.clearItems()
println "Contents ${cart.listContent()}"</pre>
</div>
</div>
<div class="paragraph">
<p>You might have noticed two implementation strategies in the code.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Public methods may internally just send the required code off to the Agent, instead of executing the same functionality directly</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>And so sequential code like</p>
</div>
<div class="listingblock">
<div class="content">
<pre>public void addItem(String product, int quantity) {
    cartState[product]=quantity
}</pre>
</div>
</div>
<div class="paragraph">
<p>becomes</p>
</div>
<div class="listingblock">
<div class="content">
<pre>public void addItem(String product, int quantity) {
    cartState &lt;&lt; {it[product] = quantity}
}</pre>
</div>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Public methods may send references to internal private methods or closures, which hold the desired functionality to perform</p>
</li>
</ol>
</div>
<div class="listingblock">
<div class="content">
<pre>public void clearItems() {
    cartState &lt;&lt; performClear
}

private Closure performClear = { it.clear() }</pre>
</div>
</div>
<div class="paragraph">
<p><strong>Currying might be necessary</strong>, if the closure takes other arguments besides the current internal state
 instance. See the <em>increaseQuantity</em> method.</p>
</div>
</div>
<div class="sect3">
<h4 id="_the_printer_service_example">The printer service example</h4>
<div class="paragraph">
<p>Another example, a not thread-safe printer service shared by multiple threads. The printer needs to have
the document and quality properties set before printing, so obviously a potential for race conditions if not
guarded properly. Callers don&#8217;t want to block until the printer is available, which the fire-and-forget
nature of actors solves very elegantly.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.agent.Agent

/**
 * A non-thread-safe service that slowly prints documents on at a time
 */
class PrinterService {
    String document
    String quality

    public void printDocument() {
        println "Printing $document in $quality quality"
        Thread.sleep 5000
        println "Done printing $document"
    }
}

def printer = new Agent&lt;PrinterService&gt;(new PrinterService())

final Thread thread1 = Thread.start {
    for (num in (1..3)) {
        final String text = "document $num"
        printer &lt;&lt; {printerService -&gt;
            printerService.document = text
            printerService.quality = 'High'
            printerService.printDocument()
        }
        Thread.sleep 200
    }
    println 'Thread 1 is ready to do something else. All print tasks have been submitted'
}

final Thread thread2 = Thread.start {
    for (num in (1..4)) {
        final String text = "picture $num"
        printer &lt;&lt; {printerService -&gt;
            printerService.document = text
            printerService.quality = 'Medium'
            printerService.printDocument()
        }
        Thread.sleep 500
    }
    println 'Thread 2 is ready to do something else. All print tasks have been submitted'
}

[thread1, thread2]*.join()
printer.await()</pre>
</div>
</div>
<div class="paragraph">
<p>For latest update, see the respective [Demos].</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_reading_the_value">Reading the value</h3>
<div class="paragraph">
<p>To follow the clojure philosophy closely the Agent class gives reads higher priority than to writes.  By
using the <em>instantVal</em> property your read request will bypass the incoming message queue of the Agent and
return the current snapshot of the internal state.  The <em>val</em> property will wait in the message queue for
processing, just like the non-blocking variant <em>valAsync(Clojure cl)</em> , which will invoke the provided
closure with the internal state as a parameter.</p>
</div>
<div class="paragraph">
<p>You have to bear in mind that the <em>instantVal</em> property might return although correct, but randomly looking
results, since the internal state of the Agent at the time of <em>instantVal</em> execution is non-deterministic
and depends on the messages that have been processed before the thread scheduler executes the body of
<em>instantVal</em> .</p>
</div>
<div class="paragraph">
<p>The <em>await()</em> method allows you to wait for processing all the messages submitted to the Agent before and so
blocks the calling thread.</p>
</div>
</div>
<div class="sect2">
<h3 id="_state_copy_strategy">State copy strategy</h3>
<div class="paragraph">
<p>To avoid leaking the internal state the Agent class allows to specify a copy strategy as the second
constructor argument.  With the copy strategy specified, the internal state is processed by the copy
strategy closure and the output value of the copy strategy value is returned to the caller instead of the
actual internal state. This applies to <em>instantVal</em>, <em>val</em> as well as to <em>valAsync()</em> .</p>
</div>
</div>
<div class="sect2">
<h3 id="_error_handling">Error handling</h3>
<div class="paragraph">
<p>Exceptions thrown from within the submitted commands are stored inside the agent and can be obtained from
the <em>errors</em> property.  The property gets cleared once read.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def jugMembers = new Agent&lt;List&gt;()
assert jugMembers.errors.empty

    jugMembers.send {throw new IllegalStateException('test1')}
    jugMembers.send {throw new IllegalArgumentException('test2')}
    jugMembers.await()

    List errors = jugMembers.errors
    assert 2 == errors.size()
    assert errors[0] instanceof IllegalStateException
    assert 'test1' == errors[0].message
    assert errors[1] instanceof IllegalArgumentException
    assert 'test2' == errors[1].message

    assert jugMembers.errors.empty</pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_fair_and_non_fair_agents">Fair and Non-fair agents</h3>
<div class="paragraph">
<p>Agents can be either fair or non-fair. Fair agents give up the thread after processing each message, non-fair agents keep a thread until their message queue is empty.
As a result, non-fair agents tend to perform better than fair ones.
The default setting for all Agent instances is to be <strong>non-fair</strong>, however by calling its <em>makeFair()</em> method the instance can be made fair.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def jugMembers = new Agent&lt;List&gt;(['Me'])  //add Me
jugMembers.makeFair()</pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_dataflow_2">Dataflow</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Dataflow concurrency offers an alternative concurrency model, which is inherently safe and robust.</p>
</div>
<div class="sect2">
<h3 id="_introduction_3">Introduction</h3>
<div class="paragraph">
<p>Check out the small example written in Groovy using GPars, which sums results of calculations performed by
three concurrently run tasks:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import static groovyx.gpars.dataflow.Dataflow.task

final def x = new DataflowVariable()
final def y = new DataflowVariable()
final def z = new DataflowVariable()

task {
    z &lt;&lt; x.val + y.val
}

task {
    x &lt;&lt; 10
}

task {
    y &lt;&lt; 5
}

println "Result: ${z.val}"</pre>
</div>
</div>
<div class="paragraph">
<p>Or the same algorithm rewritten using the <em>Dataflows</em> class.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import static groovyx.gpars.dataflow.Dataflow.task

final def df = new Dataflows()

task {
    df.z = df.x + df.y
}

task {
    df.x = 10
}

task {
    df.y = 5
}

println "Result: ${df.z}"</pre>
</div>
</div>
<div class="paragraph">
<p>We start three logical tasks, which can run in parallel and perform their particular activities. The tasks
need to exchange data and they do so using <strong>Dataflow Variables</strong>.  Think of Dataflow Variables as one-shot
channels safely and reliably transferring data from producers to their consumers.</p>
</div>
<div class="paragraph">
<p>The Dataflow Variables have a pretty straightforward semantics. When a task needs to read a value from
<em>DataflowVariable</em> (through the val property), it will block until the value has been set by another task or
thread (using the '&lt;&lt;' operator). Each <em>DataflowVariable</em> can be set <strong>only once</strong> in its lifetime. Notice
that you don&#8217;t have to bother with ordering and synchronizing the tasks or threads and their access to
shared variables. The values are magically transferred among tasks at the right time without your
intervention.  The data flow seamlessly among tasks / threads without your intervention or care.</p>
</div>
<div class="paragraph">
<p><strong>Implementation detail:</strong> The three tasks in the example <strong>do not necessarily need to be mapped to three
 physical threads</strong>. Tasks represent so-called "green" or "logical" threads and can be mapped under the
 covers to any number of physical threads. The actual mapping depends on the scheduler, but the outcome of
 dataflow algorithms doesn&#8217;t depend on the actual scheduling.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>The <em>bind</em> operation of dataflow variables silently accepts re-binding to a value, which is equal to an already bound value. Call <em>bindUnique</em> to reject equal values on already-bound variables.</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_benefits">Benefits</h4>
<div class="paragraph">
<p>Here&#8217;s what you gain by using Dataflow Concurrency (by <a href="http://www.jonasboner.com">Jonas Bonér</a>):</p>
</div>
<div class="ulist">
<ul>
<li>
<p>No race-conditions</p>
</li>
<li>
<p>No live-locks</p>
</li>
<li>
<p>Deterministic deadlocks</p>
</li>
<li>
<p>Completely deterministic programs</p>
</li>
<li>
<p>BEAUTIFUL code.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>This doesn&#8217;t sound bad, does it?</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_concepts_2">Concepts</h3>
<div class="sect3">
<h4 id="_dataflow_programming">Dataflow programming</h4>
<div class="sect4">
<h5 id="_quoting_wikipedia">Quoting Wikipedia</h5>
<div class="paragraph">
<p>Operations (in Dataflow programs) consist of "black boxes" with inputs and outputs, all of which are always
explicitly defined. They run as soon as all of their inputs become valid, as opposed to when the program
encounters them. Whereas a traditional program essentially consists of a series of statements saying "do
this, now do this", a dataflow program is more like a series of workers on an assembly line, who will do
their assigned task as soon as the materials arrive. This is why dataflow languages are inherently parallel;
the operations have no hidden state to keep track of, and the operations are all "ready" at the same time.</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_principles">Principles</h4>
<div class="paragraph">
<p>With Dataflow Concurrency you can safely share variables across tasks. These variables (in Groovy instances
of the <em>DataflowVariable</em> class) can only be assigned (using the '&lt;&lt;' operator) a value once in their
lifetime. The values of the variables, on the other hand, can be read multiple times (in Groovy through the
val property), even before the value has been assigned. In such cases the reading task is suspended until
the value is set by another task.  So you can simply write your code for each task sequentially using
Dataflow Variables and the underlying mechanics will make sure you get all the values you need in a
thread-safe manner.</p>
</div>
<div class="paragraph">
<p>In brief, you generally perform three operations with Dataflow variables:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Create a dataflow variable</p>
</li>
<li>
<p>Wait for the variable to be bound (read it)</p>
</li>
<li>
<p>Bind the variable (write to it)</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>And these are the three essential rules your programs have to follow:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>When the program encounters an unbound variable it waits for a value.</p>
</li>
<li>
<p>It is not possible to change the value of a dataflow variable once it is bound.</p>
</li>
<li>
<p>Dataflow variables makes it easy to create concurrent stream agents.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_dataflow_queues_and_broadcasts">Dataflow Queues and Broadcasts</h4>
<div class="paragraph">
<p>Before you go to check the samples of using <strong>Dataflow Variables</strong>, <strong>Tasks</strong> and <strong>Operators</strong>, you should know a
bit about streams and queues to have a full picture of Dataflow Concurrency.  Except for dataflow variables
there are also the concepts of <em>DataflowQueues</em> and <em>DataflowBroadcast</em> that you can leverage in your code.
You may think of them as thread-safe buffers or queues for message transfer among concurrent tasks or
threads. Check out a typical producer-consumer demo:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import static groovyx.gpars.dataflow.Dataflow.task

def words = ['Groovy', 'fantastic', 'concurrency', 'fun', 'enjoy', 'safe', 'GPars', 'data', 'flow']
final def buffer = new DataflowQueue()

task {
    for (word in words) {
        buffer &lt;&lt; word.toUpperCase()  //add to the buffer
    }
}

task {
    while(true) println buffer.val  //read from the buffer in a loop
}</pre>
</div>
</div>
<div class="paragraph">
<p>Both <em>DataflowBroadcasts</em> and <em>DataflowQueues</em> , just like <em>DataflowVariables</em> , implement the
<em>DataflowChannel</em> interface with common methods allowing users to write to them and read values from
them. The ability to treat both types identically through the <em>DataflowChannel</em> interface comes in handy
once you start using them to wire <em>tasks</em> , <em>operators</em> or <em>selectors</em> together.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>The <em>DataflowChannel</em> interface combines two interfaces, each serving its purpose:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>DataflowReadChannel holding all the methods necessary for reading values from a channel - getVal(), getValAsync(), whenBound(), etc.</p>
</li>
<li>
<p>DataflowWriteChannel holding all the methods necessary for writing values into a channel - bind(), &lt;&lt;</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>You may prefer using these dedicated interfaces instead of the general <em>DataflowChannel</em> interface, to better express the intended usage.</p>
</div>
</div>
</div>
<div class="paragraph">
<p>Please refer to the <a href="http://gpars.codehaus.org/API+doc">API doc</a> for more details on the channel interfaces.</p>
</div>
<div class="sect4">
<h5 id="_point_to_point_communication">Point-to-point communication</h5>
<div class="paragraph">
<p>The <em>DataflowQueue</em> class can be viewed as a point-to-point (1 to 1, many to 1) communication channel. It
allows one or more producers send messages to one reader.  If multiple readers read from the same
<em>DataflowQueue</em> , they will each consume different messages. Or to put it a different way, each message is
consumed by exactly one reader.  You can easily imagine a simple load-balancing scheme built around a shared
<em>DataflowQueue</em> with readers being added dynamically when the consumer part of your algorithm needs to
scale up.  This is also a useful default choice when connecting tasks or operators.</p>
</div>
</div>
<div class="sect4">
<h5 id="_publish_subscribe_communication">Publish-subscribe communication</h5>
<div class="paragraph">
<p>The <em>DataflowBroadcast</em> class offers a publish-subscribe (1 to many, many to many) communication model. One
or more producers write messages, while all registered readers will receive all the messages. Each message
is thus consumed by all readers with a valid subscription at the moment when the message is being written to
the channel.  The readers subscribe by calling the <em>createReadChannel()</em> method.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>DataflowWriteChannel broadcastStream = new DataflowBroadcast()
DataflowReadChannel stream1 = broadcastStream.createReadChannel()
DataflowReadChannel stream2 = broadcastStream.createReadChannel()
broadcastStream &lt;&lt; 'Message1'
broadcastStream &lt;&lt; 'Message2'
broadcastStream &lt;&lt; 'Message3'
assert stream1.val == stream2.val
assert stream1.val == stream2.val
assert stream1.val == stream2.val</pre>
</div>
</div>
<div class="paragraph">
<p>Under the hood <em>DataflowBroadcast</em> uses the <em>DataflowStream</em> class to implement the message delivery.</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_dataflowstream">DataflowStream</h4>
<div class="paragraph">
<p>The <em>DataflowStream</em> class represents a deterministic dataflow channel. It is build around the concept of a
functional queue and so provides a lock-free thread-safe implementation for message passing.  Essentially,
you may think of <em>DataflowStream</em> as a 1 to many communication channel, since when a reader consumes a
messages, other readers will still be able to read the message. Also, all messages arrive to all readers in
the same order.  Since <em>DataflowStream</em> is implemented as a functional queue, its API requires that users
traverse the values in the stream themselves.  On the other hand <em>DataflowStream</em> offers handy methods for
value filtering or transformation together with interesting performance characteristics.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>The <em>DataflowStream</em> class, unlike the other communication elements, does not implement the
<em>DataflowChannel</em> interface, since the semantics of its use is different.  Use <em>DataflowStreamReadAdapter</em>
and <em>DataflowStreamWriteAdapter</em> classes to wrap instances of the <em>DataflowChannel</em> class in
<em>DataflowReadChannel</em> or <em>DataflowWriteChannel</em> implementations.</p>
</div>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.dataflow.stream.DataflowStream
import groovyx.gpars.group.DefaultPGroup
import groovyx.gpars.scheduler.ResizeablePool

/**
 * Demonstrates concurrent implementation of the Sieve of Eratosthenes using dataflow tasks
 *
 * In principle, the algorithm consists of a concurrently run chained filters,
 * each of which detects whether the current number can be divided by a single prime number.
 * (generate nums 1, 2, 3, 4, 5, ...) -&gt; (filter by mod 2) -&gt; (filter by mod 3) -&gt; (filter by mod 5) -&gt; (filter by mod 7) -&gt; (filter by mod 11) -&gt; (caution! Primes falling out here)
 * The chain is built (grows) on the fly, whenever a new prime is found
 */

/**
 * We need a resizeable thread pool, since tasks consume threads while waiting blocked for values at DataflowQueue.val
 */
group = new DefaultPGroup(new ResizeablePool(true))

final int requestedPrimeNumberCount = 100

/**
 * Generating candidate numbers
 */
final DataflowStream candidates = new DataflowStream()
group.task {
    candidates.generate(2, {it + 1}, {it &lt; 1000})
}

/**
 * Chain a new filter for a particular prime number to the end of the Sieve
 * @param inChannel The current end channel to consume
 * @param prime The prime number to divide future prime candidates with
 * @return A new channel ending the whole chain
 */
def filter(DataflowStream inChannel, int prime) {
    inChannel.filter { number -&gt;
        group.task {
            number % prime != 0
        }
    }
}

/**
 * Consume Sieve output and add additional filters for all found primes
 */
def currentOutput = candidates
requestedPrimeNumberCount.times {
    int prime = currentOutput.first
    println "Found: $prime"
    currentOutput = filter(currentOutput, prime)
}</pre>
</div>
</div>
<div class="paragraph">
<p>For convenience and for the ability to use <em>DataflowStream</em> with other dataflow constructs, like
e.g. operators, you can wrap it with <em>DataflowReadAdapter</em> for read access or <em>DataflowWriteAdapter</em> for
write access.  The <em>DataflowStream</em> class is designed for single-threaded producers and consumers. If
multiple threads are supposed to read or write values to the stream, their access to the stream must be
serialized externally or the adapters should be used.</p>
</div>
<div class="sect4">
<h5 id="_dataflowstream_adapters">DataflowStream Adapters</h5>
<div class="paragraph">
<p>Since the <em>DataflowStream</em> API as well as the semantics of its use are very different from the one defined
by <em>Dataflow(Read/Write)Channel</em> , adapters have to be used in order to allow <em>DataflowStreams</em> to be used
with other dataflow elements.  The <em>DataflowStreamReadAdapter</em> class will wrap a <em>DataflowStream</em> with
necessary methods to read values, while the <em>DataflowStreamWriteAdapter</em> class will provide write methods
around the wrapped <em>DataflowStream</em> .</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>It is important to mention that the <em>DataflowStreamWriteAdapter</em> is thread safe allowing multiple threads to
add values to the wrapped <em>DataflowStream</em> through the adapter.  On the other hand,
<em>DataflowStreamReadAdapter</em> is designed to be used by a single thread.</p>
</div>
<div class="paragraph">
<p>To minimize the overhead and stay in-line with the <em>DataflowStream</em> semantics, the
<em>DataflowStreamReadAdapter</em> class is not thread-safe and should only be used from within a single thread.
If multiple threads need to read from a DataflowStream, they should each create their own wrapping
<em>DataflowStreamReadAdapter</em> .</p>
</div>
</div>
</div>
<div class="paragraph">
<p>Thanks to the adapters <em>DataflowStream</em> can be used for communication between operators or selectors, which
expect <em>Dataflow(Read/Write)Channels</em> .</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.dataflow.DataflowQueue
import groovyx.gpars.dataflow.stream.DataflowStream
import groovyx.gpars.dataflow.stream.DataflowStreamReadAdapter
import groovyx.gpars.dataflow.stream.DataflowStreamWriteAdapter
import static groovyx.gpars.dataflow.Dataflow.selector
import static groovyx.gpars.dataflow.Dataflow.operator

/**
 * Demonstrates the use of DataflowStreamAdapters to allow dataflow operators to use DataflowStreams
 */

final DataflowStream a = new DataflowStream()
final DataflowStream b = new DataflowStream()
def aw = new DataflowStreamWriteAdapter(a)
def bw = new DataflowStreamWriteAdapter(b)
def ar = new DataflowStreamReadAdapter(a)
def br = new DataflowStreamReadAdapter(b)

def result = new DataflowQueue()

def op1 = operator(ar, bw) {
    bindOutput it
}
def op2 = selector([br], [result]) {
    result &lt;&lt; it
}

aw &lt;&lt; 1
aw &lt;&lt; 2
aw &lt;&lt; 3
assert([1, 2, 3] == [result.val, result.val, result.val])
op1.stop()
op2.stop()
op1.join()
op2.join()</pre>
</div>
</div>
<div class="paragraph">
<p>Also the ability to select a value from multiple <em>DataflowChannels</em> can only be used through an adapter
around a <em>DataflowStream</em> :</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.dataflow.Select
import groovyx.gpars.dataflow.stream.DataflowStream
import groovyx.gpars.dataflow.stream.DataflowStreamReadAdapter
import groovyx.gpars.dataflow.stream.DataflowStreamWriteAdapter
import static groovyx.gpars.dataflow.Dataflow.select
import static groovyx.gpars.dataflow.Dataflow.task

/**
 * Demonstrates the use of DataflowStreamAdapters to allow dataflow select to select on DataflowStreams
 */

final DataflowStream a = new DataflowStream()
final DataflowStream b = new DataflowStream()
def aw = new DataflowStreamWriteAdapter(a)
def bw = new DataflowStreamWriteAdapter(b)
def ar = new DataflowStreamReadAdapter(a)
def br = new DataflowStreamReadAdapter(b)

final Select&lt;?&gt; select = select(ar, br)
task {
    aw &lt;&lt; 1
    aw &lt;&lt; 2
    aw &lt;&lt; 3
}
assert 1 == select().value
assert 2 == select().value
assert 3 == select().value
task {
    bw &lt;&lt; 4
    aw &lt;&lt; 5
    bw &lt;&lt; 6
}
def result = (1..3).collect{select()}.sort{it.value}
assert result*.value == [4, 5, 6]
assert result*.index == [1, 0, 1]</pre>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>If you don&#8217;t need any of the functional queue <em>DataflowStream-special</em> functionality, like generation,
filtering or mapping, you may consider using the <em>DataflowBroadcast</em> class instead, which offers the
<em>publish-subscribe</em> communication model through the <em>DataflowChannel</em> interface.</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_bind_handlers">Bind handlers</h4>
<div class="listingblock">
<div class="content">
<pre>def a = new DataflowVariable()
a &gt;&gt; {println "The variable has just been bound to $it"}
a.whenBound {println "Just to confirm that the variable has been really set to $it"}
...</pre>
</div>
</div>
<div class="paragraph">
<p>Bind handlers can be registered on all dataflow channels (variables, queues or broadcasts) either using the
&gt;&gt; operator and the <em>then()</em> or the <em>whenBound()</em> methods. They will be run once a value is bound to the
variable.</p>
</div>
<div class="paragraph">
<p>Dataflow queues and broadcasts also support a <em>wheneverBound</em> method to register a closure or a message
handler to run each time a value is bound to them.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def queue = new DataflowQueue()
queue.wheneverBound {println "A value $it arrived to the queue"}</pre>
</div>
</div>
<div class="paragraph">
<p>Obviously nothing prevents you from having more of such handlers for a single promise: They will all trigger
in parallel once the promise has a concrete value:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>Promise bookingPromise = task {
    final data = collectData()
    return broker.makeBooking(data)
}
…
bookingPromise.whenBound {booking -&gt; printAgenda booking}
bookingPromise.whenBound {booking -&gt; sendMeAnEmailTo booking}
bookingPromise.whenBound {booking -&gt; updateTheCalendar booking}</pre>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>Dataflow variables and broadcasts are one of several possible ways to implement <em>Parallel
Speculations</em> . For details, please check out <em>Parallel Speculations</em> in the <em>Parallel Collections</em> section
of the User Guide.</p>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_bind_handlers_grouping">Bind handlers grouping</h4>
<div class="paragraph">
<p>When you need to wait for multiple DataflowVariables/Promises to be bound, you can benefit from calling the
<em>whenAllBound()</em> function, which is available on the <em>Dataflow</em> class as well as on <em>PGroup</em> instances.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>    final group = new NonDaemonPGroup()

    //Calling asynchronous services and receiving back promises for the reservations
    Promise flightReservation = flightBookingService('PRG &lt;-&gt; BRU')
    Promise hotelReservation = hotelBookingService('BRU:Feb 24 2009 - Feb 29 2009')
    Promise taxiReservation = taxiBookingService('BRU:Feb 24 2009 10:31')

    //when all reservations have been made we need to build an agenda for our trip
    Promise agenda = group.whenAllBound(flightReservation, hotelReservation, taxiReservation) {flight, hotel, taxi -&gt;
        "Agenda: $flight | $hotel | $taxi"
    }

    //since this is a demo, we will only print the agenda and block till it is ready
    println agenda.val</pre>
</div>
</div>
<div class="paragraph">
<p>If you cannot specify up-front the number of parameters the <em>whenAllBound()</em> handler takes, use a closure
with one argument of type <em>List</em>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>Promise module1 = task {
    compile(module1Sources)
}
Promise module2 = task {
    compile(module2Sources)
}
//We don't know the number of modules that will be jarred together, so use a List
final jarCompiledModules = {List modules -&gt; ...}

whenAllBound([module1, module2], jarCompiledModules)</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_bind_handlers_chaining">Bind handlers chaining</h4>
<div class="paragraph">
<p>All dataflow channels also support the <em>then()</em> method to register a handler (a callback) that should be
invoked when a value becomes available. Unlike <em>whenBound()</em> the <em>then()</em> method allows for chaining, giving
you the option to pass result values between functions asynchronously.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>Notice that Groovy allows us to leave out some of the <em>dots</em> in the <em>then()</em> method chains.</p>
</div>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre>final DataflowVariable variable = new DataflowVariable()
final DataflowVariable result = new DataflowVariable()

variable.then {it * 2} then {it + 1} then {result &lt;&lt; it}
variable &lt;&lt; 4
assert 9 == result.val</pre>
</div>
</div>
<div class="paragraph">
<p>This could be nicely combined with <em>Asynchronous functions</em></p>
</div>
<div class="listingblock">
<div class="content">
<pre>final DataflowVariable variable = new DataflowVariable()
final DataflowVariable result = new DataflowVariable()

final doubler = {it * 2}
final adder = {it + 1}

variable.then doubler then adder then {result &lt;&lt; it}

Thread.start {variable &lt;&lt; 4}
assert 9 == result.val</pre>
</div>
</div>
<div class="paragraph">
<p>or <em>ActiveObjects</em></p>
</div>
<div class="listingblock">
<div class="content">
<pre>@ActiveObject
class ActiveDemoCalculator {
    @ActiveMethod
    def doubler(int value) {
        value * 2
    }

    @ActiveMethod
    def adder(int value) {
        value + 1
    }
}

final DataflowVariable result = new DataflowVariable()
final calculator = new ActiveDemoCalculator();
calculator.doubler(4).then {calculator.adder it}.then {result &lt;&lt; it}
assert 9 == result.val</pre>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">Motivation for chaining Promises</div>
<div class="paragraph">
<p>Chaining can save quite some code when calling other asynchronous services from within <em>whenBound()</em>
handlers. Asynchronous services, such as <em>Asynchronous Functions</em> or <em>Active Methods</em>, return <em>Promises</em> for
their results. To obtain the actual results your handlers would either have to block to wait for the value
to be bound, which would lock the current thread in an unproductive state,</p>
</div>
<div class="listingblock">
<div class="content">
<pre>variable.whenBound {value -&gt;
    Promise promise = asyncFunction(value)
    println promise.get()
}</pre>
</div>
</div>
<div class="paragraph">
<p>or, alternatively, it would register another (nested) <em>whenBound()</em> handler, which would result in
unnecessarily complex code.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>variable.whenBound {value -&gt;
    asyncFunction(value).whenBound {
        println it
    }
}</pre>
</div>
</div>
<div class="paragraph">
<p>For illustration compare the two following code snippets, one using <em>whenBound()</em> and one using <em>then()</em> chaining. They ate both equivalent in terms of functionality and behavior.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>final DataflowVariable variable = new DataflowVariable()

final doubler = {it * 2}
final inc = {it + 1}

//Using whenBound()
variable.whenBound {value -&gt;
    task {
        doubler(value)
    }.whenBound {doubledValue -&gt;
        task {
            inc(doubledValue)
        }.whenBound {incrementedValue -&gt;
            println incrementedValue
        }
    }
}

//Using then() chaining
variable.then doubler then inc then this.&amp;println

Thread.start {variable &lt;&lt; 4}</pre>
</div>
</div>
<div class="paragraph">
<p>Chaining Promises solves both of these issues elegantly:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>variable &gt;&gt; asyncFunction &gt;&gt; {println it}</pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>The <em>RightShift</em> (<em>&gt;&gt;</em>) operator has been overloaded to call <em>then()</em> and so can be chained the same way:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>final DataflowVariable variable = new DataflowVariable()
final DataflowVariable result = new DataflowVariable()

final doubler = {it * 2}
final adder = {it + 1}

variable &gt;&gt; doubler &gt;&gt; adder &gt;&gt; {result &lt;&lt; it}

Thread.start {variable &lt;&lt; 4}

assert 9 == result.val</pre>
</div>
</div>
<div class="sect4">
<h5 id="_error_handling_for_promise_chaining">Error handling for Promise chaining</h5>
<div class="paragraph">
<p>Asynchronous operations may obviously throw exceptions. It is important to be able to handle them easily and
with little effort.  GPars promises can implicitly propagate exceptions from asynchronous calculations
across promise chains.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Promises propagate result values as well as exceptions. The blocking <em>get()</em> method re-throws the
exception that was bound to the Promise and so the caller can handle it.</p>
</li>
<li>
<p>For asynchronous notifications, the <em>whenBound()</em> handler closure gets the exception passed in as an
argument.</p>
</li>
<li>
<p>The <em>then()</em> method accepts two arguments - a <strong>value handler</strong> and an optional <strong>error handler</strong>. These will
be invoked depending on whether the result is a regular value or an exception. If no errorHandler is
specified, the exception is re-thrown to the Promise returned by <em>then()</em> .</p>
</li>
<li>
<p>Exactly the same behavior as for <em>then()</em> holds true for the <em>whenAllBound()</em> method, which listens on
multiple Promises to get bound</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre>    Promise&lt;Integer&gt; initial = new DataflowVariable&lt;Integer&gt;()
    Promise&lt;String&gt; result = initial.then {it * 2} then {100 / it}                  //Will throw exception for 0
            .then {println "Logging the value $it as it passes by"; return it}      //Since no error handler is defined, exceptions will be ignored
                                                                                    //and silently re-thrown to the next handler in the chain
            .then({"The result for $num is $it"}, {"Error detected for $num: $it"}) //Here the exception is caught
    initial &lt;&lt; 0
    println result.get()</pre>
</div>
</div>
<div class="paragraph">
<p>ErrorHandler is a closure that accepts instances of <em>Throwable</em> as its only (optional) argument and returns
a value that should be bound to the result of the <em>then()</em> method call (the returned Promise). If an
exception is thrown from within an error handler, it is bound as an error to the resulting Promise.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>promise.then({it+1})                                                         //Implicitly re-throws potential exceptions bound to promise
promise.then({it+1}, {e -&gt; throw e})                                         //Explicitly re-throws potential exceptions bound to promise
promise.then({it+1}, {e -&gt; throw new RuntimeException('Error occurred', e})  //Explicitly re-throws a new exception wrapping a potential exception bound to promise</pre>
</div>
</div>
<div class="paragraph">
<p>Just like with regular exception handling in Java with try-catch statements, this behavior of GPars promises gives asynchronous invocations the freedom to handle exceptions
at the place where it is most convenient. You may freely ignore exceptions in your code and assume things just work, yet exceptions
will not get accidentally swallowed.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>task {
    'gpars.codehaus.org'.toURL().text  //should throw MalformedURLException
}
.then {page -&gt; page.toUpperCase()}
.then {page -&gt; page.contains('GROOVY')}
.then({mentionsGroovy -&gt; println "Groovy found: $mentionsGroovy"}, {error -&gt; println "Error: $error"}).join()</pre>
</div>
</div>
<div class="sect5">
<h6 id="_handling_concrete_exception_type">Handling concrete exception type</h6>
<div class="paragraph">
<p>You may be also more specific about the handled exception type:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>url.then(download)
    .then(calculateHash, {MalformedURLException e -&gt; return 0})
    .then(formatResult)
    .then(printResult, printError)
    .then(sendNotificationEmail);</pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="_customer_site_exception_handling">Customer-site exception handling</h6>
<div class="paragraph">
<p>You may also leave the exception completely un-handled and let the clients (consumers) handle it:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>Promise&lt;Object&gt; result = url.then(download).then(calculateHash).then(formatResult).then(printResult);
try {
    result.get()
} catch (Exception e) {
    //handle exceptions here
}</pre>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_putting_it_together">Putting it together</h5>
<div class="paragraph">
<p>By combining <em>whenAllBound()</em> and <em>then</em> (or &gt;&gt;) you can easily create large asynchronous scenarios in a convenient way:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>withPool {
    Closure download = {String url -&gt;
        sleep 3000  //Simulate a web read
        'web content'
    }.asyncFun()

    Closure loadFile = {String fileName -&gt;
        'file content'  //simulate a local file read
    }.asyncFun()

    Closure hash = {s -&gt; s.hashCode()}

    Closure compare = {int first, int second -&gt;
        first == second
    }

    Closure errorHandler = {println "Error detected: $it"}

    def all = whenAllBound([
                  download('http://www.gpars.org') &gt;&gt; hash,
                  loadFile('/coolStuff/gpars/website/index.html') &gt;&gt; hash
              ], compare).then({println it}, errorHandler)
    all.join()  //optionally block until the calculation is all done</pre>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>Notice that only the initial action (function) needs to be asynchronous. The functions further down the pipe will be invoked
asynchronously by the promise even if the are synchronous.</p>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_implementing_the_fork_join_pattern_with_promises">Implementing the fork/join pattern with Promises</h5>
<div class="paragraph">
<p>Promises are very flexible and can be used as an implementation vehicle for a lot of different scenarios:.
Here&#8217;s one additional handy capability od Promises. The _thenForkAndJoin() method triggers multiple
activities once the current promise is bound and returns a promise that get bound only after all the
activities finish. Let&#8217;s see how it fits into the picture:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>then()</em> - allows for chaining of activities, so that one is performed after another</p>
</li>
<li>
<p><em>whenAllBound()</em> - allows for joining multiple activities, so that a new activity is started only after they all finish</p>
</li>
<li>
<p><em>task()</em> - allows to create (fork) multiple asynchronous activities</p>
</li>
<li>
<p><em>thenForkAndJoin()</em> - a short-hand for forking several activities and joining on them</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>So with <em>thenForkAndJoin()</em> you simply create multiple activities that should be triggered by a shared (triggering) promise.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>promise.thenForkAndJoin(task1, task2, task3).then{...}</pre>
</div>
</div>
<div class="paragraph">
<p>Once all the activities return a result, they get collected into a list and bound into the promise returned
by <em>thenForkAndJoin()</em> .</p>
</div>
<div class="listingblock">
<div class="content">
<pre>task {
    2
}.thenForkAndJoin({ it ** 2 }, { it**3 }, { it**4 }, { it**5 }).then({ println it}).join()</pre>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_lazy_dataflow_tasks_and_variables">Lazy dataflow tasks and variables</h4>
<div class="paragraph">
<p>Sometimes you may like to combine the qualities of dataflow variables with their lazy initialization.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>Closure&lt;String&gt; download = {url -&gt;
    println "Downloading"
    url.toURL().text
}

def pageContent = new LazyDataflowVariable(download.curry("http://gpars.codehaus.org"))</pre>
</div>
</div>
<div class="paragraph">
<p>Instances of <em>LazyDataflowVariable</em> have an initializer specified at construction time, which only gets
triggered when someone asks for its value, either through the blocking <em>get()</em> method or using any of the
non-blocking callback methods, such as <em>then()</em> .  Since <em>LazyDataflowVariables</em> preserve all the goodies of
ordinary <em>DataflowVariables</em> , you can again chain them easily with other <em>lazy</em> or <em>ordinary</em> dataflow
variables.</p>
</div>
<div class="sect4">
<h5 id="_example">Example</h5>
<div class="paragraph">
<p>This deserves a more practical example. Taking inspiration from
<a href="http://blog.jcoglan.com/2013/03/30/callbacks-are-imperative-promises-are-functional-nodes-biggest-missed-opportunity/" class="bare">http://blog.jcoglan.com/2013/03/30/callbacks-are-imperative-promises-are-functional-nodes-biggest-missed-opportunity/</a>
the following piece of code demonstrates use of <em>LazyDataflowVariables</em> to lazily and asynchronously load
mutually dependent components into memory.  The components (modules) will be loaded in the order of their
dependencies and concurrently, if possible.  Each module will only be loaded once, irrespective of the
number of modules that depend on it.  Thanks to laziness only the modules that are transitively needed will
be loaded.  Our example uses a simple "diamond" dependency scheme:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>D depends on B and C</p>
</li>
<li>
<p>C depends on A</p>
</li>
<li>
<p>B depends on A</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>When loading D, A will get loaded first. B and C will be loaded concurrently once A has been loaded. D will
start loading once both B and C have been loaded.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def moduleA = new LazyDataflowVariable({-&gt;
    println "Loading moduleA into memory"
    sleep 3000
    println "Loaded moduleA into memory"
    return "moduleA"
})

def moduleB = new LazyDataflowVariable({-&gt;
    moduleA.then {
        println "-&gt;Loading moduleB into memory, since moduleA is ready"
        sleep 3000
        println "  Loaded moduleB into memory"
        return "moduleB"
    }
})

def moduleC = new LazyDataflowVariable({-&gt;
    moduleA.then {
        println "-&gt;Loading moduleC into memory, since moduleA is ready"
        sleep 3000
        println "  Loaded moduleC into memory"
        return "moduleC"
    }
})

def moduleD = new LazyDataflowVariable({-&gt;
    whenAllBound(moduleB, moduleC) { b, c -&gt;
        println "--&gt;Loading moduleD into memory, since moduleB and moduleC are ready"
        sleep 3000
        println "   Loaded moduleD into memory"
        return "moduleD"
    }
})

println "Nothing loaded so far"
println "==================================================================="
println "Load module: " + moduleD.get()
println "==================================================================="
println "All requested modules loaded"</pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_making_tasks_lazy">Making tasks lazy</h5>
<div class="paragraph">
<p>The <em>lazyTask()</em> method is available alongside the <em>task()</em> method to give the users a task-oriented
abstraction for delayed activities.  A <strong>Lazy Task</strong> returns an instance of <em>LazyDataflowVariable</em> (a
<em>Promise</em> ) with the initializer set to the provided closure.  As soon as someone asks for the value, the
task will start asynchronously and eventually deliver a value into the <em>LazyDataflowVariable</em> .</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.dataflow.Dataflow

def pageContent = Dataflow.lazyTask {
        println "Downloading"
        "http://gpars.codehaus.org".toURL().text
    }

println "No-one has asked for the value just yet. Bound = ${pageContent.bound}"
sleep 1000
println "Now going to ask for a value"
println pageContent.get().size()
println "Repetitive requests will receive the already calculated value. No additional downloading."
println pageContent.get().size()</pre>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_dataflow_expressions">Dataflow Expressions</h4>
<div class="paragraph">
<p>Look at the magic below:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def initialDistance = new DataflowVariable()
def acceleration = new DataflowVariable()
def time = new DataflowVariable()

task {
    initialDistance &lt;&lt; 100
    acceleration &lt;&lt; 2
    time &lt;&lt; 10
}

def result = initialDistance + acceleration*0.5*time**2
println 'Total distance ' + result.val</pre>
</div>
</div>
<div class="paragraph">
<p>We use DataflowVariables that represent several parameters to a mathematical equation calculating total
distance of an accelerating object.  In the equation itself, however, we use the DataflowVariables
directly. We do not refer to the values they represent and yet we are able to do the math correctly. This
shows that DataflowVariables can be very flexible.</p>
</div>
<div class="paragraph">
<p>For example, you can call methods on them and these methods will get dispatched to the bound values:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def name = new DataflowVariable()
task {
    name &lt;&lt; '  adam   '
}
println name.toUpperCase().trim().val</pre>
</div>
</div>
<div class="paragraph">
<p>You can pass other DataflowVariables as arguments to such methods and the real values will be passed
automatically instead:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def title = new DataflowVariable()
def searchPhrase = new DataflowVariable()
task {
    title &lt;&lt; ' Groovy in Action 2nd edition   '
}

task {
    searchPhrase &lt;&lt; '2nd'
}

println title.trim().contains(searchPhrase).val</pre>
</div>
</div>
<div class="paragraph">
<p>And you can also query properties of the bound value using directly the DataflowVariable:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def book = new DataflowVariable()
def searchPhrase = new DataflowVariable()
task {
    book &lt;&lt; [
             title:'Groovy in Action 2nd edition   ',
             author:'Dierk Koenig',
             publisher:'Manning']
}

task {
    searchPhrase &lt;&lt; '2nd'
}

book.title.trim().contains(searchPhrase).whenBound {println it}  //Asynchronous waiting

println book.title.trim().contains(searchPhrase).val  //Synchronous waiting</pre>
</div>
</div>
<div class="paragraph">
<p>Please note that the result is still a DataflowVariable (DataflowExpression to be precise), which you can
get the real value from both synchronously and asynchronously.</p>
</div>
</div>
<div class="sect3">
<h4 id="_bind_error_notification">Bind error notification</h4>
<div class="paragraph">
<p><em>DataflowVariables</em> offer the ability to send notifications to the registered listeners whenever a bind
operation fails. The <em>getBindErrorManager()</em> method allows for listener to be added and removed.  The
listeners get notified in case of a failed attempt to bind a value (through bind(), bindSafely(),
bindUnique() or leftShift()) or an error (through bindError()).</p>
</div>
<div class="listingblock">
<div class="content">
<pre>        final DataflowVariable variable = new DataflowVariable()

        variable.getBindErrorManager().addBindErrorListener(new BindErrorListener() {
            @Override
            void onBindError(final Object oldValue, final Object failedValue, final boolean uniqueBind) {
                println "Bind failed!"
            }

            @Override
            void onBindError(final Object oldValue, final Throwable failedError) {
                println "Binding an error failed!"
            }

            @Override
            public void onBindError(final Throwable oldError, final Object failedValue, final boolean uniqueBind) {
                println "Bind failed!"
            }

            @Override
            public void onBindError(final Throwable oldError, final Throwable failedError) {
                println "Binding an error failed!"
            }

        })</pre>
</div>
</div>
<div class="paragraph">
<p>This allows you to customize reactions to attempts to binding of already bound dataflow variables. For
example, using <em>bindSafely()</em> you do not get bind exceptions fired to the caller, but instead a registered
<em>BindErrorListener</em> gets notified.</p>
</div>
</div>
<div class="sect3">
<h4 id="_further_reading">Further reading</h4>
<div class="paragraph">
<p><a href="http://github.com/jboner/scala-dataflow/tree/f9a38992f5abed4df0b12f6a5293f703aa04dc33/src">Scala Dataflow library</a> by Jonas Bonér</p>
</div>
<div class="paragraph">
<p><a href="http://jonasboner.com/talks/state_youre_doing_it_wrong/html/all.html">JVM concurrency presentation slides</a> by Jonas Bonér</p>
</div>
<div class="paragraph">
<p><a href="http://github.com/larrytheliquid/dataflow/tree/master">Dataflow Concurrency library for Ruby</a></p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_tasks">Tasks</h3>
<div class="paragraph">
<p>The <strong>Dataflow tasks</strong> give you an easy-to-grasp abstraction of mutually-independent logical tasks or threads,
which can run concurrently and exchange data solely through Dataflow Variables, Queues, Broadcasts and
Streams.  Dataflow tasks with their easy-to-express mutual dependencies and inherently sequential body could
also be used as a practical implementation of UML <em>Activity Diagrams</em> .</p>
</div>
<div class="paragraph">
<p>Check out the examples.</p>
</div>
<div class="sect3">
<h4 id="_a_simple_mashup_example">A simple mashup example</h4>
<div class="paragraph">
<p>In the example we&#8217;re downloading the front pages of three popular web sites, each in their own task, while
in a separate task we&#8217;re filtering out sites talking about Groovy today and forming the output. The output
task synchronizes automatically with the three download tasks on the three Dataflow variables through which
the content of each website is passed to the output task.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import static groovyx.gpars.GParsPool.withPool
import groovyx.gpars.dataflow.DataflowVariable
import static groovyx.gpars.dataflow.Dataflow.task


/**
 * A simple mashup sample, downloads content of three websites
 * and checks how many of them refer to Groovy.
 */

def dzone = new DataflowVariable()
def jroller = new DataflowVariable()
def theserverside = new DataflowVariable()

task {
    println 'Started downloading from DZone'
    dzone &lt;&lt; 'http://www.dzone.com'.toURL().text
    println 'Done downloading from DZone'
}

task {
    println 'Started downloading from JRoller'
    jroller &lt;&lt; 'http://www.jroller.com'.toURL().text
    println 'Done downloading from JRoller'
}

task {
    println 'Started downloading from TheServerSide'
    theserverside &lt;&lt; 'http://www.theserverside.com'.toURL().text
    println 'Done downloading from TheServerSide'
}

task {
    withPool {
        println "Number of Groovy sites today: " +
                ([dzone, jroller, theserverside].findAllParallel {
                    it.val.toUpperCase().contains 'GROOVY'
                }).size()
    }
}.join()</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_grouping_tasks">Grouping tasks</h4>
<div class="paragraph">
<p>Dataflow tasks can be organized into groups to allow for performance fine-tuning. Groups provide a handy
<em>task()</em> factory method to create tasks attached to the groups.  Using groups allows you to organize tasks
or operators around different thread pools (wrapped inside the group).  While the Dataflow.task() command
schedules the task on a default thread pool (java.util.concurrent.Executor, fixed size=#cpu+1, daemon
threads), you may prefer being able to define your own thread pool(s) to run your tasks.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.group.DefaultPGroup

def group = new DefaultPGroup()

group.with {
    task {
        ...
    }

    task {
        ...
    }
}</pre>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">Custom thread pools for dataflow</div>
<div class="paragraph">
<p>The default thread pool for dataflow tasks contains daemon threads, which means your application will exit
as soon as the main thread finishes and won&#8217;t wait for all tasks to complete.  When grouping tasks, make
sure that your custom thread pools either use daemon threads, too, which can be achieved by using
DefaultPGroup or by providing your own thread factory to a thread pool constructor, or in case your thread
pools use non-daemon threads, such as when using the NonDaemonPGroup group class, make sure you shutdown the
group or the thread pool explicitly by calling its shutdown() method, otherwise your applications will not
exit.</p>
</div>
</div>
</div>
<div class="paragraph">
<p>You may selectively override the default group used for tasks, operators, callbacks and other dataflow
elements inside a code block using the <em>Dataflow.usingGroup()</em> method:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>Dataflow.usingGroup(group) {
    task {
        'http://gpars.codehaus.org'.toURL().text  //should throw MalformedURLException
    }
    .then {page -&gt; page.toUpperCase()}
    .then {page -&gt; page.contains('GROOVY')}
    .then({mentionsGroovy -&gt; println "Groovy found: $mentionsGroovy"}, {error -&gt; println "Error: $error"}).join()
}</pre>
</div>
</div>
<div class="paragraph">
<p>You can always override the default group by being specific:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>Dataflow.usingGroup(group) {
    anotherGroup.task {
        'http://gpars.codehaus.org'.toURL().text  //should throw MalformedURLException
    }
    .then(anotherGroup) {page -&gt; page.toUpperCase()}
    .then(anotherGroup) {page -&gt; page.contains('GROOVY')}.then(anotherGroup) {println Dataflow.retrieveCurrentDFPGroup();it}
    .then(anotherGroup, {mentionsGroovy -&gt; println "Groovy found: $mentionsGroovy"}, {error -&gt; println "Error: $error"}).join()
}</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_a_mashup_variant_with_methods">A mashup variant with methods</h4>
<div class="paragraph">
<p>To avoid giving you wrong impression about structuring the Dataflow code, here&#8217;s a rewrite of the mashup
example, with a <em>downloadPage()</em> method performing the actual download in a separate task and returning a
DataflowVariable instance, so that the main application thread could eventually get hold of the downloaded
content.  Dataflow variables can obviously be passed around as parameters or return values.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>package groovyx.gpars.samples.dataflow

import static groovyx.gpars.GParsExecutorsPool.withPool
import groovyx.gpars.dataflow.DataflowVariable
import static groovyx.gpars.dataflow.Dataflow.task


/**
 * A simple mashup sample, downloads content of three websites and checks how many of them refer to Groovy.
 */
final List urls = ['http://www.dzone.com', 'http://www.jroller.com', 'http://www.theserverside.com']

task {
    def pages = urls.collect { downloadPage(it) }
    withPool {
        println "Number of Groovy sites today: " +
                (pages.findAllParallel {
                    it.val.toUpperCase().contains 'GROOVY'
                }).size()
    }
}.join()

def downloadPage(def url) {
    def page = new DataflowVariable()
    task {
        println "Started downloading from $url"
        page &lt;&lt; url.toURL().text
        println "Done downloading from $url"
    }
    return page
}</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_a_physical_calculation_example">A physical calculation example</h4>
<div class="paragraph">
<p>Dataflow programs naturally scale with the number of processors. Up to a certain level, the more processors
you have the faster the program runs.  Check out, for example, the following script, which calculates
parameters of a simple physical experiment and prints out the results. Each task performs its part of the
calculation and may depend on values calculated by some other tasks as well as its result might be needed by
some of the other tasks. With Dataflow Concurrency you can split the work between tasks or reorder the tasks
themselves as you like and the dataflow mechanics will ensure the calculation will be accomplished
correctly.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.dataflow.DataflowVariable
import static groovyx.gpars.dataflow.Dataflow.task

final def mass = new DataflowVariable()
final def radius = new DataflowVariable()
final def volume = new DataflowVariable()
final def density = new DataflowVariable()
final def acceleration = new DataflowVariable()
final def time = new DataflowVariable()
final def velocity = new DataflowVariable()
final def decelerationForce = new DataflowVariable()
final def deceleration = new DataflowVariable()
final def distance = new DataflowVariable()

def t = task {
    println """

Calculating distance required to stop a moving ball.
====================================================
The ball has a radius of ${radius.val} meters and is made of a material with ${density.val} kg/m3 density,
which means that the ball has a volume of ${volume.val} m3 and a mass of ${mass.val} kg.
The ball has been accelerating with ${acceleration.val} m/s2 from 0 for ${time.val} seconds and so reached a velocity of ${velocity.val} m/s.

Given our ability to push the ball backwards with a force of ${decelerationForce.val} N (Newton), we can cause a deceleration
of ${deceleration.val} m/s2 and so stop the ball at a distance of ${distance.val} m.

=======================================================================================================================
This example has been calculated asynchronously in multiple tasks using GPars Dataflow concurrency in Groovy.
Author: ${author.val}
"""

    System.exit 0
}

task {
    mass &lt;&lt; volume.val * density.val
}

task {
    volume &lt;&lt; Math.PI * (radius.val ** 3)
}

task {
    radius &lt;&lt; 2.5
    density &lt;&lt; 	998.2071  //water
    acceleration &lt;&lt; 9.80665 //free fall
    decelerationForce &lt;&lt; 900
}

task {
    println 'Enter your name:'
    def name = new InputStreamReader(System.in).readLine()
    author &lt;&lt; (name?.trim()?.size()&gt;0 ? name : 'anonymous')
}

task {
    time &lt;&lt; 10
    velocity &lt;&lt; acceleration.val * time.val
}

task {
    deceleration &lt;&lt; decelerationForce.val / mass.val
}

task {
    distance &lt;&lt; deceleration.val * ((velocity.val/deceleration.val) ** 2) * 0.5
}

t.join()</pre>
</div>
</div>
<div class="paragraph">
<p>Note: I did my best to make all the physical calculations right. Feel free to change the values and see how
long distance you need to stop the rolling ball.</p>
</div>
</div>
<div class="sect3">
<h4 id="_deterministic_deadlocks">Deterministic deadlocks</h4>
<div class="paragraph">
<p>If you happen to introduce a deadlock in your dependencies, the deadlock will occur each time you run the
code. No randomness allowed. That&#8217;s one of the benefits of Dataflow concurrency. Irrespective of the actual
thread scheduling scheme, if you don&#8217;t get a deadlock in tests, you won&#8217;t get them in production.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>task {
    println a.val
    b &lt;&lt; 'Hi there'
}

task {
    println b.val
    a &lt;&lt; 'Hello man'
}</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_dataflows_map">Dataflows map</h4>
<div class="paragraph">
<p>As a handy shortcut the <em>Dataflows</em> class can help you reduce the amount of code you have to write to
leverage Dataflow variables.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def df = new Dataflows()
df.x = 'value1'
assert df.x == 'value1'

Dataflow.task {df.y = 'value2}

assert df.y == 'value2'</pre>
</div>
</div>
<div class="paragraph">
<p>Think of Dataflows as a map with Dataflow Variables as keys storing their bound values as appropriate map
values. The semantics of reading a value (e.g. df.x) and binding a value (e.g. df.x = 'value') remain
identical to the semantics of plain Dataflow Variables (x.val and x &lt;&lt; 'value' respectively).</p>
</div>
<div class="sect4">
<h5 id="_mixing_em_dataflows_em_and_groovy_em_with_em_blocks">Mixing <em>Dataflows</em> and Groovy <em>with</em> blocks</h5>
<div class="paragraph">
<p>When inside a <em>with</em> block of a Dataflows instance, the dataflow variables stored inside the Dataflows
instance can be accessed directly without the need to prefix them with the Dataflows instance identifier.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>new Dataflows().with {
    x = 'value1'
    assert x == 'value1'

    Dataflow.task {y = 'value2}

    assert y == 'value2'
}</pre>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_returning_a_value_from_a_task">Returning a value from a task</h4>
<div class="paragraph">
<p>Typically dataflow tasks communicate through dataflow variables. On top of that, tasks can also return
values, again through a dataflow variable.  When you invoke the <em>task()</em> factory method, you get back an
instance of Promise (implemented as DataflowVariable), through which you can listen for the task&#8217;s return
value, just like when using any other Promise or DataflowVariable.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>    final Promise t1 = task {
        return 10
    }
    final Promise t2 = task {
        return 20
    }
    def results = [t1, t2]*.val
    println 'Both sub-tasks finished and returned values: ' + results</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>Obviously the value can also be obtained without blocking the caller using the _whenBound()_ method.</pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre>def task = task {
    println 'The task is running and calculating the return value'
    30
}
task &gt;&gt; {value -&gt; println "The task finished and returned $value"}</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>=== Joining tasks</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>Using the _join()_ operation on the result dataflow variable of a task you can block until the task finishes.</pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre> task {
     final Promise t1 = task {
         println 'First sub-task running.'
     }
     final Promise t2 = task {
         println 'Second sub-task running'
     }
     [t1, t2]*.join()
     println 'Both sub-tasks finished'
 }.join()</pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_selects">Selects</h3>
<div class="paragraph">
<p>Frequently a value needs to be obtained from one of several dataflow channels (variables, queues, broadcasts
or streams). The <em>Select</em> class is suitable for such scenarios.  <em>Select</em> can scan multiple dataflow
channels and pick one channel from all the input channels, which currently have a value available for read.
The value from that channels is read and returned to the caller together with the index of the originating
channel.  Picking the channel is either random, or based on channel priority, in which case channels with
lower position index in the <em>Select</em> constructor have higher priority.</p>
</div>
<div class="sect3">
<h4 id="_selecting_a_value_from_multiple_channels">Selecting a value from multiple channels</h4>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.dataflow.DataflowQueue
import groovyx.gpars.dataflow.DataflowVariable
import static groovyx.gpars.dataflow.Dataflow.select
import static groovyx.gpars.dataflow.Dataflow.task

/**
 * Shows a basic use of Select, which monitors a set of input channels for values and makes these values
 * available on its output irrespective of their original input channel.
 * Note that dataflow variables and queues can be combined for Select.
 *
 * You might also consider checking out the prioritySelect method, which prioritizes values by the index of their input channel
 */
def a = new DataflowVariable()
def b = new DataflowVariable()
def c = new DataflowQueue()

task {
    sleep 3000
    a &lt;&lt; 10
}

task {
    sleep 1000
    b &lt;&lt; 20
}

task {
    sleep 5000
    c &lt;&lt; 30
}

def select = select([a, b, c])
println "The fastest result is ${select().value}"</pre>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>Note that the return type from <em>select()</em> is <em>SelectResult</em> , holding the value as well as the originating
channel index.</p>
</div>
</div>
</div>
<div class="paragraph">
<p>There are multiple ways to read values from a Select:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def sel = select(a, b, c, d)
def result = sel.select()                                       //Random selection
def result = sel()                                              //Random selection (a short-hand variant)
def result = sel.select([true, true, false, true])              //Random selection with guards specified
def result = sel([true, true, false, true])                     //Random selection with guards specified (a short-hand variant)
def result = sel.prioritySelect()                               //Priority selection
def result = sel.prioritySelect([true, true, false, true])      //Priority selection with guards specifies</pre>
</div>
</div>
<div class="paragraph">
<p>By default the <em>Select</em> blocks the caller until a value to read is available. The alternative
<em>selectToPromise()</em> and <em>prioritySelectToPromise()</em> methods give you a way to obtain a promise for the value
that will be selected some time in the future. Through the returned Promise you may register a callback to
get invoked asynchronously whenever the next value is selected.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def sel = select(a, b, c, d)
Promise result = sel.selectToPromise()                                       //Random selection
Promise result = sel.selectToPromise([true, true, false, true])              //Random selection with guards specified
Promise result = sel.prioritySelectToPromise()                               //Priority selection
Promise result = sel.prioritySelectToPromise([true, true, false, true])      //Priority selection with guards specifies</pre>
</div>
</div>
<div class="paragraph">
<p>Alternatively, <em>Select</em> allows to have the value sent to a provided <em>MessageStream</em> (e.g. an actor) without
blocking the caller.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def handler = actor {...}
def sel = select(a, b, c, d)

sel.select(handler)                                         //Random selection
sel(handler)                                                //Random selection (a short-hand variant)
sel.select(handler, [true, true, false, true])              //Random selection with guards specified
sel(handler, [true, true, false, true])                     //Random selection with guards specified (a short-hand variant)
sel.prioritySelect(handler)                                 //Priority selection
sel.prioritySelect(handler, [true, true, false, true])      //Priority selection with guards specifies</pre>
</div>
</div>
<div class="sect4">
<h5 id="_guards">Guards</h5>
<div class="paragraph">
<p>Guards allow the caller to omit some input channels from the selection. Guards are specified as a List of
boolean flags passed to the <em>select()</em> or <em>prioritySelect()</em> methods.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def sel = select(leaders, seniors, experts, juniors)
def teamLead = sel([true, true, false, false]).value        //Only 'leaders' and 'seniors' qualify for becoming a teamLead here</pre>
</div>
</div>
<div class="paragraph">
<p>A typical use for guards is to make Selects flexible to adopt to the changes in the user state.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.dataflow.DataflowQueue
import static groovyx.gpars.dataflow.Dataflow.select
import static groovyx.gpars.dataflow.Dataflow.task

/**
 * Demonstrates the ability to enable/disable channels during a value selection on a select by providing boolean guards.
 */
final DataflowQueue operations = new DataflowQueue()
final DataflowQueue numbers = new DataflowQueue()

def t = task {
    final def select = select(operations, numbers)
    3.times {
        def instruction = select([true, false]).value
        def num1 = select([false, true]).value
        def num2 = select([false, true]).value
        final def formula = "$num1 $instruction $num2"
        println "$formula = ${new GroovyShell().evaluate(formula)}"
    }
}

task {
    operations &lt;&lt; '+'
    operations &lt;&lt; '+'
    operations &lt;&lt; '*'
}

task {
    numbers &lt;&lt; 10
    numbers &lt;&lt; 20
    numbers &lt;&lt; 30
    numbers &lt;&lt; 40
    numbers &lt;&lt; 50
    numbers &lt;&lt; 60
}

t.join()</pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_priority_select">Priority Select</h5>
<div class="paragraph">
<p>When certain channels should have precedence over others when selecting, the prioritySelect methods should
be used instead.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>/**
 * Shows a basic use of Priority Select, which monitors a set of input channels for values and makes these values
 * available on its output irrespective of their original input channel.
 * Note that dataflow variables, queues and broadcasts can be combined for Select.
 * Unlike plain select method call, the prioritySelect call gives precedence to input channels with lower index.
 * Available messages from high priority channels will be served before messages from lower-priority channels.
 * Messages received through a single input channel will have their mutual order preserved.
 *
 */
def critical = new DataflowVariable()
def ordinary = new DataflowQueue()
def whoCares = new DataflowQueue()

task {
    ordinary &lt;&lt; 'All working fine'
    whoCares &lt;&lt; 'I feel a bit tired'
    ordinary &lt;&lt; 'We are on target'
}

task {
    ordinary &lt;&lt; 'I have just started my work. Busy. Will come back later...'
    sleep 5000
    ordinary &lt;&lt; 'I am done for now'
}

task {
    whoCares &lt;&lt; 'Huh, what is that noise'
    ordinary &lt;&lt; 'Here I am to do some clean-up work'
    whoCares &lt;&lt; 'I wonder whether unplugging this cable will eliminate that nasty sound.'
    critical &lt;&lt; 'The server room goes on UPS!'
    whoCares &lt;&lt; 'The sound has disappeared'
}

def select = select([critical, ordinary, whoCares])
println 'Starting to monitor our IT department'
sleep 3000
10.times {println "Received: ${select.prioritySelect().value}"}</pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_collecting_results_of_asynchronous_computations">Collecting results of asynchronous computations</h5>
<div class="paragraph">
<p>Asynchronous activities, no matter whether they are <strong>dataflow tasks</strong> , <strong>active objects' methods</strong> or
<strong>asynchronous functions</strong> , return <em>Promises</em> .  <em>Promises</em> implement the <em>SelectableChannel</em> interface and
so can be passed in <em>selects</em> for selection together with other <em>Promises</em> as well as <em>read channels</em> .
Similarly to Java&#8217;s <em>CompletionService</em> , GPars <em>Select</em> enables you to obtain results of asynchronous
activities as soon as each of them becomes available.  Also, you may employ <em>Select</em> to give you the
first/fastest result of several computations running in parallel.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.dataflow.Promise
import groovyx.gpars.dataflow.Select
import groovyx.gpars.group.DefaultPGroup
/**
 * Demonstrates the use of dataflow tasks and selects to pick the fastest result of concurrently run calculations.
 */

final group = new DefaultPGroup()
group.with {
    Promise p1 = task {
        sleep(1000)
        10 * 10 + 1
    }
    Promise p2 = task {
        sleep(1000)
        5 * 20 + 2
    }
    Promise p3 = task {
        sleep(1000)
        1 * 100 + 3
    }

    final alt = new Select(group, p1, p2, p3)
    def result = alt.select()
    println "Result: " + result
}</pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_timeouts_2">Timeouts</h5>
<div class="paragraph">
<p>The <em>Select.createTimeout()</em> method will create a DataflowVariable that gets bound to a value after a given
time period.  This can be leveraged in <em>Selects</em> so that they unblock after a desired delay, if none of the
other channels delivers a value before that moment. Just pass the <strong>timeout channel</strong> as another input channel
to the <em>Select</em> .</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.dataflow.Promise
import groovyx.gpars.dataflow.Select
import groovyx.gpars.group.DefaultPGroup
/**
 * Demonstrates the use of dataflow tasks and selects to pick the fastest result of concurrently run calculations.
 */

final group = new DefaultPGroup()
group.with {
    Promise p1 = task {
        sleep(1000)
        10 * 10 + 1
    }
    Promise p2 = task {
        sleep(1000)
        5 * 20 + 2
    }
    Promise p3 = task {
        sleep(1000)
        1 * 100 + 3
    }

    final timeoutChannel = Select.createTimeout(500)

    final alt = new Select(group, p1, p2, p3, timeoutChannel)
    def result = alt.select()
    println "Result: " + result
}</pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_cancellation">Cancellation</h5>
<div class="paragraph">
<p>In case you need to cancel the other tasks once a value has been calculated or a timeout expired, the best
way is to set a flag that the tasks periodically monitor. There&#8217;s intentionally no cancellation machinery
built into <em>DataflowVariables</em> or <em>Tasks</em> .</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.dataflow.Promise
import groovyx.gpars.dataflow.Select
import groovyx.gpars.group.DefaultPGroup

import java.util.concurrent.atomic.AtomicBoolean

/**
 * Demonstrates the use of dataflow tasks and selects to pick the fastest result of concurrently run calculations.
 * It shows a waz to cancel the slower tasks once a result is known
 */

final group = new DefaultPGroup()
final done = new AtomicBoolean()

group.with {
    Promise p1 = task {
        sleep(1000)
        if (done.get()) return
        10 * 10 + 1
    }
    Promise p2 = task {
        sleep(1000)
        if (done.get()) return
        5 * 20 + 2
    }
    Promise p3 = task {
        sleep(1000)
        if (done.get()) return
        1 * 100 + 3
    }

    final alt = new Select(group, p1, p2, p3, Select.createTimeout(500))
    def result = alt.select()
    done.set(true)
    println "Result: " + result
}</pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_operators">Operators</h3>
<div class="paragraph">
<p>Dataflow Operators and Selectors provide a full Dataflow implementation with all the usual ceremony.</p>
</div>
<div class="sect3">
<h4 id="_concepts_3">Concepts</h4>
<div class="paragraph">
<p>Full dataflow concurrency builds on the concept of channels connecting operators and selectors, which
consume values coming through input channels, transform them into new values and output the new values into
their output channels.  While <em>Operators</em> wait for <strong>all</strong> input channels to have a value available for read
before they start process them, <em>Selectors</em> are triggered by a value available on <strong>any</strong> of the input
channels.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>operator(inputs: [a, b, c], outputs: [d]) {x, y, z -&gt;
    ...
    bindOutput 0, x + y + z
}</pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre>/**
 * CACHE
 *
 * Caches sites' contents. Accepts requests for url content, outputs the content. Outputs requests for download
 * if the site is not in cache yet.
 */
operator(inputs: [urlRequests], outputs: [downloadRequests, sites]) {request -&gt;

    if (!request.content) {
        println "[Cache] Retrieving ${request.site}"
        def content = cache[request.site]
        if (content) {
            println "[Cache] Found in cache"
            bindOutput 1, [site: request.site, word:request.word, content: content]
        } else {
            def downloads = pendingDownloads[request.site]
            if (downloads != null) {
                println "[Cache] Awaiting download"
                downloads &lt;&lt; request
            } else {
                pendingDownloads[request.site] = []
                println "[Cache] Asking for download"
                bindOutput 0, request
            }
        }
    } else {
        println "[Cache] Caching ${request.site}"
        cache[request.site] = request.content
        bindOutput 1, request
        def downloads = pendingDownloads[request.site]
        if (downloads != null) {
            for (downloadRequest in downloads) {
                println "[Cache] Waking up"
                bindOutput 1, [site: downloadRequest.site, word:downloadRequest.word, content: request.content]
            }
            pendingDownloads.remove(request.site)
        }
    }
}</pre>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>The standard error handling will print out an error message to the standard error output and terminate the
operator in case an uncaught exception is thrown from withing the operator&#8217;s body. To alter the behavior,
you can register your own event listener:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def listener = new DataflowEventAdapter() {
    @Override
    boolean onException(final DataflowProcessor processor, final Throwable e) {
        logChannel &lt;&lt; e
        return false   //Indicate whether to terminate the operator or not
    }
}

op = group.operator(inputs: [a, b], outputs: [c], listeners: [listener]) {x, y -&gt;
    ...
}
See the _Operator lifecycle_ section for more details.</pre>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_types_of_operators">Types of operators</h5>
<div class="paragraph">
<p>There are specialized versions of operators serving specific purposes:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>operator - the basic general-purpose operator</p>
</li>
<li>
<p>selector - operator that is triggered by a value being available in any of its input channels</p>
</li>
<li>
<p>prioritySelector - a selector that prefers delivering messages from lower-indexed input channels over higher-indexed ones</p>
</li>
<li>
<p>splitter - a single-input operator copying its input values to all of its output channels</p>
</li>
</ul>
</div>
<div class="sect5">
<h6 id="_wiring_operators_together">Wiring operators together</h6>
<div class="paragraph">
<p>Operators are typically combined into networks, when some operators consume output by other operators.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>operator(inputs:[a, b], outputs:[c, d]) {...}
splitter(c, [e, f])
selector(inputs:[e, d]: outputs:[]) {...}</pre>
</div>
</div>
<div class="paragraph">
<p>You may alternatively refer to output channels through operators themselves:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def op1 = operator(inputs:[a, b], outputs:[c, d]) {...}
def sp1 = splitter(op1.outputs[0], [e, f])                            //takes the first output of op1
selector(inputs:[sp1.outputs[0], op1.outputs[1]]: outputs:[]) {...}   //takes the first output of sp1 and the second output of op1</pre>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_grouping_operators">Grouping operators</h5>
<div class="paragraph">
<p>Dataflow operators can be organized into groups to allow for performance fine-tuning. Groups provide a handy
<em>operator()</em> factory method to create tasks attached to the groups.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.group.DefaultPGroup

def group = new DefaultPGroup()

group.with {
    operator(inputs: [a, b, c], outputs: [d]) {x, y, z -&gt;
        ...
        bindOutput 0, x + y + z
    }
}</pre>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">Custom thread pools for dataflow</div>
<div class="paragraph">
<p>The default thread pool for dataflow operators contains daemon threads, which means your application will
exit as soon as the main thread finishes and won&#8217;t wait for all tasks to complete.  When grouping operators,
make sure that your custom thread pools either use daemon threads, too, which can be achieved by using
DefaultPGroup or by providing your own thread factory to a thread pool constructor, or in case your thread
pools use non-daemon threads, such as when using the NonDaemonPGroup group class, make sure you shutdown the
group or the thread pool explicitly by calling its shutdown() method, otherwise your applications will not
exit.</p>
</div>
</div>
</div>
<div class="paragraph">
<p>You may selectively override the default group used for tasks, operators, callbacks and other dataflow
elements inside a code block using the <em>Dataflow.usingGroup()</em> method:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>Dataflow.usingGroup(group) {
    operator(inputs: [a, b, c], outputs: [d]) {x, y, z -&gt;
        ...
        bindOutput 0, x + y + z
    }
}</pre>
</div>
</div>
<div class="paragraph">
<p>You can always override the default group by being specific:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>Dataflow.usingGroup(group) {
    anotherGroup.operator(inputs: [a, b, c], outputs: [d]) {x, y, z -&gt;
        ...
        bindOutput 0, x + y + z
    }
}</pre>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_constructing_operators">Constructing operators</h4>
<div class="paragraph">
<p>The construction properties of an operator, such as <em>inputs</em>, <em>outputs</em>, <em>stateObject</em> or <em>maxForks</em> cannot
be modified once the operator has been build.  You may find the <em>groovyx.gpars.dataflow.ProcessingNode</em>
class helpful when gradually collecting channels and values into lists before you finally build an operator.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.dataflow.Dataflow
import groovyx.gpars.dataflow.DataflowQueue
import static groovyx.gpars.dataflow.ProcessingNode.node

/**
 * Shows how to build operators using the ProcessingNode class
 */

final DataflowQueue aValues = new DataflowQueue()
final DataflowQueue bValues = new DataflowQueue()
final DataflowQueue results = new DataflowQueue()

//Create a config and gradually set the required properties - channels, code, etc.
def adderConfig = node {valueA, valueB -&gt;
    bindOutput valueA + valueB
}
adderConfig.inputs &lt;&lt; aValues
adderConfig.inputs &lt;&lt; bValues
adderConfig.outputs &lt;&lt; results

//Build the operator
final adder = adderConfig.operator(Dataflow.DATA_FLOW_GROUP)

//Now the operator is running and processing the data
aValues &lt;&lt; 10
aValues &lt;&lt; 20
bValues &lt;&lt; 1
bValues &lt;&lt; 2

assert [11, 22] == (1..2).collect {
    results.val
}</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_state_in_operators">State in operators</h4>
<div class="paragraph">
<p>Although operators can frequently do without keeping state between subsequent invocations, GPars allows
operators to maintain state, if desired by the developer. One obvious way is to leverage the Groovy closure
capabilities to close-over their context:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>int counter = 0
operator(inputs: [a], outputs: [b]) {value -&gt;
    counter += 1
}</pre>
</div>
</div>
<div class="paragraph">
<p>Another way, which allows you to avoid declaring the state object outside of the operator definition, is to pass the state object
into the operator as a <em>stateObject</em> parameter at construction time:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>operator(inputs: [a], outputs: [b], stateObject: [counter: 0]) {value -&gt;
    stateObject.counter += 1
}</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_parallelize_operators">Parallelize operators</h4>
<div class="paragraph">
<p>By default an operator&#8217;s body is processed by a single thread at a time. While this is a safe setting
allowing the operator&#8217;s body to be written in a non-thread-safe manner, once an operator becomes "hot" and
data start to accumulate in the operator&#8217;s input queues, you might consider allowing multiple threads to run
the operator&#8217;s body concurrently. Bear in mind that in such a case you need to avoid or protect shared
resources from multi-threaded access.  To enable multiple threads to run the operator&#8217;s body concurrently,
pass an extra <em>maxForks</em> parameter when creating an operator:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def op = operator(inputs: [a, b, c], outputs: [d, e], maxForks: 2) {x, y, z -&gt;
    bindOutput 0, x + y + z
    bindOutput 1, x * y * z
}</pre>
</div>
</div>
<div class="paragraph">
<p>The value of the <em>maxForks</em> parameter indicates the maximum of threads running the operator
concurrently. Only positive numbers are allowed with value 1 being the default.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>Please always make sure the <strong>group</strong> serving the operator holds enough threads to support all requested
forks.  Using groups allows you to organize tasks or operators around different thread pools (wrapped inside
the group).  While the Dataflow.task() command schedules the task on a default thread pool
(java.util.concurrent.Executor, fixed size=#cpu+1, daemon threads), you may prefer being able to define your
own thread pool(s) to run your tasks.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def group = new DefaultPGroup(10)
group.operator((inputs: [a, b, c], outputs: [d, e], maxForks: 5) {x, y, z -&gt; ...}</pre>
</div>
</div>
<div class="paragraph">
<p>The default group uses a resizeable thread pool as so will never run out of threads.</p>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_synchronizing_the_output">Synchronizing the output</h5>
<div class="paragraph">
<p>When enabling internal parallelization of an operator by setting the value for <em>maxForks</em> to a value greater
than 1 it is important to remember that without explicit or implicit synchronization in the operators' body
race-conditions may occur.  Especially bear in mind that values written to multiple output channels are not
guarantied to be written atomically in the same order to all the channels</p>
</div>
<div class="listingblock">
<div class="content">
<pre>operator(inputs:[inputChannel], outputs:[a, b], maxForks:5) {msg -&gt;
    bindOutput 0, msg
    bindOutput 1, msg
}
inputChannel &lt;&lt; 1
inputChannel &lt;&lt; 2
inputChannel &lt;&lt; 3
inputChannel &lt;&lt; 4
inputChannel &lt;&lt; 5</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>May result in output channels having the values mixed-up something like:</pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre>a -&gt; 1, 3, 2, 4, 5
b -&gt; 2, 1, 3, 5, 4</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>Explicit synchronization is one way to get correctly bound all output channels and protect operator not-thread local state:</pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre>def lock = new Object()
operator(inputs:[inputChannel], outputs:[a, b], maxForks:5) {msg -&gt;
    doStuffThatIsThreadSafe()

    synchronized(lock) {
        doSomethingThatMustNotBeAccessedByMultipleThreadsAtTheSameTime()
        bindOutput 0, msg
        bindOutput 1, 2*msg
    }
}</pre>
</div>
</div>
<div class="paragraph">
<p>Obviously you need to weight the pros and cons here, since synchronization may defeat the purpose of setting
<em>maxForks</em> to a value greater than 1.</p>
</div>
<div class="paragraph">
<p>To set values of all the operator&#8217;s output channels in one atomic step, you may also consider calling either
the <em>bindAllOutputsAtomically</em> method, passing in a single value to write to all output channels or the
<em>bindAllOutputsAtomically</em> method, which takes a multiple values, each of which will be written to the
output channel with the same position index.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>operator(inputs:[inputChannel], outputs:[a, b], maxForks:5) {msg -&gt;
    doStuffThatIsThreadSafe()
        bindAllOutputValuesAtomically msg, 2*msg
    }
}</pre>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="literalblock">
<div class="content">
<pre>Using the _bindAllOutputs_ or the _bindAllOutputValues_ methods will not guarantee atomicity of writes across al the output channels when using internal parallelism.
If preserving the order of messages in multiple output channels is not an issue, _bindAllOutputs_ as well as _bindAllOutputValues_ will provide better performance over the atomic variants.</pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_operator_lifecycle">Operator lifecycle</h5>
<div class="paragraph">
<p>Dataflow operators and selectors fire several events during their lifecycle, which allows the interested
parties to obtain notifications and potential alter operator&#8217;s behavior. The <em>DataflowEventListener</em>
interface offers a couple of callback methods:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>public interface DataflowEventListener {
    /**
     * Invoked immediately after the operator starts by a pooled thread before the first message is obtained
     *
     * @param processor The reporting dataflow operator/selector
     */
    void afterStart(DataflowProcessor processor);

    /**
     * Invoked immediately after the operator terminates
     *
     * @param processor The reporting dataflow operator/selector
     */
    void afterStop(DataflowProcessor processor);

    /**
     * Invoked if an exception occurs.
     * If any of the listeners returns true, the operator will terminate.
     * Exceptions outside of the operator's body or listeners' messageSentOut() handlers will terminate the operator irrespective of the listeners' votes.
     *
     * @param processor The reporting dataflow operator/selector
     * @param e         The thrown exception
     * @return True, if the operator should terminate in response to the exception, false otherwise.
     */
    boolean onException(DataflowProcessor processor, Throwable e);

    /**
     * Invoked when a message becomes available in an input channel.
     *
     * @param processor The reporting dataflow operator/selector
     * @param channel   The input channel holding the message
     * @param index     The index of the input channel within the operator
     * @param message   The incoming message
     * @return The original message or a message that should be used instead
     */
    Object messageArrived(DataflowProcessor processor, DataflowReadChannel&lt;Object&gt; channel, int index, Object message);

    /**
     * Invoked when a control message (instances of ControlMessage) becomes available in an input channel.
     *
     * @param processor The reporting dataflow operator/selector
     * @param channel   The input channel holding the message
     * @param index     The index of the input channel within the operator
     * @param message   The incoming message
     * @return The original message or a message that should be used instead
     */
    Object controlMessageArrived(DataflowProcessor processor, DataflowReadChannel&lt;Object&gt; channel, int index, Object message);

    /**
     * Invoked when a message is being bound to an output channel.
     *
     * @param processor The reporting dataflow operator/selector
     * @param channel   The output channel to send the message to
     * @param index     The index of the output channel within the operator
     * @param message   The message to send
     * @return The original message or a message that should be used instead
     */
    Object messageSentOut(DataflowProcessor processor, DataflowWriteChannel&lt;Object&gt; channel, int index, Object message);

    /**
     * Invoked when all messages required to trigger the operator become available in the input channels.
     *
     * @param processor The reporting dataflow operator/selector
     * @param messages  The incoming messages
     * @return The original list of messages or a modified/new list of messages that should be used instead
     */
    List&lt;Object&gt; beforeRun(DataflowProcessor processor, List&lt;Object&gt; messages);

    /**
     * Invoked when the operator completes a single run
     *
     * @param processor The reporting dataflow operator/selector
     * @param messages  The incoming messages that have been processed
     */
    void afterRun(DataflowProcessor processor, List&lt;Object&gt; messages);

    /**
     * Invoked when the fireCustomEvent() method is triggered manually on a dataflow operator/selector
     *
     * @param processor The reporting dataflow operator/selector
     * @param data      The custom piece of data provided as part of the event
     * @return A value to return from the fireCustomEvent() method to the caller (event initiator)
     */
    Object customEvent(DataflowProcessor processor, Object data);
}</pre>
</div>
</div>
<div class="paragraph">
<p>A default implementation is provided through the <em>DataflowEventAdapter</em> class.</p>
</div>
<div class="paragraph">
<p>Listeners provide a way to handle exceptions, when they occur inside operators. A listener may typically log such exceptions,
notify a supervising entity, generate an alternative output or perform any steps required to recover from the situation.
If there&#8217;s no listener registered or if any of the listeners returns <em>true</em> the operator will terminate, preserving the contract of <em>afterStop()</em> .
Exceptions that occur outside the actual operator&#8217;s body, i.e. at the parameter preparation phase before the body is triggered
or at the clean-up and channel subscription phase, after the body finishes, always lead to operator termination.</p>
</div>
<div class="paragraph">
<p>The <em>fireCustomEvent()</em> method available on operators and selectors may be used to communicate back and forth between operator&#8217;s body
and the interested listeners:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>final listener = new DataflowEventAdapter() {
    @Override
    Object customEvent(DataflowProcessor processor, Object data) {
        println "Log: Getting quite high on the scale $data"
        return 100  //The value to use instead
    }
}

op = group.operator(inputs: [a, b], outputs: [c], listeners: [listener]) {x, y -&gt;
    final sum = x + y
    if (sum &gt; 100) bindOutput(fireCustomEvent(sum))  //Reporting that the sum is too high, binding the lowered value that comes back
    else bindOutput sum
}</pre>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_selectors">Selectors</h4>
<div class="paragraph">
<p>Selector&#8217;s body should be a closure consuming either one or two arguments.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>selector (inputs : [a, b, c], outputs : [d, e]) {value -&gt;
    ....
}</pre>
</div>
</div>
<div class="paragraph">
<p>The two-argument closure will get a value plus an index of the input channel, the value of which is
currently being processed.  This allows the selector to distinguish between values coming through different
input channels.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>selector (inputs : [a, b, c], outputs : [d, e]) {value, index -&gt;
    ....
}</pre>
</div>
</div>
<div class="sect4">
<h5 id="_priority_selector">Priority Selector</h5>
<div class="paragraph">
<p>When priorities need to be preserved among input channels, a <em>DataflowPrioritySelector</em> should be used.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>prioritySelector(inputs : [a, b, c], outputs : [d, e]) {value, index -&gt;
    ...
}</pre>
</div>
</div>
<div class="paragraph">
<p>The priority selector will always prefer values from channels with lower position index over values coming
through the channels with higher position index.</p>
</div>
</div>
<div class="sect4">
<h5 id="_join_selector">Join selector</h5>
<div class="paragraph">
<p>A selector without a body closure specified will copy all incoming values to all of its output channels.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def join = selector (inputs : [programmers, analysis, managers], outputs : [employees, colleagues])</pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_internal_parallelism">Internal parallelism</h5>
<div class="paragraph">
<p>The <em>maxForks</em> attribute allowing for internal selectors parallelism is also available.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>selector (inputs : [a, b, c], outputs : [d, e], maxForks : 5) {value -&gt;
    ....
}</pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_guards_2">Guards</h5>
<div class="paragraph">
<p>Just like <em>Selects</em> , <em>Selectors</em> also allow the users to temporarily include/exclude individual input
channels from selection.  The <em>guards</em> input property can be used to set the initial mask on all input
channels and the <em>setGuards</em> and <em>setGuard</em> methods are then available in the selector&#8217;s body.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.dataflow.DataflowQueue
import static groovyx.gpars.dataflow.Dataflow.selector
import static groovyx.gpars.dataflow.Dataflow.task

/**
 * Demonstrates the ability to enable/disable channels during a value selection on a select by providing boolean guards.
 */
final DataflowQueue operations = new DataflowQueue()
final DataflowQueue numbers = new DataflowQueue()

def instruction
def nums = []

selector(inputs: [operations, numbers], outputs: [], guards: [true, false]) {value, index -&gt;   //initial guards is set here
    if (index == 0) {
        instruction = value
        setGuard(0, false)  //setGuard() used here
        setGuard(1, true)
    }
    else nums &lt;&lt; value
    if (nums.size() == 2) {
        setGuards([true, false])                                    //setGuards() used here
        final def formula = "${nums[0]} $instruction ${nums[1]}"
        println "$formula = ${new GroovyShell().evaluate(formula)}"
        nums.clear()
    }
}

task {
    operations &lt;&lt; '+'
    operations &lt;&lt; '+'
    operations &lt;&lt; '*'
}

task {
    numbers &lt;&lt; 10
    numbers &lt;&lt; 20
    numbers &lt;&lt; 30
    numbers &lt;&lt; 40
    numbers &lt;&lt; 50
    numbers &lt;&lt; 60
}</pre>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>Avoid combining <em>guards</em> and <em>maxForks</em> greater than 1. Although the <em>Selector</em> is thread-safe and won&#8217;t be damaged in any way, the guards are likely not to be set
the way you expect. The multiple threads running selector&#8217;s body concurrently will tend to over-write each-other&#8217;s settings to the <em>guards</em> property.</p>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_shutting_down_dataflow_networks">Shutting Down Dataflow Networks</h3>
<div class="paragraph">
<p>Shutting down a network of dataflow processors (operators and selectors) may sometimes be a non-trivial
task, especially if you need a generic mechanism that will not leave any messages unprocessed.</p>
</div>
<div class="paragraph">
<p>Dataflow operators and selectors can be terminated in three ways:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>by calling the terminate() method on all operators that need to be terminated</p>
</li>
<li>
<p>by sending a poisson message</p>
</li>
<li>
<p>by setting up a network of activity monitors that will shutdown the network after all messages have been processed</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Check out the details on the ways that GPars provides.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">Shutting down the thread pool</div>
<div class="paragraph">
<p>If you use a custom <em>PGroup</em> to maintain a thread pool for your dataflow network, you should not forget to
shutdown the pool once the network is terminated.  Otherwise the thread pool will consume system resources
and, in case of using non-daemon threads, it will prevent JVM from exit.</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_emergency_shutdown">Emergency shutdown</h4>
<div class="paragraph">
<p>You can call <em>terminate()</em> on any operator/selector to immediately shut it down. Provided you keep track of
all your processors, perhaps by adding them to a list, the fastest way to stop the network would be:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>allMyProcessors*.terminate()</pre>
</div>
</div>
<div class="paragraph">
<p>This should, however, be treated as an emergency exit, since no guarantees can be given regarding messages
processed nor finished work.  Operators will simply terminate instantly leaving work unfinished and
abandoning messages in the input channels.  Certainly, the lifecycle event listeners hooked to the
operators/selectors will have their <em>afterStop()</em> event handlers invoked in order to, for example, release
resources or output a note into the log.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def op1 = operator(inputs: [a, b, c], outputs: [d, e]) {x, y, z -&gt; }

def op2 = selector(inputs: [d], outputs: [f, out]) { }

def op3 = prioritySelector(inputs: [e, f], outputs: [b]) {value, index -&gt; }

[op1, op2, op3]*.terminate()  //Terminate all operators by calling the terminate() method on them
op1.join()
op2.join()
op3.join()</pre>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>Shutting down the whole JVM through <em>System.exit()</em> will also obviously shutdown the dataflow network, however, no lifecycle listeners will be invoked in such cases.</p>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_stopping_operators_gently">Stopping operators gently</h5>
<div class="paragraph">
<p>Operators handle incoming messages repeatedly. The only safe moment for stopping an operator without the
risk of loosing any messages is right after the operator has finished processing messages and is just about
to look for more messages in its incoming pipes.  This is exactly what the <em>terminateAfterNextRun()</em> method
does. It will schedule the operator for shutdown after the next set of messages gets handled.</p>
</div>
<div class="paragraph">
<p>The unprocessed messages will stay in the input channels, which allows you to handle them later, perhaps
with a different operator/selector or in some other way. Using <em>terminateAfterNextRun()</em> you will not loose
any input messages.  This may be particularly handy when you use a group of operators/selectors to
load-balance messages coming from a channel.  Once the work-load decreases, the terminateAfterNextRun()
method may be used to safely reduce the pool of load-balancing operators.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">Detecting shutdown</div>
<div class="paragraph">
<p>Operators and electors offer a handy <em>join()</em> method for those who need to block until the operator terminates.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>allMyProcessors*.join()</pre>
</div>
</div>
<div class="paragraph">
<p>This is the easies way to wait until the whole dataflow network shuts down, irrespective of the shutdown method used.</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_poisonpill">PoisonPill</h4>
<div class="paragraph">
<p><em>PoisonPill</em> is a common term for a strategy that uses special-purpose messages to stop entities that
receive it.  GPars offers the <em>PoisonPill</em> class, which has exactly such effect or operators and
selectors. Since <em>PoisonPill</em> is a <em>ControlMessage</em>, it is invisible to operator&#8217;s body and custom code does
not need to handle it in any way.  <em>DataflowEventListeners</em> may react to <em>ControlMessages</em> through the
<em>controlMessageArrived()</em> handler method.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def op1 = operator(inputs: [a, b, c], outputs: [d, e]) {x, y, z -&gt; }

def op2 = selector(inputs: [d], outputs: [f, out]) { }

def op3 = prioritySelector(inputs: [e, f], outputs: [b]) {value, index -&gt; }

a &lt;&lt; PoisonPill.instance  //Send the poisson

op1.join()
op2.join()
op3.join()</pre>
</div>
</div>
<div class="paragraph">
<p>After receiving a poisson an operator terminates, right after it finishes the current calculation and makes
sure the poisson is sent to all its output channels, so that the poisson can spread to the connected
operators.  Also, although operators typically wait for all inputs to have a value, in case of
<em>PoisonPills</em>, the operator will terminate immediately as soon as a <em>PoisonPill</em> appears on any of its
inputs. The values already obtained from the other channels will be lost. It can be considered an error in
the design of the network, if these messages were supposed to be processed.  They would need a proper value
as their peer and not a PoisonPill in order to be processes normally.</p>
</div>
<div class="paragraph">
<p>Selectors, on the other hand, will patiently wait for <em>PoisonPill</em> to be received from all their input
channels before sending it on the the output channels.  This behavior prevents networks containing
<strong>feed-back loops involving selectors</strong> from being shutdown using <em>PoisonPill</em> .  A selector would never
receive a <em>PoisonPill</em> from the channel that comes back from behind the selector. A different shutdown
strategy should be used for such networks.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>Given the potential variety of operator networks and their asynchronous nature, a good termination strategy is that
operators and selectors should only ever terminate themselves.
All ways of terminating them from outside (either by calling the terminate() method or by sending poisson down the stream)
may result in messages being lost somewhere in the pipes, when the reading operators terminate before they fully handle
the messages waiting in their input channels.</p>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_immediate_poison_pill">Immediate poison pill</h4>
<div class="paragraph">
<p>Especially for selectors to shutdown immediately after receiving a poison pill, a notion of <strong>immediate
poison pill</strong> has been introduced.  Since normal, non-immediate poison pills merely close the input channel
leaving the selector alive until at least one input channel remains open, the immediate poison pill closes
the selector instantly. Obviously, unprocessed messages from the other selector&#8217;s input channels will not be
handled by the selector, once it reads an immediate poison pill.</p>
</div>
<div class="paragraph">
<p>With immediate poison pill you can safely shutdown networks with selectors involved in feedback loops.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def op1 = selector(inputs: [a, b, c], outputs: [d, e]) {value, index -&gt; }
def op2 = selector(inputs: [d], outputs: [f, out]) { }
def op3 = prioritySelector(inputs: [e, f], outputs: [b]) {value, index -&gt; }

a &lt;&lt; PoisonPill.immediateInstance

[op1, op2, op3]*.join()</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_poison_with_counting">Poison with counting</h4>
<div class="paragraph">
<p>When sending a poison pill down the operator network you may need to be notified when all the operators or a
specified number of them have been stopped. The <em>CountingPoisonPill</em> class serves exactly this purpose:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>operator(inputs: [a, b, c], outputs: [d, e]) {x, y, z -&gt; }
selector(inputs: [d], outputs: [f, out]) { }
prioritySelector(inputs: [e, f], outputs: [b]) {value, index -&gt; }

//Send the poisson indicating the number of operators than need to be terminated before we can continue
final pill = new CountingPoisonPill(3)
a &lt;&lt; pill

//Wait for all operators to terminate
pill.join()
//At least 3 operators should be terminated by now</pre>
</div>
</div>
<div class="paragraph">
<p>The <em>termination</em> property of the <em>CountingPoisonPill</em> class is a regular <em>Promise&lt;Boolean&gt;</em> and so has a lot of handy properties.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>//Send the poisson indicating the number of operators than need to be terminated before we can continue
final pill = new CountingPoisonPill(3)
pill.termination.whenBound {println "Reporting asynchronously that the network has been stopped"}
a &lt;&lt; pill

if (pill.termination.bound) println "Wow, that was quick. We are done already!"
else println "Things are being slow today. The network is still running."

//Wait for all operators to terminate
assert pill.termination.get()
//At least 3 operators should be terminated by now</pre>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>An immediate variant of <em>CountingPoisonPill</em> is also available - <em>ImmediateCountingPoisonPill</em> .</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def op1 = selector(inputs: [a, b, c], outputs: [d, e]) {value, index -&gt; }
def op2 = selector(inputs: [d], outputs: [f, out]) { }
def op3 = prioritySelector(inputs: [e, f], outputs: [b]) {value, index -&gt; }

final pill = new ImmediateCountingPoisonPill(3)
a &lt;&lt; pill
pill.join()</pre>
</div>
</div>
<div class="paragraph">
<p><em>ImmediateCountingPoisonPill</em> will safely and instantly shutdown dataflow networks even with selectors
involved in feedback loops, which normal non-immediate poison pill would not be able to.</p>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_poison_strategies">Poison strategies</h4>
<div class="paragraph">
<p>To correctly shutdown a network using <em>PoisonPill</em> you must identify the appropriate set of channels to send
<em>PoisonPill</em> to.  <em>PoisonPill</em> will spread in the network the usual way through the channels and processors
down the stream. Typically the right channels to send <em>PoisonPill</em> to will be those that serve as <strong>data
sources</strong> for the network.  This may be difficult to achieve for general cases or for complex networks. On
the other hand, for networks with a prevalent direction of message flow <em>PoisonPill</em> provides a very
straightforward way to shutdown the whole network gracefully.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>Load-balancing architectures, which use multiple operators reading messages off a shared channel (queue),
will also prevent poison shutdown to work properly, since only one of the reading operators will get to read
the poison message.  You may consider using <strong>forked operators</strong> instead, by setting the <em>maxForks</em> property
to a value greater than 1.  Another alternative is to manually split the message stream into multiple
channels, each of which would be consumed by one of the original operators.</p>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_termination_tips_and_tricks">Termination tips and tricks</h4>
<div class="paragraph">
<p>Notice that GPars <em>tasks</em> return a <em>DataflowVariable</em>, which gets bound to a value as soon as the task
finishes.  The 'terminator' operator below leverages the fact that <em>DataflowVariables</em> are implementations
of the <em>DataflowReadChannel</em> interface and thus can be consumed by operators. As soon as both tasks finish,
the operator will send a <em>PoisonPill</em> down the <em>q</em> channel to stop the consumer as soon as it processes all
data.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.dataflow.DataflowQueue
import groovyx.gpars.group.NonDaemonPGroup


def group = new NonDaemonPGroup()

final DataflowQueue q = new DataflowQueue()

// final destination
def customs = group.operator(inputs: [q], outputs: []) { value -&gt;
    println "Customs received $value"
}

// big producer
def green = group.task {
    (1..100).each {
        q &lt;&lt; 'green channel ' + it
        sleep 10
    }
}

// little producer
def red = group.task {
    (1..10).each {
        q &lt;&lt; 'red channel ' + it
        sleep 15
    }
}

def terminator = group.operator(inputs: [green, red], outputs: []) { t1, t2 -&gt;
    q &lt;&lt; PoisonPill.instance
}

customs.join()
group.shutdown()</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_keeping_poisonpill_inside_a_given_network">Keeping PoisonPill inside a given network</h4>
<div class="paragraph">
<p>If your network passed values through channels to entities outside of it, you may need to stop the
<em>PoisonPill</em> messages on the network boundaries. This can be easily achieved by putting a single-input
single-output filtering operator on each such channel.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>operator(networkLeavingChannel, otherNetworkEnteringChannel) {value -&gt;
    if (!(value instanceOf PoisonPill)) bindOutput it
}</pre>
</div>
</div>
<div class="paragraph">
<p>The <em>Pipeline</em> DSL may be also helpful here:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>networkLeavingChannel.filter { !(it instanceOf PoisonPill) } into otherNetworkEnteringChannel</pre>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>Check out the <em>Pipeline DSL</em> section to find out more on pipelines.</p>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_graceful_shutdown">Graceful shutdown</h4>
<div class="paragraph">
<p>GPars provides a generic way to shutdown a dataflow network. Unlike the previously mentioned mechanisms this
approach will keep the network running until all the messages get handled and than gracefully shuts all
operators down letting you know when this happens.  You have to pay a modest performance penalty,
though. This is unavoidable since we need to keep track of what&#8217;s happening inside the network.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.dataflow.DataflowBroadcast
import groovyx.gpars.dataflow.DataflowQueue
import groovyx.gpars.dataflow.operator.component.GracefulShutdownListener
import groovyx.gpars.dataflow.operator.component.GracefulShutdownMonitor
import groovyx.gpars.group.DefaultPGroup
import groovyx.gpars.group.PGroup

PGroup group = new DefaultPGroup(10)
final a = new DataflowQueue()
final b = new DataflowQueue()
final c = new DataflowQueue()
final d = new DataflowQueue&lt;Object&gt;()
final e = new DataflowBroadcast&lt;Object&gt;()
final f = new DataflowQueue&lt;Object&gt;()
final result = new DataflowQueue&lt;Object&gt;()

final monitor = new GracefulShutdownMonitor(100);

def op1 = group.operator(inputs: [a, b], outputs: [c], listeners: [new GracefulShutdownListener(monitor)]) {x, y -&gt;
    sleep 5
    bindOutput x + y
}
def op2 = group.operator(inputs: [c], outputs: [d, e], listeners: [new GracefulShutdownListener(monitor)]) {x -&gt;
    sleep 10
    bindAllOutputs 2*x
}
def op3 = group.operator(inputs: [d], outputs: [f], listeners: [new GracefulShutdownListener(monitor)]) {x -&gt;
    sleep 5
    bindOutput x + 40
}
def op4 = group.operator(inputs: [e.createReadChannel(), f], outputs: [result], listeners: [new GracefulShutdownListener(monitor)]) {x, y -&gt;
    sleep 5
    bindOutput x + y
}

100.times{a &lt;&lt; 10}
100.times{b &lt;&lt; 20}

final shutdownPromise = monitor.shutdownNetwork()

100.times{assert 160 == result.val}

shutdownPromise.get()
[op1, op2, op3, op4]*.join()

group.shutdown()</pre>
</div>
</div>
<div class="paragraph">
<p>First, we need an instance of <em>GracefulShutdownMonitor</em> , which will orchestrate the shutdown process. It
relies on instances of <em>GracefulShutdownListener</em> attached to all operators/selectors. These listeners
observe their respective processors together with their input channels and report to the shared
<em>GracefulShutdownMonitor</em>.  Once <em>shutdownNetwork()</em> is called on <em>GracefulShutdownMonitor</em> , it will
periodically check for reported activities, query the state of operators as well as the number of messages
in their input channels.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>Please make sure that no new messages enter the dataflow network after the shutdown has been initiated,
since this may cause the network to never terminate.  The shutdown process should only be started after all
data producers have ceased sending additional messages to the monitored network.</p>
</div>
</div>
</div>
<div class="paragraph">
<p>The <em>shutdownNetwork()</em> method returns a <em>Promise</em> so that you can do the usual set of tricks with it -
block waiting for the network to terminate using the <em>get()</em> method, register a callback using the
<em>whenBound()</em> method or make it trigger a whole set of activities through the <em>then()</em> method.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">Limitations of graceful shutdown</div>
<div class="ulist">
<ul>
<li>
<p>For <em>GracefulShutdownListener</em> to work correctly, its <em>messageArrived()</em> event handler must see the
original value that has arrived through the input channel. Since some event listeners may alter the
messages as they pass through the listeners it is advisable to add the <em>GracefulShutdownListener</em> first to
the list of listeners on each dataflow processor.</p>
</li>
<li>
<p>Also, graceful shutdown will not work for those rare operators that have listeners, which turn control
messages into plain value messages in the <em>controlMessageArrived()</em> event handler.</p>
</li>
<li>
<p>Third and last, load-balancing architectures, which use multiple operators reading messages off a shared
channel (queue), will also prevent graceful shutdown to work properly. You may consider using <strong>forked
operators</strong> instead, by setting the <em>maxForks</em> property to a value greater than 1. Another alternative is
to manually split the message stream into multiple channels, each of which would be consumed by one of the
original operators.</p>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_application_frameworks">Application Frameworks</h3>
<div class="paragraph">
<p>Dataflow Operators and Selectors can be successfully used to build high-level domain-specific frameworks for
problems that naturally fit the flow model.</p>
</div>
<div class="sect3">
<h4 id="_building_flow_frameworks_on_top_of_gpars_dataflow">Building flow frameworks on top of GPars dataflow</h4>
<div class="paragraph">
<p>GPars dataflow can be viewed as bottom-line language-level infrastructure. Operators, selectors, channels
and event listeners can be very useful at language level to combine, for example, with actors or parallel
collections.  Whenever a need comes for asynchronous handling of events that come through one of more
channels, a dataflow operator or a small dataflow network could be a very good fit. Unlike tasks, operators
are lightweight and release threads when there&#8217;s no message to process. Unlike actors, operators are
addressed indirectly through channels and may easily combine messages from multiple channels into one
action.</p>
</div>
<div class="paragraph">
<p>Alternatively, operators can be looked at as continuous functions, which instantly and repeatedly transform
their input values into output.  We believe that a concurrency-friendly general-purpose programming language
should provide this type of abstraction.</p>
</div>
<div class="paragraph">
<p>At the same time, dataflow elements can be easily used as building blocks for constructing domain-specific
workflow-like frameworks.  These frameworks can offer higher-level abstractions specialized to a single
problem domain, which would be inappropriate for a general-purpose language-level library. Each of the
higher-level concepts is then mapped to (potentially several) GPars concepts.</p>
</div>
<div class="paragraph">
<p>For example, a network solving data-mining problems may consist of several data sources, data cleaning
nodes, categorization nodes, reporting nodes and others. Image processing network, on the other hand, may
need nodes specialized in image compression and format transformation. Similarly, networks for data
encryption, mp3 encoding, work-flow management as well as many other domains that would benefit from
dataflow-based solutions, will differ in many aspects - the type of nodes in the network, the type and
frequency of events, the load-balancing scheme, potential constraints on branching, the need for
visualization, debugging and logging, the way users define the networks and interact with them as well as
many others.</p>
</div>
<div class="paragraph">
<p>The higher-level application-specific frameworks should put effort into providing abstractions best suited
for the given domain and hide GPars complexities. For example, the visual graph of the network that the user
manipulates on the screen should typically not show all the channels that participate in the
network. Debugging or logging channels, which rarely contribute to the core of the solution, are among the
first good candidates to consider for exclusion. Also channels and lifecycle-event listeners, which
orchestrate aspects such as load balancing or graceful shutdown, will probably be not exposed to the user,
although they will be part of the generated and executed network. Similarly, a single channel in the
domain-specific model will in reality translate into multiple channels perhaps with one or more
logging/transforming/filtering operators connecting them together. The function associated with a node will
most likely be wrapped with some additional infrastructural code to form the operator&#8217;s body.</p>
</div>
<div class="paragraph">
<p>GPars gives you the underlying components that the end user may be abstracted away completely by the
application-specific framework.  This keeps GPars domain-agnostic and universal, yet useful at the
implementation level.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_pipeline_dsl">Pipeline DSL</h3>
<div class="sect3">
<h4 id="_a_dsl_for_building_operators_pipelines">A DSL for building operators pipelines</h4>
<div class="paragraph">
<p>Building dataflow networks can be further simplified. GPars offers handy shortcuts for the common scenario
of building (mostly linear) pipelines of operators.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def toUpperCase = {s -&gt; s.toUpperCase()}

final encrypt = new DataflowQueue()
final DataflowReadChannel encrypted = encrypt | toUpperCase | {it.reverse()} | {'###encrypted###' + it + '###'}

encrypt &lt;&lt; "I need to keep this message secret!"
encrypt &lt;&lt; "GPars can build linear operator pipelines really easily"

println encrypted.val
println encrypted.val</pre>
</div>
</div>
<div class="paragraph">
<p>This saves you from directly creating, wiring and manipulating all the channels and operators that are to
form the pipeline.  The <em>pipe</em> operator lets you hook an output of one function/operator/process to the
input of another one. Just like chaining system processes on the command line.</p>
</div>
<div class="paragraph">
<p>The <em>pipe</em> operator is a handy shorthand for a more generic <em>chainWith()</em> method:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def toUpperCase = {s -&gt; s.toUpperCase()}

final encrypt = new DataflowQueue()
final DataflowReadChannel encrypted = encrypt.chainWith toUpperCase chainWith {it.reverse()} chainWith {'###encrypted###' + it + '###'}

encrypt &lt;&lt; "I need to keep this message secret!"
encrypt &lt;&lt; "GPars can build linear operator pipelines really easily"

println encrypted.val
println encrypted.val</pre>
</div>
</div>
<div class="sect4">
<h5 id="_combining_pipelines_with_straight_operators">Combining pipelines with straight operators</h5>
<div class="paragraph">
<p>Since each operator pipeline has an entry and an exit channel, pipelines can be wired into more complex
operator networks.  Only your imagination can limit your ability to mix pipelines with channels and
operators in the same network definitions.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def toUpperCase = {s -&gt; s.toUpperCase()}
def save = {text -&gt;
    //Just pretending to be saving the text to disk, database or whatever
    println 'Saving ' + text
}

final toEncrypt = new DataflowQueue()
final DataflowReadChannel encrypted = toEncrypt.chainWith toUpperCase chainWith {it.reverse()} chainWith {'###encrypted###' + it + '###'}

final DataflowQueue fork1 = new DataflowQueue()
final DataflowQueue fork2 = new DataflowQueue()
splitter(encrypted, [fork1, fork2])  //Split the data flow

fork1.chainWith save  //Hook in the save operation

//Hook in a sneaky decryption pipeline
final DataflowReadChannel decrypted = fork2.chainWith {it[15..-4]} chainWith {it.reverse()} chainWith {it.toLowerCase()}
      .chainWith {'Groovy leaks! Check out a decrypted secret message: ' + it}

toEncrypt &lt;&lt; "I need to keep this message secret!"
toEncrypt &lt;&lt; "GPars can build operator pipelines really easy"

println decrypted.val
println decrypted.val</pre>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>The type of the channel is preserved across the whole pipeline. E.g. if you start chaining off a synchronous
 channel, all the channels in the pipeline will be synchronous. In that case, obviously, the whole chain
 blocks, including the writer who writes into the channel at head, until someone reads data off the tail of
 the pipeline.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>final SyncDataflowQueue queue = new SyncDataflowQueue()
final result = queue.chainWith {it * 2}.chainWith {it + 1} chainWith {it * 100}

Thread.start {
    5.times {
        println result.val
    }
}

queue &lt;&lt; 1
queue &lt;&lt; 2
queue &lt;&lt; 3
queue &lt;&lt; 4
queue &lt;&lt; 5</pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_joining_pipelines">Joining pipelines</h5>
<div class="paragraph">
<p>Two pipelines (or channels) can be connected using the <em>into()</em> method:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>final encrypt = new DataflowQueue()
final DataflowWriteChannel messagesToSave = new DataflowQueue()
encrypt.chainWith toUpperCase chainWith {it.reverse()} into messagesToSave

task {
    encrypt &lt;&lt; "I need to keep this message secret!"
    encrypt &lt;&lt; "GPars can build operator pipelines really easy"
}

task {
    2.times {
        println "Saving " + messagesToSave.val
    }
}</pre>
</div>
</div>
<div class="paragraph">
<p>The output of the <em>encryption</em> pipeline is directly connected to the input of the <em>saving</em> pipeline (a
single channel in out case).</p>
</div>
</div>
<div class="sect4">
<h5 id="_forking_the_data_flow">Forking the data flow</h5>
<div class="paragraph">
<p>When a need comes to copy the output of a pipeline/channel into more than one following pipeline/channel,
the <em>split()</em> method will help you:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>final encrypt = new DataflowQueue()
final DataflowWriteChannel messagesToSave = new DataflowQueue()
final DataflowWriteChannel messagesToLog = new DataflowQueue()

encrypt.chainWith toUpperCase chainWith {it.reverse()}.split(messagesToSave, messagesToLog)</pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_tapping_into_the_pipeline">Tapping into the pipeline</h5>
<div class="paragraph">
<p>Like <em>split()</em> the <em>tap()</em> method allows you to fork the data flow into multiple channels. Tapping, however,
is slightly more convenient in some scenarios, since it treats one of the two new forks as the successor of
the pipeline.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>queue.chainWith {it * 2}.tap(logChannel).chainWith{it + 1}.tap(logChannel).into(PrintChannel)</pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_merging_channels">Merging channels</h5>
<div class="paragraph">
<p>Merging allows you to join multiple read channels as inputs for a single dataflow operator. The function
passed as the second argument needs to accept as many arguments as there are channels being merged - each
will hold a value of the corresponding channel.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>maleChannel.merge(femaleChannel) {m, f -&gt; m.marry(f)}.into(mortgageCandidatesChannel)</pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_separation">Separation</h5>
<div class="paragraph">
<p><em>Separation</em> is the opposite operation to <em>merge</em>. The supplied closure returns a list of values, each of
which will be output into an output channel with the corresponding position index.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>queue1.separate([queue2, queue3, queue4]) {a -&gt; [a-1, a, a+1]}</pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_choices">Choices</h5>
<div class="paragraph">
<p>The <em>binaryChoice()</em> and <em>choice()</em> methods allow you to send a value to one out of two (or many) output
channels, as indicated by the return value from a closure.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>queue1.binaryChoice(queue2, queue3) {a -&gt; a &gt; 0}
queue1.choice([queue2, queue3, queue4]) {a -&gt; a % 3}</pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_filtering">Filtering</h5>
<div class="paragraph">
<p>The <em>filter()</em> method allows to filter data in the pipeline using boolean predicates.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>        final DataflowQueue queue1 = new DataflowQueue()
        final DataflowQueue queue2 = new DataflowQueue()

        final odd = {num -&gt; num % 2 != 0 }

        queue1.filter(odd) into queue2
        (1..5).each {queue1 &lt;&lt; it}
        assert 1 == queue2.val
        assert 3 == queue2.val
        assert 5 == queue2.val</pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_null_values">Null values</h5>
<div class="paragraph">
<p>If a chained function returns a <em>null</em> value, it is normally passed along the pipeline as a valid value. To
indicate to the operator that no value should be passed further down the pipeline, a <em>NullObject.nullObject</em>
instance must be returned.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>        final DataflowQueue queue1 = new DataflowQueue()
        final DataflowQueue queue2 = new DataflowQueue()

        final odd = {num -&gt;
            if (num == 5) return null  //null values are normally passed on
            if (num % 2 != 0) return num
            else return NullObject.nullObject  //this value gets blocked
        }

        queue1.chainWith odd into queue2
        (1..5).each {queue1 &lt;&lt; it}
        assert 1 == queue2.val
        assert 3 == queue2.val
        assert null == queue2.val</pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_customizing_the_thread_pools">Customizing the thread pools</h5>
<div class="paragraph">
<p>All of the Pipeline DSL methods allow for custom thread pools or <em>PGroups</em> to be specified:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>channel | {it * 2}

channel.chainWith(closure)
channel.chainWith(pool) {it * 2}
channel.chainWith(group) {it * 2}

channel.into(otherChannel)
channel.into(pool, otherChannel)
channel.into(group, otherChannel)

channel.split(otherChannel1, otherChannel2)
channel.split(otherChannels)
channel.split(pool, otherChannel1, otherChannel2)
channel.split(pool, otherChannels)
channel.split(group, otherChannel1, otherChannel2)
channel.split(group, otherChannels)

channel.tap(otherChannel)
channel.tap(pool, otherChannel)
channel.tap(group, otherChannel)

channel.merge(otherChannel)
channel.merge(otherChannels)
channel.merge(pool, otherChannel)
channel.merge(pool, otherChannels)
channel.merge(group, otherChannel)
channel.merge(group, otherChannels)

channel.filter( otherChannel)
channel.filter(pool, otherChannel)
channel.filter(group, otherChannel)

channel.binaryChoice( trueBranch, falseBranch)
channel.binaryChoice(pool, trueBranch, falseBranch)
channel.binaryChoice(group, trueBranch, falseBranch)

channel.choice( branches)
channel.choice(pool, branches)
channel.choice(group, branches)

channel.separate( outputs)
channel.separate(pool, outputs)
channel.separate(group, outputs)</pre>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_overriding_the_default_pgroup">Overriding the default PGroup</h4>
<div class="paragraph">
<p>To avoid the necessity to specify PGroup for each Pipeline DSL method separately you may override the value
of the default Dataflow PGroup.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>Dataflow.usingGroup(group) {
    channel.choice(branches)
}
//Is identical to
channel.choice(group, branches)</pre>
</div>
</div>
<div class="paragraph">
<p>The <em>Dataflow.usingGroup()</em> method resets the value of the default dataflow PGroup for the given code block
to the value specified.</p>
</div>
</div>
<div class="sect3">
<h4 id="_the_pipeline_builder">The pipeline builder</h4>
<div class="paragraph">
<p>The <em>Pipeline</em> class offers an intuitive builder for operator pipelines. The greatest benefit of using the
<em>Pipeline</em> class compared to chaining the channels directly is the ease with which a custom thread
pool/group can be applied to all the operators along the constructed chain.  The available methods and
overloaded operators are identical to the ones available on channels directly.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.dataflow.DataflowQueue
import groovyx.gpars.dataflow.operator.Pipeline
import groovyx.gpars.scheduler.DefaultPool
import groovyx.gpars.scheduler.Pool

final DataflowQueue queue = new DataflowQueue()
final DataflowQueue result1 = new DataflowQueue()
final DataflowQueue result2 = new DataflowQueue()
final Pool pool = new DefaultPool(false, 2)

final negate = {-it}

final Pipeline pipeline = new Pipeline(pool, queue)

pipeline | {it * 2} | {it + 1} | negate
pipeline.split(result1, result2)

queue &lt;&lt; 1
queue &lt;&lt; 2
queue &lt;&lt; 3

assert -3 == result1.val
assert -5 == result1.val
assert -7 == result1.val

assert -3 == result2.val
assert -5 == result2.val
assert -7 == result2.val

pool.shutdown()</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_passing_construction_parameters_through_the_pipeline_dsl">Passing construction parameters through the Pipeline DSL</h4>
<div class="paragraph">
<p>You are likely to frequently need the ability to pass additional initialization parameters to the operators,
such as the listeners to attach or the value for <em>maxForks</em>. Just like when building operators directly, the
Pipeline DSL methods accept an optional map of parameters to pass in.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>new Pipeline(group, queue1).merge([maxForks: 4, listeners: [listener]], queue2) {a, b -&gt; a + b}.into queue3</pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_implementation">Implementation</h3>
<div class="paragraph">
<p>The Dataflow Concurrency in GPars builds on the same principles as the actor support. All of the dataflow
tasks share a thread pool and so the number threads created through <em>Dataflow.task()</em> factory method don&#8217;t
need to correspond to the number of physical threads required from the system.  The <em>PGroup.task()</em> factory
method can be used to attach the created task to a group. Since each group defines its own thread pool, you
can easily organize tasks around different thread pools just like you do with actors.</p>
</div>
<div class="sect3">
<h4 id="_combining_actors_and_dataflow_concurrency">Combining actors and Dataflow Concurrency</h4>
<div class="paragraph">
<p>The good news is that you can combine actors and Dataflow Concurrency in any way you feel fit for your
particular problem at hands. You can freely you use Dataflow Variables from actors.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>final DataflowVariable a = new DataflowVariable()

final Actor doubler = Actors.actor {
    react {message-&gt;
        a &lt;&lt; 2 * message
    }
}

final Actor fakingDoubler = actor {
    react {
        doubler.send it  //send a number to the doubler
        println "Result ${a.val}"  //wait for the result to be bound to 'a'
    }
}

fakingDoubler &lt;&lt; 10</pre>
</div>
</div>
<div class="paragraph">
<p>In the example you see the "fakingDoubler" using both messages and a <em>DataflowVariable</em> to communicate with
the <em>doubler</em> actor.</p>
</div>
</div>
<div class="sect3">
<h4 id="_using_plain_java_threads">Using plain java threads</h4>
<div class="paragraph">
<p>The <em>DataflowVariable</em> as well as the <em>DataflowQueue</em> classes can obviously be used from any thread of your
application, not only from the tasks created by <em>Dataflow.task()</em> . Consider the following example:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.dataflow.DataflowVariable

final DataflowVariable a = new DataflowVariable&lt;String&gt;()
final DataflowVariable b = new DataflowVariable&lt;String&gt;()

Thread.start {
    println "Received: $a.val"
    Thread.sleep 2000
    b &lt;&lt; 'Thank you'
}

Thread.start {
    Thread.sleep 2000
    a &lt;&lt; 'An important message from the second thread'
    println "Reply: $b.val"
}</pre>
</div>
</div>
<div class="paragraph">
<p>We&#8217;re creating two plain <em>java.lang.Thread</em> instances, which exchange data using the two data flow
variables. Obviously, neither the actor lifecycle methods, nor the send/react functionality or thread
pooling take effect in such scenarios.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_synchronous_variables_and_channels">Synchronous Variables and Channels</h3>
<div class="paragraph">
<p>When using asynchronous dataflow channels, apart from the fact that readers have to wait for a value to be
available for consumption, the communicating parties remain completely independent. Writers don&#8217;t wait for
their messages to get consumed. Readers obtain values immediately as they come and ask.  Synchronous
channels, on the other hand, can synchronize writers with the readers as well as multiple readers among
themselves.  This is particularly useful when you need to increase the level of determinism. The
writer-to-reader partial ordering imposed by asynchronous communication is complemented with
reader-to-writer partial ordering, when using synchronous communication.  In other words, you are guaranteed
that whatever the reader did before reading a value from a synchronous channel preceded whatever the writer
did after writing the value.  Also, with synchronous communication writers can never get too far ahead of
readers, which simplifies reasoning about the system and reduces the need to manage data production speed in
order to avoid system overload.</p>
</div>
<div class="sect3">
<h4 id="_synchronous_dataflow_queue">Synchronous dataflow queue</h4>
<div class="paragraph">
<p>The <em>SyncDataflowQueue</em> class should be used for point-to-point (1:1 or n:1) communication. Each message
written to the queue will be consumed by exactly one reader. Writers are blocked until their message is
consumed, readers are blocked until there&#8217;s a value available for them to read.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.dataflow.SyncDataflowQueue
import groovyx.gpars.group.NonDaemonPGroup

/**
 * Shows how synchronous dataflow queues can be used to throttle fast producer when serving data to a slow consumer.
 * Unlike when using asynchronous channels, synchronous channels block both the writer and the readers until all parties are ready to exchange messages.
 */

def group = new NonDaemonPGroup()

final SyncDataflowQueue channel = new SyncDataflowQueue()

def producer = group.task {
    (1..30).each {
        channel &lt;&lt; it
        println "Just sent $it"
    }
    channel &lt;&lt; -1
}

def consumer = group.task {
    while (true) {
        sleep 500  //simulating a slow consumer
        final Object msg = channel.val
        if (msg == -1) return
        println "Received $msg"
    }
}

consumer.join()

group.shutdown()</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_synchronous_dataflow_broadcast">Synchronous dataflow broadcast</h4>
<div class="paragraph">
<p>The <em>SyncDataflowBroadcast</em> class should be used for publish-subscribe (1:n or n:m) communication. Each
message written to the broadcast will be consumed by all subscribed readers. Writers are blocked until their
message is consumed by all readers, readers are blocked until there&#8217;s a value available for them to read and
all the other subscribed readers ask for the message as well.  With <em>SyncDataflowBroadcast</em> you get all
readers processing the same message at the same time and waiting for one-another before getting the
next one.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.dataflow.SyncDataflowBroadcast
import groovyx.gpars.group.NonDaemonPGroup

/**
 * Shows how synchronous dataflow broadcasts can be used to throttle fast producer when serving data to slow consumers.
 * Unlike when using asynchronous channels, synchronous channels block both the writer and the readers until all parties are ready to exchange messages.
 */

def group = new NonDaemonPGroup()

final SyncDataflowBroadcast channel = new SyncDataflowBroadcast()

def subscription1 = channel.createReadChannel()
def fastConsumer = group.task {
    while (true) {
        sleep 10  //simulating a fast consumer
        final Object msg = subscription1.val
        if (msg == -1) return
        println "Fast consumer received $msg"
    }
}

def subscription2 = channel.createReadChannel()
def slowConsumer = group.task {
    while (true) {
        sleep 500  //simulating a slow consumer
        final Object msg = subscription2.val
        if (msg == -1) return
        println "Slow consumer received $msg"
    }
}

def producer = group.task {
    (1..30).each {
        println "Sending $it"
        channel &lt;&lt; it
        println "Sent $it"
    }
    channel &lt;&lt; -1
}

[fastConsumer, slowConsumer]*.join()

group.shutdown()</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_synchronous_dataflow_variable">Synchronous dataflow variable</h4>
<div class="paragraph">
<p>Unlike <em>DataflowVariable</em>, which is asynchronous and only blocks the readers until a value is bound to the
variable, the <em>SyncDataflowVariable</em> class provides a one-shot data exchange mechanism that blocks the
writer and all readers until a specified number of waiting parties is reached.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.dataflow.SyncDataflowVariable
import groovyx.gpars.group.NonDaemonPGroup

final NonDaemonPGroup group = new NonDaemonPGroup()

final SyncDataflowVariable value = new SyncDataflowVariable(2)  //two readers required to exchange the message

def writer = group.task {
    println "Writer about to write a value"
    value &lt;&lt; 'Hello'
    println "Writer has written the value"
}

def reader = group.task {
    println "Reader about to read a value"
    println "Reader has read the value: ${value.val}"
}

def slowReader = group.task {
    sleep 5000
    println "Slow reader about to read a value"
    println "Slow reader has read the value: ${value.val}"
}

[reader, slowReader]*.join()

group.shutdown()</pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_kanban_flow">Kanban Flow</h3>
<div class="paragraph">
<p>APIs:
[KanbanFlow|api:groovyx.gpars.dataflow.KanbanFlow] |
[KanbanLink|api:groovyx.gpars.dataflow.KanbanLink] |
[KanbanTray|api:groovyx.gpars.dataflow.KanbanTray] |</p>
</div>
<div class="sect3 gpars dataflow ProcessingNode">
<h4 id="_kanbanflow">KanbanFlow</h4>
<div class="paragraph">
<p>A <em>KanbanFlow</em> is a composed object that uses dataflow abstractions to define dependencies between multiple
concurrent producer and consumer operators.</p>
</div>
<div class="paragraph">
<p>Each link between a producer and a consumer is defined by a <em>KanbanLink</em>.</p>
</div>
<div class="paragraph">
<p>Inside each KanbanLink, the communication between producer and consumer follows the KanbanFlow pattern as
described in <a href="http://people.canoo.com/mittie/kanbanflow.html">The KanbanFlow Pattern</a>.  They use objects of
type <em>KanbanTray</em> to send products downstream and signal requests for further products back to the producer.</p>
</div>
<div class="paragraph">
<p>The figure below shows a <em>KanbanLink</em> with one producer, one consumer and five trays numbered 0 to 4. Tray
number 0 has been used to take a product from producer to consumer, has been emptied by the consumer and is
now sent back to the producer&#8217;s input queue. Trays 1 and 2 wait carry products waiting for consumption,
trays 3 and 4 wait to be used by producers.</p>
</div>
<div class="paragraph">
<p>!dataflow_kanban.png!</p>
</div>
<div class="paragraph">
<p>A <em>KanbanFlow</em> object links producers to consumers thus creating <em>KanbanLink</em> objects.  In the course of
this activity, a second link may be constructed where the producer is the same object that acted as the
consumer in a formerly created link such that the two links become connected to build a chain.</p>
</div>
<div class="paragraph">
<p>Here is an example of a <em>KanbanFlow</em> with only one link, e.g. one producer and one consumer.  The producer
always sends the number 1 downstream and the consumer prints this number.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import static groovyx.gpars.dataflow.ProcessingNode.node
import groovyx.gpars.dataflow.KanbanFlow

def producer = node { down -&gt; down 1 }
def consumer = node { up   -&gt; println up.take() }

new KanbanFlow().with {
    link producer to consumer
    start()
    // run for a while
    stop()
}</pre>
</div>
</div>
<div class="paragraph">
<p>For putting a product into a tray and sending the tray downstream, one can either use the @send()@ method,
the @&lt;&lt;@ operator, or use the tray as a method object.  The following lines are equivalent:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>node { down -&gt; down.send 1 }
node { down -&gt; down &lt;&lt; 1 }
node { down -&gt; down 1 }</pre>
</div>
</div>
<div class="paragraph">
<p>When a product is taken from the input tray with the @take()@ method, the empty tray is automatically
released.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>You should call @take()@ only once!</p>
</div>
</div>
</div>
<div class="paragraph">
<p>If you prefer to not using an empty tray for sending products downstream (as typically the case when a
<em>ProcessingNode</em> acts as a filter), you must release the tray in order to keep it in play. Otherwise, the
number of trays in the system decreases. You can release a tray either by calling the @release()@ method or
by using the @~@ operator (think "shake it off").  The following lines are equivalent:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>node { down -&gt; down.release() }
node { down -&gt; ~down }</pre>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>Trays are automatically released, if you call any of the @take()@ or @send()@ methods.</p>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_various_linking_structures">Various linking structures</h5>
<div class="paragraph">
<p>In addition to a linear chains, a <em>KanbanFlow</em> can also link a single producer to multiple consumers (tree)
or multiple producers to a single consumer (collector) or any combination of the above that results in a
directed acyclic graph (DAG).</p>
</div>
<div class="paragraph">
<p>The <em>KanbanFlowTest</em> class has many examples for such structures, including scenarios where a single
producer delegates work to multiple consumers with:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>a <strong>work-stealing</strong> strategy where all consumers get their pick from the downstream,</p>
</li>
<li>
<p>a <strong>master-slave</strong> strategy where a producer chooses from the available consumers, and</p>
</li>
<li>
<p>a <strong>broadcast</strong> strategy where a producer sends all products to all consumers.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Cycles are forbidden by default but when enabled, they can be used as so-called generators. A producer can
even be his own consumer that increases a product value in every cycle. The generator itself remains
state-free since the value is only stored as a product riding on a tray.  Such a generator can be used for
e.g. lazy sequences or as a the "heartbeat" of a subsequent flow.</p>
</div>
<div class="paragraph">
<p>The approach of generator "loops" can equally be applied to collectors, where a collector does not maintain
any internal state but sends a collection onto itself, adding products at each call.</p>
</div>
<div class="paragraph">
<p>Generally speaking, a <em>ProcessingNode</em> can link to itself for exporting state to the tray/product that it
sends to itself. Access to the product is then <strong>thread-safe by design</strong>.</p>
</div>
</div>
<div class="sect4">
<h5 id="_composing_kanbanflows">Composing KanbanFlows</h5>
<div class="paragraph">
<p>Just as <em>KanbanLink</em> objects can be chained together to form a <em>KanbanFlow</em>, flows themselves can be
composed again to form new greater flows from existing smaller ones.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def firstFlow = new KanbanFlow()
def producer  = node(counter)
def consumer  = node(repeater)
firstFlow.link(producer).to(consumer)

def secondFlow = new KanbanFlow()
def producer2  = node(repeater)
def consumer2  = node(reporter)
secondFlow.link(producer2).to(consumer2)

flow = firstFlow + secondFlow

flow.start()</pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_customizing_concurrency_characteristics">Customizing concurrency characteristics</h5>
<div class="paragraph">
<p>The amount of concurrency in a kanban system is determined by the number of trays (sometimes called <strong>WIP</strong> =
work in progress). With no trays in the streams, the system does nothing:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>With one tray only, the system is confined to sequential execution.</p>
</li>
<li>
<p>With more trays, concurrency begins.</p>
</li>
<li>
<p>With more trays than available processing units, the system begins to waste resources.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The number of trays can be controlled in various ways. They are typically set when starting the flow.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>flow.start(0) // start without trays
flow.start(1) // start with one tray per link in the flow
flow.start()  // start with the optimal number of trays</pre>
</div>
</div>
<div class="paragraph">
<p>In addition to the trays, the <em>KanbanFlow</em> may also be constrained by its underlying <em>ThreadPool</em>. A pool of
size 1 for example will not allow much concurrency.</p>
</div>
<div class="paragraph">
<p><em>KanbanFlows</em> use a default pool that is dimensioned by the number of available cores. This can be
customized by setting the @pooledGroup@ property.</p>
</div>
<div class="paragraph">
<p><strong>Test:</strong> \\
"KanbanFlowTest":https://github.com/GPars/GPars/blob/master/src/test/groovy/groovyx/gpars/dataflow/KanbanFlowTest.groovy \\
<strong>Demos:</strong> \\
"DemoKanbanFlow":https://github.com/GPars/GPars/blob/master/src/test/groovy/groovyx/gpars/samples/dataflow/kanban/DemoKanbanFlow.groovy \\
"DemoKanbanFlowBroadcast":https://github.com/GPars/GPars/blob/master/src/test/groovy/groovyx/gpars/samples/dataflow/kanban/DemoKanbanFlowBroadcast.groovy \\
"DemoKanbanFlowCycle":https://github.com/GPars/GPars/blob/master/src/test/groovy/groovyx/gpars/samples/dataflow/kanban/DemoKanbanFlowCycle.groovy \\
"DemoKanbanLazyPrimeSequenceLoops":https://github.com/GPars/GPars/blob/master/src/test/groovy/groovyx/gpars/samples/dataflow/kanban/DemoKanbanLazyPrimeSequenceLoops.groovy</p>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_classic_examples_2">Classic Examples</h3>
<div class="sect3">
<h4 id="_the_sieve_of_eratosthenes_implementation_using_dataflow_tasks">The Sieve of Eratosthenes implementation using dataflow tasks</h4>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.dataflow.DataflowQueue
import static groovyx.gpars.dataflow.Dataflow.task

/**
 * Demonstrates concurrent implementation of the Sieve of Eratosthenes using dataflow tasks
 */

final int requestedPrimeNumberCount = 1000

final DataflowQueue initialChannel = new DataflowQueue()

/**
 * Generating candidate numbers
 */
task {
    (2..10000).each {
        initialChannel &lt;&lt; it
    }
}

/**
 * Chain a new filter for a particular prime number to the end of the Sieve
 * @param inChannel The current end channel to consume
 * @param prime The prime number to divide future prime candidates with
 * @return A new channel ending the whole chain
 */
def filter(inChannel, int prime) {
    def outChannel = new DataflowQueue()

    task {
        while (true) {
            def number = inChannel.val
            if (number % prime != 0) {
                outChannel &lt;&lt; number
            }
        }
    }
    return outChannel
}

/**
 * Consume Sieve output and add additional filters for all found primes
 */
def currentOutput = initialChannel
requestedPrimeNumberCount.times {
    int prime = currentOutput.val
    println "Found: $prime"
    currentOutput = filter(currentOutput, prime)
}</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_the_sieve_of_eratosthenes_implementation_using_a_combination_of_dataflow_tasks_and_operators">The Sieve of Eratosthenes implementation using a combination of dataflow tasks and operators</h4>
<div class="listingblock">
<div class="content">
<pre>       import groovyx.gpars.dataflow.DataflowQueue
       import static groovyx.gpars.dataflow.Dataflow.operator
       import static groovyx.gpars.dataflow.Dataflow.task

       /**
        * Demonstrates concurrent implementation of the Sieve of Eratosthenes using dataflow tasks and operators
        */

       final int requestedPrimeNumberCount = 100

       final DataflowQueue initialChannel = new DataflowQueue()

       /**
        * Generating candidate numbers
        */
       task {
           (2..1000).each {
               initialChannel &lt;&lt; it
           }
       }

       /**
        * Chain a new filter for a particular prime number to the end of the Sieve
        * @param inChannel The current end channel to consume
        * @param prime The prime number to divide future prime candidates with
        * @return A new channel ending the whole chain
        */
       def filter(inChannel, int prime) {
           def outChannel = new DataflowQueue()

           operator([inputs: [inChannel], outputs: [outChannel]]) {
               if (it % prime != 0) {
                   bindOutput it
               }
           }
           return outChannel
       }

       /**
        * Consume Sieve output and add additional filters for all found primes
        */
       def currentOutput = initialChannel
       requestedPrimeNumberCount.times {
           int prime = currentOutput.val
           println "Found: $prime"
           currentOutput = filter(currentOutput, prime)
       }</pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_software_transactional_memory_stm">Software Transactional Memory (STM)</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Software Transactional Memory (STM) gives developers transactional semantics for accessing in-memory
data. When multiple threads share data in memory, by marking blocks of code as transactional (atomic) the
developer delegates the responsibility for data consistency to the STM engine.  GPars leverages the
<a href="https://github.com/pveentjer/Multiverse">Multiverse STM engine</a>.</p>
</div>
<div class="sect2">
<h3 id="_running_a_piece_of_code_atomically">Running a piece of code atomically</h3>
<div class="paragraph">
<p>When using STM, developers organize their code into transactions. A transaction is a piece of code, which is
executed <strong>atomically</strong> - either all the code is run or none at all.  The data used by the transactional code
remains <strong>consistent</strong> irrespective of whether the transaction finishes normally or abruptly.  While running
inside a transaction the code is given an illusion of being <strong>isolated</strong> from the other concurrently run
transactions so that changes to data in one transaction are not visible in the other ones until the
transactions commit. This gives us the <strong>ACI</strong> part of the <strong>ACID</strong> characteristics of database
transactions. The <strong>durability</strong> transactional aspect so typical for databases, is not typically mandated
for Stm.</p>
</div>
<div class="paragraph">
<p>GPars allows developers to specify transaction boundaries by using the <em>atomic</em> closures.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.stm.GParsStm
import org.multiverse.api.references.TxnInteger
import static org.multiverse.api.StmUtils.newTxnInteger

public class Account {
    private final TxnInteger amount = newTxnInteger(0);

    public void transfer(final int a) {
        GParsStm.atomic {
            amount.increment(a);
        }
    }

    public int getCurrentAmount() {
        GParsStm.atomicWithInt {
            amount.get();
        }
    }
}</pre>
</div>
</div>
<div class="paragraph">
<p>There are several types of <em>atomic</em> closures, each for different type of return value:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>atomic</em> - returning <em>Object</em></p>
</li>
<li>
<p><em>atomicWithInt</em> - returning <em>int</em></p>
</li>
<li>
<p><em>atomicWithLong</em> - returning <em>long</em></p>
</li>
<li>
<p><em>atomicWithBoolean</em> - returning <em>boolean</em></p>
</li>
<li>
<p><em>atomicWithDouble</em> - returning <em>double</em></p>
</li>
<li>
<p><em>atomicWithVoid</em> - no return value</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Multiverse by default uses optimistic locking strategy and automatically rolls back and retries colliding
transactions.  Developers should thus restrain from irreversible actions (e.g. writing to the console,
sending and e-mail, launching a missile, etc.) in their transactional code.  To increase flexibility, the
default Multiverse settings can be customized through custom <em>atomic blocks</em> .</p>
</div>
</div>
<div class="sect2">
<h3 id="_customizing_the_transactional_properties">Customizing the transactional properties</h3>
<div class="paragraph">
<p>Frequently it may be desired to specify different values for some of the transaction properties
(e.g. read-only transactions, locking strategy, isolation level, etc.).  The <em>createAtomicBlock</em> method will
create a new <em>AtomicBlock</em> configured with the supplied values:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.stm.GParsStm
import org.multiverse.api.AtomicBlock
import org.multiverse.api.PropagationLevel

final TxnExecutor block = GParsStm.createTxnExecutor(maxRetries: 3000, familyName: 'Custom', PropagationLevel: PropagationLevel.Requires, interruptible: false)
assert GParsStm.atomicWithBoolean(block) {
    true
}</pre>
</div>
</div>
<div class="paragraph">
<p>The customized <em>AtomicBlock</em> can then be used to create transactions following the specified
settings. <em>AtomicBlock</em> instances are thread-safe and can be freely reused among threads and transactions.</p>
</div>
</div>
<div class="sect2">
<h3 id="_using_the_em_transaction_em_object">Using the <em>Transaction</em> object</h3>
<div class="paragraph">
<p>The atomic closures are provided the current <em>Transaction</em> as a parameter. The <em>Txn</em> objects representing a
transaction can then be used to manually control the transaction. This is illustrated in the example below,
where we use the <em>retry()</em> method to block the current transaction until the counter reaches the desired
value:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import groovyx.gpars.stm.GParsStm
import org.multiverse.api.PropagationLevel
import org.multiverse.api.TxnExecutor

import static org.multiverse.api.StmUtils.newTxnInteger

final TxnExecutor block = GParsStm.createTxnExecutor(maxRetries: 3000, familyName: 'Custom', PropagationLevel: PropagationLevel.Requires, interruptible: false)

def counter = newTxnInteger(0)
final int max = 100
Thread.start {
    while (counter.atomicGet() &lt; max) {
        counter.atomicIncrementAndGet(1)
        sleep 10
    }
}
assert max + 1 == GParsStm.atomicWithInt(block) { tx -&gt;
    if (counter.get() == max) return counter.get() + 1
    tx.retry()
}</pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_data_structures">Data structures</h3>
<div class="paragraph">
<p>You might have noticed in the code examples above that we use dedicated data structures to hold values. The
fact is that normal Java classes do not support transactions and thus cannot be used directly, since
Multiverse would not be able to share them safely among concurrent transactions, commit them nor roll them
back.  We need to use data that know about transactions:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>TxnIntRef</p>
</li>
<li>
<p>TxnLongRef</p>
</li>
<li>
<p>TxnBooleanRef</p>
</li>
<li>
<p>TxnDoubleRef</p>
</li>
<li>
<p>TxnRef</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>You typically create these through the factory methods of the <em>org.multiverse.api.StmUtils</em> class.</p>
</div>
</div>
<div class="sect2">
<h3 id="_more_information">More information</h3>
<div class="paragraph">
<p>We decided not to duplicate the information that was already available on the Multiverse website.
Unfortunately with the closure of Codehaus, that website is longer available. You may try to
decipher more information from the <a href="https://github.com/pveentjer/Multiverse">Multiverse source code</a>.
As we are unclear about the future of the Multiverse project, we are considering using a different
STM implementation in a future GParse 2.0.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_google_app_engine_integration">Google App Engine Integration</h2>
<div class="sectionbody">
<div class="paragraph">
<p>GPars can be run on the <a href="https://developers.google.com/appengine/">Google App Engine (GAE)</a>.  It can be made
part of Groovy and Java GAE applications as well as a plugged into Gaelyk.  The small
<a href="https://github.com/musketyr/gpars-appengine">GPars App Engine integration library</a> provides all the necessary
infrastructure to hook GAE services into GPars.  Although you&#8217;ll be running on GAE threads and leveraging
GAE timer services, the high-level abstractions remain the same.  With a few restrictions you can still use
GPars actors, dataflow, agents, parallel collections and other handy concepts.</p>
</div>
<div class="paragraph">
<p>Please refer to the <a href="https://github.com/musketyr/gpars-appengine">GPars App Engine library</a> documentation for
details on how to proceed with GPars on GAE.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_tips">Tips</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_general_gpars_tips">General GPars Tips</h3>
<div class="sect3">
<h4 id="_grouping_2">Grouping</h4>
<div class="paragraph">
<p>High-level concurrency concepts, like Agents, Actors or Dataflow tasks and operators can be grouped around
shared thread pools.  The <em>PGroup</em> class and its sub-classes represent convenient GPars wrappers around
thread pools.  Objects created using the group&#8217;s factory methods will share the group&#8217;s thread pool.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def group1 = new DefaultPGroup()
def group2 = new NonDaemonPGroup()

group1.with {
    task {...}
    task {...}
    def op = operator(...) {...}
    def actor = actor{...}
    def anotherActor = group2.actor{...}  //will belong to group2
    def agent = safe(0)
}</pre>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>When customizing the thread pools for groups, consider using the existing GPars implementations - the
<em>DefaultPool</em> or <em>ResizeablePool</em> classes.  Or you may create your own implementation of the
<em>groovyx.gpars.scheduler.Pool</em> interface to pass to the <em>DefaultPGroup</em> or <em>NonDaemonPGroup</em> constructors.</p>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_java_api">Java API</h4>
<div class="paragraph">
<p>Most of GPars functionality can be used from Java just as well as from Groovy. Checkout the <em>2.6 Java API -
Using GPars from Java</em> section of the User Guide and experiment with the Maven-based stand-alone Java
<a href="http://gpars.codehaus.org/Demos">demo applications</a>.  Take GPars with you wherever you go!</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_performance_2">Performance</h3>
<div class="paragraph">
<p>Your code in Groovy can be just as fast as code written in Java, Scala or any other programing language.
This should not be surprising, since GPars is technically a solid tasty Java-made cake with a Groovy DSL
cream on it.</p>
</div>
<div class="paragraph">
<p>Unlike in Java, however, with GPars, as well as with other DSL-friendly languages, you are very likely to
experience a useful kind of code speed-up for free, a speed-up coming from a better and cleaner design of
your application. Coding with a concurrency DSL will give you smaller code-base with code using the
concurrency primitives as language constructs. So it is much easier to build robust concurrent applications,
identify potential bottle-necks or errors and eliminate them.</p>
</div>
<div class="paragraph">
<p>While this whole User Guide is describing how to use Groovy and GPars to create beautiful and robust
concurrent code, let&#8217;s use this chapter to highlight a few places, where some code tuning or minor design
compromises could give you interesting performance gains.</p>
</div>
<div class="sect3">
<h4 id="_parallel_collections_3">Parallel Collections</h4>
<div class="paragraph">
<p>Methods for parallel collection processing, like <em>eachParallel()</em> , <em>collectParallel()</em> and such use
<em>Parallel Array</em> , an efficient tree-like data structure behind the scenes.  This data structure has to be
built from the original collection each time you call any of the parallel collection methods.  Thus when
chaining parallel method calls you might consider using the <em>map/reduce</em> API instead or resort to using the
<em>ParallelArray</em> API directly, to avoid the <em>Parallel Array</em> creation overhead.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>GParsPool.withPool {
    people.findAllParallel{it.isMale()}.collectParallel{it.name}.any{it == 'Joe'}
    people.parallel.filter{it.isMale()}.map{it.name}.filter{it == 'Joe'}.size() &gt; 0
    people.parallelArray.withFilter({it.isMale()} as Predicate).withMapping({it.name} as Mapper).any{it == 'Joe'} != null
}</pre>
</div>
</div>
<div class="paragraph">
<p>In many scenarios changing the pool size from the default value may give you performance
benefits. Especially if your tasks perform IO operations, like file or database access, networking and such,
increasing the number of threads in the pool is likely to help performance.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>GParsPool.withPool(50) {
    ...
}</pre>
</div>
</div>
<div class="paragraph">
<p>Since the closures you provide to the parallel collection processing methods will get executed frequently
and concurrently, you may further slightly benefit from turning them into Java.</p>
</div>
</div>
<div class="sect3">
<h4 id="_actors_4">Actors</h4>
<div class="paragraph">
<p>GPars actors are fast. <em>DynamicDispatchActors</em> and <em>ReactiveActors</em> are about twice as fast as the
<em>DefaultActors</em> , since they don&#8217;t have to maintain an implicit state between subsequent message
arrivals. The <em>DefaultActors</em> are in fact on par in performance with actors in <em>Scala</em> , which you can
hardly hear of as being slow.</p>
</div>
<div class="paragraph">
<p>If top performance is what you&#8217;re looking for, a good start is to identify the following patterns in your
actor code:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>actor {
    loop {
        react {msg -&gt;
            switch(msg) {
                case String:...
                case Integer:...
            }
        }
    }
}</pre>
</div>
</div>
<div class="paragraph">
<p>and replace them with <em>DynamicDispatchActor</em> :</p>
</div>
<div class="listingblock">
<div class="content">
<pre>messageHandler {
    when{String msg -&gt; ...}
    when{Integer msg -&gt; ...}
}</pre>
</div>
</div>
<div class="paragraph">
<p>The <em>loop</em> and <em>react</em> methods are rather costly to call.</p>
</div>
<div class="paragraph">
<p>Defining a <em>DynamicDispatchActor</em> or <em>ReactiveActor</em> as classes instead of using the <em>messageHandler</em> and
<em>reactor</em> factory methods will also give you some more speed:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>class MyHandler extends DynamicDispatchActor {
    public void handleMessage(String msg) {
        ...
    }

    public void handleMessage(Integer msg) {
        ...
    }
}</pre>
</div>
</div>
<div class="paragraph">
<p>Now, moving the <em>MyHandler</em> class into Java will squeeze the last bit of performance from GPars.</p>
</div>
<div class="sect4">
<h5 id="_pool_adjustment">Pool adjustment</h5>
<div class="paragraph">
<p>GPars allows you to group actors around thread pools, giving you the freedom to organize actors any way you
like.  It is always worthwhile to experiment with the actor pool size and type. <em>FJPool</em> usually gives
better characteristics that <em>DefaultPool</em> , but seems to be more sensitive to the number of threads in the
pool.  Sometimes using a <em>ResizeablePool</em> or <em>ResizeableFJPool</em> could help performance by automatic
eliminating unneeded threads.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def attackerGroup = new DefaultPGroup(new ResizeableFJPool(10))
def defenderGroup = new DefaultPGroup(new DefaultPool(5))

def attacker = attackerGroup.actor {...}
def defender = defenderGroup.messageHandler {...}
...</pre>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_agents_3">Agents</h4>
<div class="paragraph">
<p>GPars <em>Agents</em> are even a bit faster in processing messages than actors. The advice to group agents wisely
around thread pools and tune the pool sizes and types applies to agents as well as to actors.  With agents,
you may also benefit from submitting Java-written closures as messages.</p>
</div>
</div>
<div class="sect3">
<h4 id="_share_your_experience">Share your experience</h4>
<div class="paragraph">
<p>The more we hear about GPars uses in the wild the better we can adapt it for the future. Let us know how you
use GPars and how it performs.  Send us your benchmarks, performance comparisons or profiling reports to
help us tune GPars for you.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_hosted_environment">Hosted environment</h3>
<div class="paragraph">
<p>Hosted environments, such as Google App Engine, impose additional restrictions on threading. For GPars to
integrate with these environments better, the default thread factory and timer factory can be customized.
The <em>GPars_Config</em> class provides static initialization methods allowing third parties to register their own
implementations of the <em>PoolFactory</em> and <em>TimerFactory</em> interfaces, which will then be used to create
default pools and timers for Actors, Dataflow and PGroups.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>public final class GParsConfig {
    private static volatile PoolFactory poolFactory;
    private static volatile TimerFactory timerFactory;

    public static void setPoolFactory(final PoolFactory pool)

    public static PoolFactory getPoolFactory()

    public static Pool retrieveDefaultPool()

    public static void setTimerFactory(final TimerFactory timerFactory)

    public static TimerFactory getTimerFactory()

    public static GeneralTimer retrieveDefaultTimer(final String name, final boolean daemon)

    public static void shutdown()
}</pre>
</div>
</div>
<div class="paragraph">
<p>The custom factories should be registered immediately after the application startup in order for Actors and
Dataflow to be able to use them for their default groups.</p>
</div>
<div class="sect3">
<h4 id="_shutdown">Shutdown</h4>
<div class="paragraph">
<p>The <em>GParsConfig.shutdown()</em> method can be used in managed environments to properly shutdown all
asynchronously run timers and free the memory from all thread-local variables. After the call to this method
the GPars library will no longer provide the declared services.</p>
</div>
</div>
<div class="sect3">
<h4 id="_compatibility">Compatibility</h4>
<div class="paragraph">
<p>Some further compatibility problems may occur when running GPars in a hosted environment. The most
noticeable one is probably the lack of ForkJoinThreadPool support in GAE. Functionality such as Fork/Join
and GParsPool may thus not be available on some services as a result. However, GParsExecutorsPool, Dataflow,
Actors, Agents and Stm should work normally even when using managed non-Java SE thread pools.</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_remoting">Remoting</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Concepts like Actors, Dataflows and Agents are not restricted just to single VM,
where they provide an abstraction layer for concurrent programming
that allows to separate logic from low level synchronization code.
These concepts can be easly extended to multiple nodes in a network.
Following chapter describes remoting in GPars.</p>
</div>
<div class="paragraph">
<p><strong>Remark</strong>: Remoting for GPars was a <em>Google Summer of Code 2014</em> project.</p>
</div>
<div class="sect2">
<h3 id="_introduction_4">Introduction</h3>
<div class="paragraph">
<p>To use Actors, Dataflows or Agent remotely a new remote proxy object was introduced (with <em>Remote</em> prefix).
The proxy object usually has the same interface as its local counterpart,
which allows to use it in place of local counterpart.
Under the hood proxy object just sends messages over a wire to original instance.
To transport messages across the network <a href="http://netty.io">Netty</a> library was used.
To create a proxy-object instance serialization mechanism is used (more in <a href="#remote-serialization">Serialization</a>).</p>
</div>
<div class="paragraph">
<p>General scheme of using remote is as follows (details can be found in section below):</p>
</div>
<div class="paragraph">
<p>At <em>host A</em>:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Create remoting context and start a server to handle incomming requests.</p>
</li>
<li>
<p>Publish an instance under specified <em>name</em></p>
</li>
</ol>
</div>
<div class="paragraph">
<p>At <em>host B</em>:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Create remoting context</p>
</li>
<li>
<p>Ask for an instance with specified <em>name</em> from <em>hostA:port</em>. A promise is returned.</p>
</li>
<li>
<p>Get a proxy object from the promise.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p><strong>Note</strong>: At this moment a new connection is created for each request.</p>
</div>
<div class="sect3">
<h4 id="remote-serialization">Serialization</h4>
<div class="paragraph">
<p>Following mechanism was used to create proxy objects:</p>
</div>
<div class="paragraph">
<p><em>object</em> &#8592;(serialization)&#8594; <em>handle</em> ---- [network] ---- <em>handle</em> &#8592;(serialization)&#8594; <em>proxy-object</em></p>
</div>
<div class="paragraph">
<p>One of the main advantages of this mechanism is
that sending proxy-object reference back is deserialized to original instance.</p>
</div>
<div class="paragraph">
<p>As all messages are seralized before sending over a wire,
they must implement <em>Serializable</em> interface.
This is a consequence of using build-in Java serialization mechanism and Netty&#8217;s <em>ObjectDecoder/ObjectEncoder</em>.
On the other hand it gives a flexibility to send any custom object as a message to Actor
or to use DataflowVariable(s) of any type.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_dataflows">Dataflows</h3>
<div class="paragraph">
<p>In order to use remoting for Dataflows, a context (<em>RemoteDataflows</em> class) has to be created.
Within this context dataflows can be published and retrieved from remote hosts.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-groovy" data-lang="groovy">def remoteDataflows = RemoteDataflows.create()</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Note</strong>: In all subsections we assume that context is already created as shown above.</p>
</div>
<div class="paragraph">
<p>After creating context, if you want to allow other hosts to retrieve published dataflows,
you need to start a server. You need to provied address and port to listen on (eq. <em>localhost</em>:11222,
10.0.0.123:11333).</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-groovy" data-lang="groovy">remoteDataflows.startServer HOST PORT</code></pre>
</div>
</div>
<div class="paragraph">
<p>To stop the server, there is <em>stopServer()</em> method. Note that both method are asynchronous,
they don&#8217;t block - server is started/stopped in background.
Multiple execution of these methods or executing them in wrong order results in exception.</p>
</div>
<div class="paragraph">
<p><strong>Remark</strong>: To only retrieve instances from remote hosts starting a server is not necessary.</p>
</div>
<div class="sect3">
<h4 id="_dataflowvariable">DataflowVariable</h4>
<div class="paragraph">
<p>DataflowVariable is a core part of Dataflows subsystem that received remoting abilities.
Other structures(?) and subsystems depend on it.</p>
</div>
<div class="paragraph">
<p>Publishing a variable within context is done simply by:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-groovy" data-lang="groovy">def variable = new DataflowVariable()
remoteDataflows.publish variable "my-first-variable"</code></pre>
</div>
</div>
<div class="paragraph">
<p>It registers the variable under given name, so when a request for variable with name <em>my-first-variable</em> comes,
variable can be sent to remote host.
It&#8217;s important to remember, that publishing another variable under the same name,
will override the provious one and subsequent requests will send newly published one.</p>
</div>
<div class="paragraph">
<p>Retrieving of a variable is done by:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-groovy" data-lang="groovy">def remoteVariablePromise = remoteDataflows.getVariable HOST, PORT, "my-first-variable"
def remoteVariable = remoteVariablePromise.get()</code></pre>
</div>
</div>
<div class="paragraph">
<p>The <em>getVariable</em> method is non-blocking and returns promise, that will eventually hold a proxy object to variable.
This proxy has the same interface as DataflowVariable and can be used seemlessly as regular variable.</p>
</div>
<div class="paragraph">
<p>To explore a full example see: <em>groovyx.gpars.samples.remote.dataflow.variable</em></p>
</div>
</div>
<div class="sect3">
<h4 id="_dataflowbroadcast">DataflowBroadcast</h4>
<div class="paragraph">
<p>It&#8217;s possible to subscribe to DataflowBroadcast on remote host.
To do this, one had to publish it first (assuming that context is already created):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-groovy" data-lang="groovy">def stream = new DataflowBroadcast()
remoteDataflows.publish stream "my-first-broadcast"</code></pre>
</div>
</div>
<div class="paragraph">
<p>Then on other host it can be retrieved:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-groovy" data-lang="groovy">def readChannelPromise = remoteDataflows.getReadChannel HOST, PORT, "my-first-broadcast"
def readChannel = readChannelPromise.get()</code></pre>
</div>
</div>
<div class="paragraph">
<p>Obtainted proxy object has the same interface as ReadChannel
and can be used in same fashion as ReadChannel of regular DataflowBroadcast.</p>
</div>
<div class="paragraph">
<p>To explore a full example see: <em>groovyx.gpars.samples.remote.dataflow.broadcast</em></p>
</div>
</div>
<div class="sect3">
<h4 id="_dataflowqueue">DataflowQueue</h4>
<div class="paragraph">
<p>DataflowQueue received similar functionality. It can be published:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-groovy" data-lang="groovy">def queue = new DataflowQueue()
remoteDataflows.publish queue, "my-first-queue"</code></pre>
</div>
</div>
<div class="paragraph">
<p>and in similar way retrieved on remote host:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-groovy" data-lang="groovy">def queuePromise = remoteDataflows.getQueue HOST, PORT, "my-first-queue"
def queue = queuePromise.get()</code></pre>
</div>
</div>
<div class="paragraph">
<p>New items can be pushed into remote proxy of queue.
Such elements are sent over a wire to original instance and pushed into it.
Retrieval sends a request for an element to original instance.
Conceptually remote proxy is an interface -
it just sends request to original instance.</p>
</div>
<div class="paragraph">
<p>To explore a full example see:
<em>groovyx.gpars.samples.remote.dataflow.queue</em> or <em>groovyx.gpars.samples.remote.dataflow.queuebalancer</em></p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_actors_5">Actors</h3>
<div class="paragraph">
<p>Remote Actors subsystem is designed in similar way.
To start, a context (<em>RemoteActors</em> class) has to be created.
Within the context Actors instances can be published or retrieved from remote hosts.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-groovy" data-lang="groovy">def remoteActors = RemoteActors.create()</code></pre>
</div>
</div>
<div class="paragraph">
<p>Publishing:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-groovy" data-lang="groovy">def actor = ...
remoteActors.publish actor, "actor-name"</code></pre>
</div>
</div>
<div class="paragraph">
<p>Retrieval:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-groovy" data-lang="groovy">def actorPromise = remoteActors.get HOST, PORT, "actor-name"
def remoteActor = actorPromise.get()</code></pre>
</div>
</div>
<div class="paragraph">
<p>It is possible to join on remote Actor, this will block until original Actor ends its work.
Sending replies and <em>sendAndWait</em> are supported as well.</p>
</div>
<div class="paragraph">
<p>One can send any object as a message to Actor, but keep in mind it has to be <em>Serializable</em>.</p>
</div>
<div class="paragraph">
<p>See example: <em>groovyx.gpars.samples.remote.actor</em></p>
</div>
<div class="sect3">
<h4 id="_remote_actor_names">Remote Actor Names</h4>
<div class="paragraph">
<p>A context (<em>RemoteActors</em> class) may be represented by a name.
To create one with a name use:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-groovy" data-lang="groovy">def remoteActors = RemoteActors.create "test-group-1"</code></pre>
</div>
</div>
<div class="paragraph">
<p>Actors published withing this context may be accessed by providing a special actor URL.
For example: publishing an actor under name "actor" within this context makes it accessible under URL
"test-group-1/actor".</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-groovy" data-lang="groovy">def actor = remoteActors.get "test-group-1/actor"</code></pre>
</div>
</div>
<div class="paragraph">
<p>Host and port of an instance holding this actor is determined automatically.
Invoking <em>get</em> method sends a broadcast (to <em>255.255.255.255</em>) with a query
for an actor with specified name within a context with specified name.
Matching instance responds to that query with necessary information (host and port).</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
<div class="title">Allowed actor and context names</div>
As the URL contains "/" (backslash) as separator between context and actor name,
it is not allowed to use backslashes in actor name.
Context name can contain any UTF characters though.
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_agents_4">Agents</h3>
<div class="paragraph">
<p>Remote Agents system is designed in similar fashion.
To begin, a context (<em>RemoteAgents</em> class) has to be created.
Within the context Agents can be published or retrieved from remote hosts.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-groovy" data-lang="groovy">def remoteAgents = RemoteAgents.create()</code></pre>
</div>
</div>
<div class="paragraph">
<p>Publishing:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-groovy" data-lang="groovy">def agent = ...
remoteAgents.publish agent, "agent-name"</code></pre>
</div>
</div>
<div class="paragraph">
<p>Retrieval:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-groovy" data-lang="groovy">def agentPromise = remoteAgents.get HOST, PORT, "agent-name"
def remoteAgent = agentPromise.get()</code></pre>
</div>
</div>
<div class="paragraph">
<p>There are two ways of executing closures used to update state of remote Agent instance:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>remote</em> - closure is serialized and sent to original instance and executed in that context</p>
</li>
<li>
<p><em>local</em> - current state is retrieved and closure is executed where the update originated,
then updated value is sent to original instance.
Concurrent changes to Agent wait until this process ends.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>By default remote Agent uses <em>remote</em> execution policy.
Changing it is possible in following way:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-groovy" data-lang="groovy">def agentPromise = remoteAgents.get HOST, PORT, "agent"
def remoteAgent =  agentPromise.get()
remoteAgent.executionPolicy = AgentClosureExecutionPolicy.LOCAL</code></pre>
</div>
</div>
<div class="paragraph">
<p>See example: <em>groovyx.gpars.samples.remote.agent</em></p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_conclusion">Conclusion</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This was quite a wild ride, wasn&#8217;t it? Now, after going through the User Guide, you&#8217;re certainly ready to
build fast, robust and reliable concurrent applications.  You&#8217;ve seen that there are many concepts you can
choose from and each has its own areas of applicability. The ability to pick the right concept to apply to a
given problem and combine it with the rest of the system is key to being a successful developer.  If you
feel you can do this with GPars, the mission of the User Guide has been accomplished.</p>
</div>
<div class="paragraph">
<p>Now, go ahead, use GPars and have fun!</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="__a_href_quick_reference_html_quick_reference_a"><a href="quick_reference.html">Quick Reference</a></h2>
<div class="sectionbody">

</div>
</div>
</div>
<div id="footer">
<div id="footer-text">
Last updated 2015-09-26 12:52:57 BST
</div>
</div>
</body>
</html>